{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overvew\n",
    "- nb019を改良\n",
    "    - earlystoppingを実装\n",
    "    - best stateでモデルを保存\n",
    "    - resnet18 --> resnet50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CONST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "NB = '020'\n",
    "DEBUG = False\n",
    "PERIOD = 5\n",
    "PATH_EVENT = './../data_ignore/event/nb017_event_rms/nb017_event_rms.csv'\n",
    "DATASET = '32khz'\n",
    "DIR_MODEL = './../data_ignore/model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "settings_str = \"\"\"\n",
    "globals:\n",
    "  seed: 1213\n",
    "  device: cuda\n",
    "  num_epochs: 45\n",
    "  output_dir: /kaggle/training_output/\n",
    "  use_fold: 0\n",
    "  target_sr: 32000\n",
    "\n",
    "dataset:\n",
    "  name: SpectrogramDataset\n",
    "  params:\n",
    "    img_size: 224\n",
    "    melspectrogram_parameters:\n",
    "      n_mels: 128\n",
    "      fmin: 20\n",
    "      fmax: 16000\n",
    "    \n",
    "split:\n",
    "  name: StratifiedKFold\n",
    "  params:\n",
    "    n_splits: 5\n",
    "    random_state: 42\n",
    "    shuffle: True\n",
    "\n",
    "loader:\n",
    "  train:\n",
    "    batch_size: 20\n",
    "    shuffle: True\n",
    "    num_workers: 5\n",
    "    pin_memory: True\n",
    "    drop_last: True\n",
    "  val:\n",
    "    batch_size: 15\n",
    "    shuffle: False\n",
    "    num_workers: 5\n",
    "    pin_memory: True\n",
    "    drop_last: False\n",
    "\n",
    "model:\n",
    "  name: resnest50_fast_1s1x64d\n",
    "  params:\n",
    "    pretrained: True\n",
    "    n_classes: 264\n",
    "\n",
    "loss:\n",
    "  name: BCEWithLogitsLoss\n",
    "  params: {}\n",
    "\n",
    "optimizer:\n",
    "  name: Adam\n",
    "  params:\n",
    "    lr: 0.001\n",
    "\n",
    "scheduler:\n",
    "  name: CosineAnnealingLR\n",
    "  params:\n",
    "    T_max: 10\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import everything I need :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/librosa/util/decorators.py:9: NumbaDeprecationWarning: An import was requested from a module that has moved location.\n",
      "Import of 'jit' requested from: 'numba.decorators', please update to use 'numba.core.decorators' or pin to Numba version 0.48.0. This alias will not be present in Numba version 0.50.0.\n",
      "  from numba.decorators import jit as optional_jit\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gc\n",
    "import cv2 \n",
    "import time\n",
    "import yaml\n",
    "import random\n",
    "import librosa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import soundfile as sf\n",
    "from pathlib import Path\n",
    "from scipy.io import wavfile\n",
    "import matplotlib.pyplot as plt\n",
    "from fastprogress import progress_bar\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models\n",
    "import torch.utils.data as data\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, './../src/util/')\n",
    "from const import BIRD_CODE, INV_BIRD_CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# My function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed: int = 42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)  # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mono_to_color(X, mean=None, std=None, norm_max=None, norm_min=None, eps=1e-6):\n",
    "    # Stack X as [X,X,X]\n",
    "    X = np.stack([X, X, X], axis=-1)\n",
    "\n",
    "    # Standardize\n",
    "    mean = mean or X.mean()\n",
    "    X = X - mean\n",
    "    std = std or X.std()\n",
    "    Xstd = X / (std + eps)\n",
    "    _min, _max = Xstd.min(), Xstd.max()\n",
    "    norm_max = norm_max or _max\n",
    "    norm_min = norm_min or _min\n",
    "    if (_max - _min) > eps:\n",
    "        # Normalize to [0, 255]\n",
    "        V = Xstd\n",
    "        V[V < norm_min] = norm_min\n",
    "        V[V > norm_max] = norm_max\n",
    "        V = 255 * (V - norm_min) / (norm_max - norm_min)\n",
    "        V = V.astype(np.uint8)\n",
    "    else:\n",
    "        # Just zero\n",
    "        V = np.zeros_like(Xstd, dtype=np.uint8)\n",
    "    return V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpectrogramDataset(data.Dataset):\n",
    "    def __init__(self, file_list, img_size=224, \n",
    "                 waveform_transforms=None, spectrogram_transforms=None, melspectrogram_parameters={}):\n",
    "        \n",
    "        self.file_list = file_list  # list of list: [file_path, ebird_code]\n",
    "        self.img_size = img_size\n",
    "        self.waveform_transforms = waveform_transforms\n",
    "        self.spectrogram_transforms = spectrogram_transforms\n",
    "        self.melspectrogram_parameters = melspectrogram_parameters\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_list)\n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "        wav_path, ebird_code = self.file_list[idx]\n",
    "\n",
    "        y, sr = sf.read(wav_path)\n",
    "#         sr, y = wavfile.read(wav_path)\n",
    "\n",
    "        if self.waveform_transforms:\n",
    "            y = self.waveform_transforms(y)\n",
    "        else:\n",
    "            len_y = len(y)\n",
    "            effective_length = sr * PERIOD\n",
    "            if len_y < effective_length:\n",
    "                new_y = np.zeros(effective_length, dtype=y.dtype)\n",
    "                start = np.random.randint(effective_length - len_y)\n",
    "                new_y[start:start + len_y] = y\n",
    "                y = new_y.astype(np.float32)\n",
    "            elif len_y > effective_length:\n",
    "                start = np.random.randint(len_y - effective_length)\n",
    "                y = y[start:start + effective_length].astype(np.float32)\n",
    "            else:\n",
    "                y = y.astype(np.float32)\n",
    "\n",
    "        melspec = librosa.feature.melspectrogram(y, sr=sr, **self.melspectrogram_parameters)\n",
    "        melspec = librosa.power_to_db(melspec).astype(np.float32)\n",
    "\n",
    "        if self.spectrogram_transforms:\n",
    "            melspec = self.spectrogram_transforms(melspec)\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "        image = mono_to_color(melspec)\n",
    "        height, width, _ = image.shape\n",
    "        image = cv2.resize(image, (int(width * self.img_size / height), self.img_size))\n",
    "        image = np.moveaxis(image, 2, 0)\n",
    "        image = (image / 255.0).astype(np.float32)\n",
    "\n",
    "#         labels = np.zeros(len(BIRD_CODE), dtype=\"i\")\n",
    "        labels = np.zeros(len(BIRD_CODE), dtype=\"f\")\n",
    "        labels[BIRD_CODE[ebird_code]] = 1\n",
    "\n",
    "        return image, labels\n",
    "\n",
    "class SpectrogramEventRmsDataset(data.Dataset):\n",
    "    def __init__(self, file_list, img_size=224, \n",
    "                 waveform_transforms=None, spectrogram_transforms=None, melspectrogram_parameters={}):\n",
    "        \n",
    "        self.file_list = file_list  # list of list: [file_path, ebird_code]\n",
    "        self.img_size = img_size\n",
    "        self.waveform_transforms = waveform_transforms\n",
    "        self.spectrogram_transforms = spectrogram_transforms\n",
    "        self.melspectrogram_parameters = melspectrogram_parameters\n",
    "        self.df_rms = pd.read_csv(PATH_FEAT)\n",
    "        self.sr_feat = 4\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_list)\n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "        wav_path, ebird_code = self.file_list[idx]\n",
    "\n",
    "        y, sr = sf.read(wav_path)\n",
    "        \n",
    "        if self.waveform_transforms:\n",
    "            y = self.waveform_transforms(y)\n",
    "        else:\n",
    "            len_y = len(y)\n",
    "            effective_length = sr * PERIOD\n",
    "            if len_y < effective_length:\n",
    "                new_y = np.zeros(effective_length, dtype=y.dtype)\n",
    "                start = np.random.randint(effective_length - len_y)\n",
    "                new_y[start:start + len_y] = y\n",
    "                y = new_y.astype(np.float32)\n",
    "            elif len_y > effective_length:\n",
    "                basename = os.path.basename(wav_path)\n",
    "                rms = self.df_rms.query('filename == @basename').librosa_rms.values\n",
    "                x_feat_sec = np.arange(0, len(rms))/self.sr_feat + 1/self.sr_feat\n",
    "                event_mask = rms > 1.3*np.median(rms)\n",
    "                \n",
    "                silent = ~any(event_mask)\n",
    "                if silent:\n",
    "                    # event を検出できなかったらランダムにクロップ\n",
    "                    start = np.random.randint(len_y - effective_length)\n",
    "                    y = y[start:start + effective_length].astype(np.float32)\n",
    "                else:\n",
    "                    choice = random.choice(x_feat_sec[event_mask])\n",
    "                    ed_sec = x_feat_sec[-1]\n",
    "                    st_range_sec = 2.5001\n",
    "                    ed_range_sec = ed_sec - 2.5001\n",
    "                    range_in = (st_range_sec <= choice) & (choice <= ed_range_sec)\n",
    "                    if range_in:\n",
    "                        idxs = np.arange(len_y)\n",
    "                        x_sec = idxs/sr\n",
    "                        mask = (choice - 2.5) < x_sec\n",
    "                        start = idxs[mask][0]\n",
    "                        y = y[start:start + effective_length].astype(np.float32)\n",
    "                    else:\n",
    "                        # ランダムにクロップ\n",
    "                        start = np.random.randint(len_y - effective_length)\n",
    "                        y = y[start:start + effective_length].astype(np.float32)\n",
    "                    \n",
    "                # ----\n",
    "            else:\n",
    "                y = y.astype(np.float32)\n",
    "\n",
    "        melspec = librosa.feature.melspectrogram(y, sr=sr, **self.melspectrogram_parameters)\n",
    "        melspec = librosa.power_to_db(melspec).astype(np.float32)\n",
    "\n",
    "        if self.spectrogram_transforms:\n",
    "            melspec = self.spectrogram_transforms(melspec)\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "        image = mono_to_color(melspec)\n",
    "        height, width, _ = image.shape\n",
    "        image = cv2.resize(image, (int(width * self.img_size / height), self.img_size))\n",
    "        image = np.moveaxis(image, 2, 0)\n",
    "        image = (image / 255.0).astype(np.float32)\n",
    "\n",
    "#         labels = np.zeros(len(BIRD_CODE), dtype=\"i\")\n",
    "        labels = np.zeros(len(BIRD_CODE), dtype=\"f\")\n",
    "        labels[BIRD_CODE[ebird_code]] = 1\n",
    "\n",
    "        return image, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpectrogramEventRmsDatasetV3(data.Dataset):\n",
    "    def __init__(self, file_list, img_size=224, \n",
    "                 waveform_transforms=None, spectrogram_transforms=None, melspectrogram_parameters={}):\n",
    "        \n",
    "        self.file_list = file_list  # list of list: [file_path, ebird_code]\n",
    "        self.img_size = img_size\n",
    "        self.waveform_transforms = waveform_transforms\n",
    "        self.spectrogram_transforms = spectrogram_transforms\n",
    "        self.melspectrogram_parameters = melspectrogram_parameters\n",
    "#         self.df_rms = pd.read_csv(PATH_FEAT)\n",
    "        self.df_event = pd.read_csv(PATH_EVENT)\n",
    "        self.sr_feat = 4\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_list)\n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "        wav_path, ebird_code = self.file_list[idx]\n",
    "\n",
    "        y, sr = sf.read(wav_path)\n",
    "        \n",
    "        if self.waveform_transforms:\n",
    "            y = self.waveform_transforms(y)\n",
    "        else:\n",
    "            len_y = len(y)\n",
    "            effective_length = sr * PERIOD\n",
    "            if len_y < effective_length:\n",
    "                new_y = np.zeros(effective_length, dtype=y.dtype)\n",
    "                start = np.random.randint(effective_length - len_y)\n",
    "                new_y[start:start + len_y] = y\n",
    "                y = new_y.astype(np.float32)\n",
    "            elif len_y > effective_length:\n",
    "                basename = os.path.basename(wav_path)\n",
    "                event_sec_list = self.df_event.query('filename == @basename').event_sec_list.to_list()[0]\n",
    "                event_sec_list = self.string_to_list(event_sec_list)\n",
    "                \n",
    "                # on event\n",
    "                if len(event_sec_list) != 0:\n",
    "                    choice = random.choice(event_sec_list)\n",
    "                    # 前から2.5秒、後ろから2.5秒の範囲におさまってるか(境界問題)\n",
    "                    ed_sec = len_y / sr\n",
    "                    st_range_sec = PERIOD/2 + 0.0001\n",
    "                    ed_range_sec = ed_sec - st_range_sec\n",
    "                    range_in = (st_range_sec <= choice) & (choice <= ed_range_sec)\n",
    "                    if range_in:\n",
    "                        start = int((choice - PERIOD/2) * sr)\n",
    "                        y = y[start:start + effective_length].astype(np.float32)\n",
    "                    else:\n",
    "                        # ランダムにクロップ\n",
    "                        start = np.random.randint(len_y - effective_length)\n",
    "                        y = y[start:start + effective_length].astype(np.float32)\n",
    "                # off event\n",
    "                else:\n",
    "                    # event を検出できなかったらランダムにクロップ\n",
    "                    start = np.random.randint(len_y - effective_length)\n",
    "                    y = y[start:start + effective_length].astype(np.float32)\n",
    "                    \n",
    "                # ----\n",
    "            else:\n",
    "                y = y.astype(np.float32)\n",
    "\n",
    "\n",
    "        melspec = librosa.feature.melspectrogram(y, sr=sr, **self.melspectrogram_parameters)\n",
    "        melspec = librosa.power_to_db(melspec).astype(np.float32)\n",
    "\n",
    "        if self.spectrogram_transforms:\n",
    "            melspec = self.spectrogram_transforms(melspec)\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "        image = mono_to_color(melspec)\n",
    "        height, width, _ = image.shape\n",
    "        image = cv2.resize(image, (int(width * self.img_size / height), self.img_size))\n",
    "        image = np.moveaxis(image, 2, 0)\n",
    "        image = (image / 255.0).astype(np.float32)\n",
    "\n",
    "#         labels = np.zeros(len(BIRD_CODE), dtype=\"i\")\n",
    "        labels = np.zeros(len(BIRD_CODE), dtype=\"f\")\n",
    "        labels[BIRD_CODE[ebird_code]] = 1\n",
    "\n",
    "        return image, labels\n",
    "    \n",
    "    def string_to_list(self, list_str):\n",
    "        for str_replace in ['\\n', '[', ']']:\n",
    "            list_str = list_str.replace(str_replace, '')\n",
    "\n",
    "        split = list_str.split(' ')\n",
    "        events_num = []\n",
    "        for text in split:\n",
    "            try:\n",
    "                num = np.float32(text)\n",
    "                events_num.append(num)\n",
    "            except:\n",
    "                pass\n",
    "        return events_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loaders_for_training(dataset_class, args_dataset, args_loader, train_file_list, valid_file_list):\n",
    "    # # make dataset\n",
    "    train_dataset = dataset_class(train_file_list, **args_dataset)\n",
    "    val_dataset = dataset_class(valid_file_list, **args_dataset)\n",
    "    # # make dataloader\n",
    "    train_loader = data.DataLoader(train_dataset, **args_loader[\"train\"])\n",
    "    valid_loader = data.DataLoader(val_dataset, **args_loader[\"val\"])\n",
    "    \n",
    "    return train_loader, valid_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[globals]\n",
      "{'seed': 1213, 'device': 'cuda', 'num_epochs': 45, 'output_dir': '/kaggle/training_output/', 'use_fold': 0, 'target_sr': 32000}\n",
      "[dataset]\n",
      "{'name': 'SpectrogramDataset', 'params': {'img_size': 224, 'melspectrogram_parameters': {'n_mels': 128, 'fmin': 20, 'fmax': 16000}}}\n",
      "[split]\n",
      "{'name': 'StratifiedKFold', 'params': {'n_splits': 5, 'random_state': 42, 'shuffle': True}}\n",
      "[loader]\n",
      "{'train': {'batch_size': 20, 'shuffle': True, 'num_workers': 5, 'pin_memory': True, 'drop_last': True}, 'val': {'batch_size': 15, 'shuffle': False, 'num_workers': 5, 'pin_memory': True, 'drop_last': False}}\n",
      "[model]\n",
      "{'name': 'resnest50_fast_1s1x64d', 'params': {'pretrained': True, 'n_classes': 264}}\n",
      "[loss]\n",
      "{'name': 'BCEWithLogitsLoss', 'params': {}}\n",
      "[optimizer]\n",
      "{'name': 'Adam', 'params': {'lr': 0.001}}\n",
      "[scheduler]\n",
      "{'name': 'CosineAnnealingLR', 'params': {'T_max': 10}}\n"
     ]
    }
   ],
   "source": [
    "settings = yaml.safe_load(settings_str)\n",
    "if DEBUG:\n",
    "    settings['split']['params']['n_splits'] = 2\n",
    "    settings['globals']['num_epochs'] = 3\n",
    "\n",
    "for k, v in settings.items():\n",
    "    print(\"[{}]\".format(k))\n",
    "    print(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "data path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = Path.cwd().parent\n",
    "input_ex_root = root / 'data_ignore/external_dataset' / DATASET\n",
    "train_resampled_audio_dirs = [input_ex_root / \"birdsong-resampled-train-audio-{:0>2}\"\n",
    "                              .format(i)  for i in range(5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('/home/user/Git/kaggle-Cornell-Birdcall-Identification/data_ignore/external_dataset/32khz/birdsong-resampled-train-audio-00'),\n",
       " PosixPath('/home/user/Git/kaggle-Cornell-Birdcall-Identification/data_ignore/external_dataset/32khz/birdsong-resampled-train-audio-01'),\n",
       " PosixPath('/home/user/Git/kaggle-Cornell-Birdcall-Identification/data_ignore/external_dataset/32khz/birdsong-resampled-train-audio-02'),\n",
       " PosixPath('/home/user/Git/kaggle-Cornell-Birdcall-Identification/data_ignore/external_dataset/32khz/birdsong-resampled-train-audio-03'),\n",
       " PosixPath('/home/user/Git/kaggle-Cornell-Birdcall-Identification/data_ignore/external_dataset/32khz/birdsong-resampled-train-audio-04')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_resampled_audio_dirs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(train_resampled_audio_dirs[0] / \"train_mod.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Execution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "train_all を作成  \n",
    "train_all: リサンプル後のファイルパスなどを追加"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21375, 38)\n",
      "(21375, 3)\n",
      "(21375, 39)\n"
     ]
    }
   ],
   "source": [
    "tmp_list = []\n",
    "for audio_d in train_resampled_audio_dirs:\n",
    "    if not audio_d.exists():\n",
    "        continue\n",
    "    for ebird_d in audio_d.iterdir():\n",
    "        if ebird_d.is_file():\n",
    "            continue\n",
    "        for i, wav_f in enumerate(ebird_d.iterdir()):\n",
    "            bool_n_splits = i==settings['split']['params']['n_splits']\n",
    "            if bool_n_splits and DEBUG: break  # if DEBUG=True: 1bird/n_splits file\n",
    "            tmp_list.append([ebird_d.name, wav_f.name, wav_f.as_posix()])\n",
    "            \n",
    "train_wav_path_exist = pd.DataFrame(\n",
    "    tmp_list, columns=[\"ebird_code\", \"resampled_filename\", \"file_path\"])\n",
    "\n",
    "del tmp_list\n",
    "\n",
    "train_all = pd.merge(\n",
    "    train, train_wav_path_exist, on=[\"ebird_code\", \"resampled_filename\"], how=\"inner\")\n",
    "\n",
    "if DEBUG: print('----- debug mode -----')\n",
    "print(train.shape)\n",
    "print(train_wav_path_exist.shape)\n",
    "print(train_all.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(**settings[\"split\"][\"params\"])\n",
    "\n",
    "train_all[\"fold\"] = -1\n",
    "for fold_id, (train_index, val_index) in enumerate(skf.split(train_all, train_all[\"ebird_code\"])):\n",
    "    train_all.iloc[val_index, -1] = fold_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[fold 0] train: 17057, val: 4318\n"
     ]
    }
   ],
   "source": [
    "use_fold = settings[\"globals\"][\"use_fold\"]\n",
    "idx_train = train_all['fold']!=use_fold\n",
    "idx_valid = train_all['fold']==use_fold\n",
    "train_file_list = train_all[idx_train][['file_path', 'ebird_code']].values.tolist()\n",
    "valid_file_list = train_all[idx_valid][['file_path', 'ebird_code']].values.tolist()\n",
    "\n",
    "print(\"[fold {}] train: {}, val: {}\".format(use_fold, len(train_file_list), len(valid_file_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21375"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_file_list)+len(valid_file_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(settings['globals']['seed'])\n",
    "device = torch.device(settings['globals']['device'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "**<font color='orange'> -------------------- settings ------------------ </font>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # get loader\n",
    "train_loader, valid_loader = get_loaders_for_training(\n",
    "    SpectrogramEventRmsDatasetV3,\n",
    "    settings[\"dataset\"][\"params\"], settings[\"loader\"], train_file_list, valid_file_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resnet18\n",
    "# model = models.resnet18(pretrained=True)\n",
    "# model.fc = nn.Linear(in_features=512, out_features=len(BIRD_CODE))\n",
    "\n",
    "# resnet34\n",
    "# model = models.resnet34(pretrained=True)\n",
    "# model.fc = nn.Linear(in_features=512, out_features=len(BIRD_CODE))\n",
    "\n",
    "# resnet50 のファインチューニング\n",
    "model = models.resnet50(pretrained=True)\n",
    "model.fc = nn.Linear(in_features=2048, out_features=len(BIRD_CODE))\n",
    "\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<font color='orange'> ------------------------------------------------ </font>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # get optimizer\n",
    "optimizer = getattr(\n",
    "        torch.optim, settings[\"optimizer\"][\"name\"]\n",
    "        )(model.parameters(), **settings[\"optimizer\"][\"params\"])\n",
    "\n",
    "# # # get scheduler\n",
    "scheduler = getattr(\n",
    "    torch.optim.lr_scheduler, settings[\"scheduler\"][\"name\"]\n",
    "    )(optimizer, **settings[\"scheduler\"][\"params\"])\n",
    "\n",
    "# # # get loss\n",
    "loss_func = getattr(nn, settings[\"loss\"][\"name\"])(**settings[\"loss\"][\"params\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, device, train_loader, optimizer, scheduler, loss_func):\n",
    "    model.train()\n",
    "    epoch_train_loss = 0\n",
    "    for batch_idx, (data, target) in enumerate(progress_bar(train_loader)):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = loss_func(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        epoch_train_loss += loss.item()*data.size(0)\n",
    "    loss = epoch_train_loss / len(train_loader.dataset)\n",
    "    del data\n",
    "    return loss\n",
    "\n",
    "class EarlyStopping:\n",
    "    \"\"\"\n",
    "    Early stops the training if validation loss doesn't improve after a given patience.\n",
    "    https://github.com/Bjarten/early-stopping-pytorch/blob/master/pytorchtools.py\n",
    "    \"\"\"\n",
    "    def __init__(self, patience=7, verbose=False, delta=0, path='checkpoint.pt', trace_func=print):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            patience (int): How long to wait after last time validation loss improved.\n",
    "                            Default: 7\n",
    "            verbose (bool): If True, prints a message for each validation loss improvement. \n",
    "                            Default: False\n",
    "            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n",
    "                            Default: 0\n",
    "            path (str): Path for the checkpoint to be saved to.\n",
    "                            Default: 'checkpoint.pt'\n",
    "            trace_func (function): trace print function.\n",
    "                            Default: print            \n",
    "        \"\"\"\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = np.Inf\n",
    "        self.delta = delta\n",
    "        self.path = path\n",
    "        self.trace_func = trace_func\n",
    "        self.best_state_dict = {}\n",
    "    def __call__(self, val_loss, model):\n",
    "\n",
    "        score = -val_loss\n",
    "\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            self.trace_func(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, val_loss, model):\n",
    "        '''Saves model when validation loss decrease.'''\n",
    "        if self.verbose:\n",
    "            self.trace_func(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
    "#         torch.save(model.state_dict(), self.path)\n",
    "        self.best_state_dict = model.state_dict()\n",
    "        self.val_loss_min = val_loss\n",
    "        \n",
    "def get_epoch_loss(model, device, valid_loder, loss_func):\n",
    "    model.eval()\n",
    "    epoch_valid_loss = 0\n",
    "    for batch_idx, (data, target) in enumerate(progress_bar(valid_loader)):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        output = model(data)\n",
    "        loss = loss_func(output, target)\n",
    "        epoch_valid_loss += loss.item()*data.size(0)\n",
    "    \n",
    "    loss = epoch_valid_loss / len(valid_loader.dataset)\n",
    "    del data\n",
    "    return loss\n",
    "\n",
    "def evaluate(model, device, valid_loder, loss_func):\n",
    "    model.eval()\n",
    "    epoch_valid_loss = 0\n",
    "    for batch_idx, (data, target) in enumerate(progress_bar(valid_loader)):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        output = model(data)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        loss = loss_func(output, target)\n",
    "        epoch_valid_loss += loss.item()*data.size(0)\n",
    "    \n",
    "    loss = epoch_valid_loss / len(valid_loader.dataset)\n",
    "    del data\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='45' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/45 00:00<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " epoch: 1 Sun Aug 16 11:44:58 2020\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='671' class='' max='852' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      78.76% [671/852 08:28<02:17]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "losses_train = []\n",
    "losses_valid = []\n",
    "epochs = []\n",
    "\n",
    "early_stopping = EarlyStopping(patience=7, verbose=True)\n",
    "n_epoch = settings['globals']['num_epochs']\n",
    "# n_epoch = 50\n",
    "for epoch in progress_bar(range(1, n_epoch+1)):\n",
    "    print(f'\\n epoch: {epoch} {time.ctime()}')\n",
    "    loss_train = train(model, device, train_loader, optimizer, scheduler, loss_func)\n",
    "    loss_valid = get_epoch_loss(model, device, valid_loader, loss_func)\n",
    "    print(f'loss_train: {loss_train}, loss_valid: {loss_valid}')\n",
    "    \n",
    "    epochs.append(epoch)\n",
    "    losses_train.append(loss_train)\n",
    "    losses_valid.append(loss_valid)\n",
    "    \n",
    "    early_stopping(loss_valid, model)\n",
    "\n",
    "    if early_stopping.early_stop:\n",
    "        print(\"Early stopping\")\n",
    "        break\n",
    "model.load_state_dict(early_stopping.best_state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(epochs, losses_train, '-x', label='train')\n",
    "plt.plot(epochs, losses_valid, '-x', label='valid')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del train_loader\n",
    "# del valid_loader\n",
    "# del model\n",
    "del optimizer\n",
    "del scheduler\n",
    "del loss_func\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = f'{DIR_MODEL}/nb{NB}_{model.__class__.__name__}/'\n",
    "file_dir = os.path.dirname(save_dir)\n",
    "if not os.path.exists(file_dir):\n",
    "    os.makedirs(file_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = f'{save_dir}model_{model.__class__.__name__}.pth'\n",
    "save_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DEBUG:\n",
    "    pass\n",
    "else:\n",
    "    torch.save(model.state_dict(), save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# check model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DEBUG:\n",
    "    pass\n",
    "else:\n",
    "    load_weights = torch.load(save_path)\n",
    "    model.load_state_dict(load_weights)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
