{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview\n",
    "- nb011でevent部分だけ抽出する **(1.3\\*med(rms)を閾値として**)ことをしてみたので、それを使ったデータローダーを作成する。\n",
    "- nb010のresnet18の学習で使ったデータローダーは以下の方法を取っていた\n",
    "    - 音ファイルをロード\n",
    "    - ランダムにスペクトログラムを5秒クリップ\n",
    "- 今回の手法は、\n",
    "    - 音ファイルをロード\n",
    "    - rmsが閾値を超えている部分(event音)を取得(下図の赤い点部分)\n",
    "    - event部分をランダムに選択(赤い点1つを選ぶ)\n",
    "    - 選択された部分前後0.25秒のスペクトログラムを取得\n",
    "    \n",
    "    ![event detection](../data/info/images/readme/013_event_rms.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CONST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "NB = '012'\n",
    "DEBUG = False\n",
    "PERIOD = 5\n",
    "DATASET = '32khz'\n",
    "PATH_FEAT = './../data_ignore/features/table/nb011_librosa_rms.csv'\n",
    "DIR_FEAT = './../data_ignore/features/table/'\n",
    "DIR_AUDIO = './../data_ignore/official/train_audio/'\n",
    "PATH_TRAIN_CSV = './../data_ignore/official/train.csv'\n",
    "sr_feat = int(1/0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "settings_str = \"\"\"\n",
    "globals:\n",
    "  seed: 1213\n",
    "  device: cuda\n",
    "  num_epochs: 50\n",
    "  output_dir: /kaggle/training_output/\n",
    "  use_fold: 0\n",
    "  target_sr: 32000\n",
    "\n",
    "dataset:\n",
    "  name: SpectrogramDataset\n",
    "  params:\n",
    "    img_size: 224\n",
    "    melspectrogram_parameters:\n",
    "      n_mels: 128\n",
    "      fmin: 20\n",
    "      fmax: 16000\n",
    "    \n",
    "split:\n",
    "  name: StratifiedKFold\n",
    "  params:\n",
    "    n_splits: 5\n",
    "    random_state: 42\n",
    "    shuffle: True\n",
    "\n",
    "loader:\n",
    "  train:\n",
    "    batch_size: 50\n",
    "    shuffle: True\n",
    "    num_workers: 5\n",
    "    pin_memory: True\n",
    "    drop_last: True\n",
    "  val:\n",
    "    batch_size: 50\n",
    "    shuffle: False\n",
    "    num_workers: 5\n",
    "    pin_memory: True\n",
    "    drop_last: False\n",
    "\n",
    "model:\n",
    "  name: resnest50_fast_1s1x64d\n",
    "  params:\n",
    "    pretrained: True\n",
    "    n_classes: 264\n",
    "\n",
    "loss:\n",
    "  name: BCEWithLogitsLoss\n",
    "  params: {}\n",
    "\n",
    "optimizer:\n",
    "  name: Adam\n",
    "  params:\n",
    "    lr: 0.001\n",
    "\n",
    "scheduler:\n",
    "  name: CosineAnnealingLR\n",
    "  params:\n",
    "    T_max: 10\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import every thing I need :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/librosa/util/decorators.py:9: NumbaDeprecationWarning: An import was requested from a module that has moved location.\n",
      "Import of 'jit' requested from: 'numba.decorators', please update to use 'numba.core.decorators' or pin to Numba version 0.48.0. This alias will not be present in Numba version 0.50.0.\n",
      "  from numba.decorators import jit as optional_jit\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import sys\n",
    "import yaml\n",
    "import random\n",
    "import librosa\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import soundfile as sf\n",
    "from pathlib import Path\n",
    "import IPython.display\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from fastprogress import progress_bar\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "import torch\n",
    "import torch.utils.data as data\n",
    "\n",
    "sys.path.insert(0, './../src/util/')\n",
    "from const import BIRD_CODE, INV_BIRD_CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# My function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed: int = 42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)  # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mono_to_color(X, mean=None, std=None, norm_max=None, norm_min=None, eps=1e-6):\n",
    "    # Stack X as [X,X,X]\n",
    "    X = np.stack([X, X, X], axis=-1)\n",
    "\n",
    "    # Standardize\n",
    "    mean = mean or X.mean()\n",
    "    X = X - mean\n",
    "    std = std or X.std()\n",
    "    Xstd = X / (std + eps)\n",
    "    _min, _max = Xstd.min(), Xstd.max()\n",
    "    norm_max = norm_max or _max\n",
    "    norm_min = norm_min or _min\n",
    "    if (_max - _min) > eps:\n",
    "        # Normalize to [0, 255]\n",
    "        V = Xstd\n",
    "        V[V < norm_min] = norm_min\n",
    "        V[V > norm_max] = norm_max\n",
    "        V = 255 * (V - norm_min) / (norm_max - norm_min)\n",
    "        V = V.astype(np.uint8)\n",
    "    else:\n",
    "        # Just zero\n",
    "        V = np.zeros_like(Xstd, dtype=np.uint8)\n",
    "    return V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpectrogramDataset(data.Dataset):\n",
    "    def __init__(self, file_list, img_size=224, \n",
    "                 waveform_transforms=None, spectrogram_transforms=None, melspectrogram_parameters={}):\n",
    "        \n",
    "        self.file_list = file_list  # list of list: [file_path, ebird_code]\n",
    "        self.img_size = img_size\n",
    "        self.waveform_transforms = waveform_transforms\n",
    "        self.spectrogram_transforms = spectrogram_transforms\n",
    "        self.melspectrogram_parameters = melspectrogram_parameters\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_list)\n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "        wav_path, ebird_code = self.file_list[idx]\n",
    "\n",
    "        y, sr = sf.read(wav_path)\n",
    "#         sr, y = wavfile.read(wav_path)\n",
    "\n",
    "        if self.waveform_transforms:\n",
    "            y = self.waveform_transforms(y)\n",
    "        else:\n",
    "            len_y = len(y)\n",
    "            effective_length = sr * PERIOD\n",
    "            if len_y < effective_length:\n",
    "                new_y = np.zeros(effective_length, dtype=y.dtype)\n",
    "                start = np.random.randint(effective_length - len_y)\n",
    "                new_y[start:start + len_y] = y\n",
    "                y = new_y.astype(np.float32)\n",
    "            elif len_y > effective_length:\n",
    "                start = np.random.randint(len_y - effective_length)\n",
    "                y = y[start:start + effective_length].astype(np.float32)\n",
    "            else:\n",
    "                y = y.astype(np.float32)\n",
    "\n",
    "        melspec = librosa.feature.melspectrogram(y, sr=sr, **self.melspectrogram_parameters)\n",
    "        melspec = librosa.power_to_db(melspec).astype(np.float32)\n",
    "\n",
    "        if self.spectrogram_transforms:\n",
    "            melspec = self.spectrogram_transforms(melspec)\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "        image = mono_to_color(melspec)\n",
    "        height, width, _ = image.shape\n",
    "        image = cv2.resize(image, (int(width * self.img_size / height), self.img_size))\n",
    "        image = np.moveaxis(image, 2, 0)\n",
    "        image = (image / 255.0).astype(np.float32)\n",
    "\n",
    "#         labels = np.zeros(len(BIRD_CODE), dtype=\"i\")\n",
    "        labels = np.zeros(len(BIRD_CODE), dtype=\"f\")\n",
    "        labels[BIRD_CODE[ebird_code]] = 1\n",
    "\n",
    "        return image, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loaders_for_training(dataset_class, args_dataset, args_loader, train_file_list, val_file_list):\n",
    "    # # make dataset\n",
    "    train_dataset = dataset_class(train_file_list, **args_dataset)\n",
    "    val_dataset = dataset_class(val_file_list, **args_dataset)\n",
    "    # # make dataloader\n",
    "    train_loader = data.DataLoader(train_dataset, **args_loader[\"train\"])\n",
    "    val_loader = data.DataLoader(val_dataset, **args_loader[\"val\"])\n",
    "    \n",
    "    return train_loader, val_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[globals]\n",
      "{'seed': 1213, 'device': 'cuda', 'num_epochs': 50, 'output_dir': '/kaggle/training_output/', 'use_fold': 0, 'target_sr': 32000}\n",
      "\n",
      "[dataset]\n",
      "{'name': 'SpectrogramDataset', 'params': {'img_size': 224, 'melspectrogram_parameters': {'n_mels': 128, 'fmin': 20, 'fmax': 16000}}}\n",
      "\n",
      "[split]\n",
      "{'name': 'StratifiedKFold', 'params': {'n_splits': 5, 'random_state': 42, 'shuffle': True}}\n",
      "\n",
      "[loader]\n",
      "{'train': {'batch_size': 50, 'shuffle': True, 'num_workers': 5, 'pin_memory': True, 'drop_last': True}, 'val': {'batch_size': 50, 'shuffle': False, 'num_workers': 5, 'pin_memory': True, 'drop_last': False}}\n",
      "\n",
      "[model]\n",
      "{'name': 'resnest50_fast_1s1x64d', 'params': {'pretrained': True, 'n_classes': 264}}\n",
      "\n",
      "[loss]\n",
      "{'name': 'BCEWithLogitsLoss', 'params': {}}\n",
      "\n",
      "[optimizer]\n",
      "{'name': 'Adam', 'params': {'lr': 0.001}}\n",
      "\n",
      "[scheduler]\n",
      "{'name': 'CosineAnnealingLR', 'params': {'T_max': 10}}\n"
     ]
    }
   ],
   "source": [
    "settings = yaml.safe_load(settings_str)\n",
    "for k, v in settings.items():\n",
    "    print('')\n",
    "    print(\"[{}]\".format(k))\n",
    "    print(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "data path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = Path.cwd().parent\n",
    "input_ex_root = root / 'data_ignore/external_dataset' / DATASET\n",
    "train_resampled_audio_dirs = [input_ex_root / \"birdsong-resampled-train-audio-{:0>2}\"\n",
    "                              .format(i)  for i in range(5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('/home/user/Git/kaggle-Cornell-Birdcall-Identification/data_ignore/external_dataset/32khz/birdsong-resampled-train-audio-00'),\n",
       " PosixPath('/home/user/Git/kaggle-Cornell-Birdcall-Identification/data_ignore/external_dataset/32khz/birdsong-resampled-train-audio-01'),\n",
       " PosixPath('/home/user/Git/kaggle-Cornell-Birdcall-Identification/data_ignore/external_dataset/32khz/birdsong-resampled-train-audio-02'),\n",
       " PosixPath('/home/user/Git/kaggle-Cornell-Birdcall-Identification/data_ignore/external_dataset/32khz/birdsong-resampled-train-audio-03'),\n",
       " PosixPath('/home/user/Git/kaggle-Cornell-Birdcall-Identification/data_ignore/external_dataset/32khz/birdsong-resampled-train-audio-04')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_resampled_audio_dirs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(train_resampled_audio_dirs[0] / \"train_mod.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "train_all を作成  \n",
    "train_all: リサンプル後のファイルパスなどを追加"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21375, 38)\n",
      "(21375, 3)\n",
      "(21375, 39)\n"
     ]
    }
   ],
   "source": [
    "tmp_list = []\n",
    "for audio_d in train_resampled_audio_dirs:\n",
    "    if not audio_d.exists():\n",
    "        continue\n",
    "    for ebird_d in audio_d.iterdir():\n",
    "        if ebird_d.is_file():\n",
    "            continue\n",
    "        for wav_f in ebird_d.iterdir():\n",
    "            tmp_list.append([ebird_d.name, wav_f.name, wav_f.as_posix()])\n",
    "            \n",
    "train_wav_path_exist = pd.DataFrame(\n",
    "    tmp_list, columns=[\"ebird_code\", \"resampled_filename\", \"file_path\"])\n",
    "\n",
    "del tmp_list\n",
    "\n",
    "train_all = pd.merge(\n",
    "    train, train_wav_path_exist, on=[\"ebird_code\", \"resampled_filename\"], how=\"inner\")\n",
    "\n",
    "print(train.shape)\n",
    "print(train_wav_path_exist.shape)\n",
    "print(train_all.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(**settings[\"split\"][\"params\"])\n",
    "\n",
    "train_all[\"fold\"] = -1\n",
    "for fold_id, (train_index, val_index) in enumerate(skf.split(train_all, train_all[\"ebird_code\"])):\n",
    "    train_all.iloc[val_index, -1] = fold_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[fold 0] train: 17057, val: 4318\n"
     ]
    }
   ],
   "source": [
    "use_fold = settings[\"globals\"][\"use_fold\"]\n",
    "idx_train = train_all['fold']!=use_fold\n",
    "idx_valid = train_all['fold']==use_fold\n",
    "train_file_list = train_all[idx_train][['file_path', 'ebird_code']].values.tolist()\n",
    "valid_file_list = train_all[idx_valid][['file_path', 'ebird_code']].values.tolist()\n",
    "\n",
    "print(\"[fold {}] train: {}, val: {}\".format(use_fold, len(train_file_list), len(valid_file_list)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpectrogramEventRmsDataset(data.Dataset):\n",
    "    def __init__(self, file_list, img_size=224, \n",
    "                 waveform_transforms=None, spectrogram_transforms=None, melspectrogram_parameters={}):\n",
    "        \n",
    "        self.file_list = file_list  # list of list: [file_path, ebird_code]\n",
    "        self.img_size = img_size\n",
    "        self.waveform_transforms = waveform_transforms\n",
    "        self.spectrogram_transforms = spectrogram_transforms\n",
    "        self.melspectrogram_parameters = melspectrogram_parameters\n",
    "        self.df_rms = pd.read_csv(PATH_FEAT)\n",
    "        self.sr_feat = 4\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_list)\n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "        wav_path, ebird_code = self.file_list[idx]\n",
    "\n",
    "        y, sr = sf.read(wav_path)\n",
    "        \n",
    "        if self.waveform_transforms:\n",
    "            y = self.waveform_transforms(y)\n",
    "        else:\n",
    "            len_y = len(y)\n",
    "            effective_length = sr * PERIOD\n",
    "            if len_y < effective_length:\n",
    "                new_y = np.zeros(effective_length, dtype=y.dtype)\n",
    "                start = np.random.randint(effective_length - len_y)\n",
    "                new_y[start:start + len_y] = y\n",
    "                y = new_y.astype(np.float32)\n",
    "            elif len_y > effective_length:\n",
    "                basename = os.path.basename(wav_path)\n",
    "                rms = self.df_rms.query('filename == @basename').librosa_rms.values\n",
    "                x_feat_sec = np.arange(0, len(rms))/self.sr_feat + 1/self.sr_feat\n",
    "                event_mask = rms > 1.3*np.median(rms)\n",
    "                \n",
    "                silent = ~any(event_mask)\n",
    "                if silent:\n",
    "                    # event を検出できなかったらランダムにクロップ\n",
    "                    start = np.random.randint(len_y - effective_length)\n",
    "                    y = y[start:start + effective_length].astype(np.float32)\n",
    "                else:\n",
    "                    choice = random.choice(x_feat_sec[event_mask])\n",
    "                    ed_sec = x_feat_sec[-1]\n",
    "                    st_range_sec = 2.5001\n",
    "                    ed_range_sec = ed_sec - 2.5001\n",
    "                    range_in = (st_range_sec <= choice) & (choice <= ed_range_sec)\n",
    "                    if range_in:\n",
    "                        idxs = np.arange(len_y)\n",
    "                        x_sec = idxs/sr\n",
    "                        mask = (choice - 2.5) < x_sec\n",
    "                        start = idxs[mask][0]\n",
    "                        y = y[start:start + effective_length].astype(np.float32)\n",
    "                    else:\n",
    "                        # ランダムにクロップ\n",
    "                        start = np.random.randint(len_y - effective_length)\n",
    "                        y = y[start:start + effective_length].astype(np.float32)\n",
    "                    \n",
    "                # ----\n",
    "            else:\n",
    "                y = y.astype(np.float32)\n",
    "\n",
    "        melspec = librosa.feature.melspectrogram(y, sr=sr, **self.melspectrogram_parameters)\n",
    "        melspec = librosa.power_to_db(melspec).astype(np.float32)\n",
    "\n",
    "        if self.spectrogram_transforms:\n",
    "            melspec = self.spectrogram_transforms(melspec)\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "        image = mono_to_color(melspec)\n",
    "        height, width, _ = image.shape\n",
    "        image = cv2.resize(image, (int(width * self.img_size / height), self.img_size))\n",
    "        image = np.moveaxis(image, 2, 0)\n",
    "        image = (image / 255.0).astype(np.float32)\n",
    "\n",
    "#         labels = np.zeros(len(BIRD_CODE), dtype=\"i\")\n",
    "        labels = np.zeros(len(BIRD_CODE), dtype=\"f\")\n",
    "        labels[BIRD_CODE[ebird_code]] = 1\n",
    "\n",
    "        return image, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 計測"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset で比較する"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "SpectrogramEventRmsDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = SpectrogramEventRmsDataset(train_file_list, **settings['dataset']['params'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='17057' class='' max='17057' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [17057/17057 49:50<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2h 17min 12s, sys: 2h 45min 25s, total: 5h 2min 38s\n",
      "Wall time: 49min 50s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for i in progress_bar(range(len(train_dataset))):\n",
    "    _ = train_dataset.__getitem__(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "SpectrogramDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "_train_dataset = SpectrogramDataset(train_file_list, **settings['dataset']['params'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='17057' class='' max='17057' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [17057/17057 14:28<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1h 9min 22s, sys: 1h 40min 33s, total: 2h 49min 56s\n",
      "Wall time: 14min 28s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for i in progress_bar(range(len(_train_dataset))):\n",
    "    _ = _train_dataset.__getitem__(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
