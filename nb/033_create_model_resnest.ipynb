{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overvew\n",
    "\n",
    "- nb029の改良\n",
    "- schedulerの更新位置がおかしかったので変更"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CONST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "NB = '033'\n",
    "DEBUG = False\n",
    "PERIOD = 5\n",
    "# PATH_EVENT = './../data_ignore/event/nb017_event_rms/nb017_event_rms.csv'\n",
    "DATASET = '32khz'\n",
    "DIR_MODEL = './../data_ignore/model'\n",
    "PATH_MODEL = './../data_ignore/model/resnest50/resnest50_fast_1s1x64d-d8fbf808.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "settings_str = \"\"\"\n",
    "globals:\n",
    "  seed: 1213\n",
    "  device: cuda\n",
    "  num_epochs: 45\n",
    "  output_dir: /kaggle/training_output/\n",
    "  use_fold: 0\n",
    "  target_sr: 32000\n",
    "\n",
    "dataset:\n",
    "  name: SpectrogramDataset\n",
    "  params:\n",
    "    img_size: 224\n",
    "    melspectrogram_parameters:\n",
    "      n_mels: 128\n",
    "      fmin: 20\n",
    "      fmax: 16000\n",
    "    \n",
    "split:\n",
    "  name: StratifiedKFold\n",
    "  params:\n",
    "    n_splits: 5\n",
    "    random_state: 42\n",
    "    shuffle: True\n",
    "\n",
    "loader:\n",
    "  train:\n",
    "    batch_size: 50\n",
    "    shuffle: True\n",
    "    num_workers: 10\n",
    "    pin_memory: True\n",
    "    drop_last: True\n",
    "  val:\n",
    "    batch_size: 50\n",
    "    shuffle: False\n",
    "    num_workers: 10\n",
    "    pin_memory: True\n",
    "    drop_last: False\n",
    "\n",
    "model:\n",
    "  name: resnest50_fast_1s1x64d\n",
    "  params:\n",
    "    pretrained: True\n",
    "    n_classes: 264\n",
    "\n",
    "loss:\n",
    "  name: BCEWithLogitsLoss\n",
    "  params: {}\n",
    "\n",
    "optimizer:\n",
    "  name: Adam\n",
    "  params:\n",
    "    lr: 0.001\n",
    "\n",
    "scheduler:\n",
    "  name: CosineAnnealingLR\n",
    "  params:\n",
    "    T_max: 10\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import everything I need :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import typing as tp\n",
    "import logging\n",
    "import cv2 \n",
    "import warnings\n",
    "import math\n",
    "import time\n",
    "import yaml\n",
    "import random\n",
    "import librosa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import soundfile as sf\n",
    "from pathlib import Path\n",
    "from scipy.io import wavfile\n",
    "import matplotlib.pyplot as plt\n",
    "from fastprogress import progress_bar\n",
    "from contextlib import contextmanager\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "# from torchvision import models\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data\n",
    "import resnest.torch as resnest_torch\n",
    "from torch.nn import Conv2d, Module, Linear, BatchNorm2d, ReLU\n",
    "from torch.nn.modules.utils import _pair\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, './../src/util/')\n",
    "from const import BIRD_CODE, INV_BIRD_CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# My function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed: int = 42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)  # type: ignore\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mono_to_color(X, mean=None, std=None, norm_max=None, norm_min=None, eps=1e-6):\n",
    "    # Stack X as [X,X,X]\n",
    "    X = np.stack([X, X, X], axis=-1)\n",
    "\n",
    "    # Standardize\n",
    "    mean = mean or X.mean()\n",
    "    X = X - mean\n",
    "    std = std or X.std()\n",
    "    Xstd = X / (std + eps)\n",
    "    _min, _max = Xstd.min(), Xstd.max()\n",
    "    norm_max = norm_max or _max\n",
    "    norm_min = norm_min or _min\n",
    "    if (_max - _min) > eps:\n",
    "        # Normalize to [0, 255]\n",
    "        V = Xstd\n",
    "        V[V < norm_min] = norm_min\n",
    "        V[V > norm_max] = norm_max\n",
    "        V = 255 * (V - norm_min) / (norm_max - norm_min)\n",
    "        V = V.astype(np.uint8)\n",
    "    else:\n",
    "        # Just zero\n",
    "        V = np.zeros_like(Xstd, dtype=np.uint8)\n",
    "    return V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpectrogramDataset(data.Dataset):\n",
    "    def __init__(self, file_list, img_size=224, \n",
    "                 waveform_transforms=None, spectrogram_transforms=None, melspectrogram_parameters={}):\n",
    "        \n",
    "        self.file_list = file_list  # list of list: [file_path, ebird_code]\n",
    "        self.img_size = img_size\n",
    "        self.waveform_transforms = waveform_transforms\n",
    "        self.spectrogram_transforms = spectrogram_transforms\n",
    "        self.melspectrogram_parameters = melspectrogram_parameters\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_list)\n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "        wav_path, ebird_code = self.file_list[idx]\n",
    "\n",
    "        y, sr = sf.read(wav_path)\n",
    "#         sr, y = wavfile.read(wav_path)\n",
    "\n",
    "        if self.waveform_transforms:\n",
    "            y = self.waveform_transforms(y)\n",
    "        else:\n",
    "            len_y = len(y)\n",
    "            effective_length = sr * PERIOD\n",
    "            if len_y < effective_length:\n",
    "                new_y = np.zeros(effective_length, dtype=y.dtype)\n",
    "                start = np.random.randint(effective_length - len_y)\n",
    "                new_y[start:start + len_y] = y\n",
    "                y = new_y.astype(np.float32)\n",
    "            elif len_y > effective_length:\n",
    "                start = np.random.randint(len_y - effective_length)\n",
    "                y = y[start:start + effective_length].astype(np.float32)\n",
    "            else:\n",
    "                y = y.astype(np.float32)\n",
    "\n",
    "        melspec = librosa.feature.melspectrogram(y, sr=sr, **self.melspectrogram_parameters)\n",
    "        melspec = librosa.power_to_db(melspec).astype(np.float32)\n",
    "\n",
    "        if self.spectrogram_transforms:\n",
    "            melspec = self.spectrogram_transforms(melspec)\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "        image = mono_to_color(melspec)\n",
    "        height, width, _ = image.shape\n",
    "        image = cv2.resize(image, (int(width * self.img_size / height), self.img_size))\n",
    "        image = np.moveaxis(image, 2, 0)\n",
    "        image = (image / 255.0).astype(np.float32)\n",
    "\n",
    "#         labels = np.zeros(len(BIRD_CODE), dtype=\"i\")\n",
    "        labels = np.zeros(len(BIRD_CODE), dtype=\"f\")\n",
    "        labels[BIRD_CODE[ebird_code]] = 1\n",
    "\n",
    "        return image, labels\n",
    "\n",
    "class SpectrogramEventRmsDataset(data.Dataset):\n",
    "    def __init__(self, file_list, img_size=224, \n",
    "                 waveform_transforms=None, spectrogram_transforms=None, melspectrogram_parameters={}):\n",
    "        \n",
    "        self.file_list = file_list  # list of list: [file_path, ebird_code]\n",
    "        self.img_size = img_size\n",
    "        self.waveform_transforms = waveform_transforms\n",
    "        self.spectrogram_transforms = spectrogram_transforms\n",
    "        self.melspectrogram_parameters = melspectrogram_parameters\n",
    "        self.df_rms = pd.read_csv(PATH_FEAT)\n",
    "        self.sr_feat = 4\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_list)\n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "        wav_path, ebird_code = self.file_list[idx]\n",
    "\n",
    "        y, sr = sf.read(wav_path)\n",
    "        \n",
    "        if self.waveform_transforms:\n",
    "            y = self.waveform_transforms(y)\n",
    "        else:\n",
    "            len_y = len(y)\n",
    "            effective_length = sr * PERIOD\n",
    "            if len_y < effective_length:\n",
    "                new_y = np.zeros(effective_length, dtype=y.dtype)\n",
    "                start = np.random.randint(effective_length - len_y)\n",
    "                new_y[start:start + len_y] = y\n",
    "                y = new_y.astype(np.float32)\n",
    "            elif len_y > effective_length:\n",
    "                basename = os.path.basename(wav_path)\n",
    "                rms = self.df_rms.query('filename == @basename').librosa_rms.values\n",
    "                x_feat_sec = np.arange(0, len(rms))/self.sr_feat + 1/self.sr_feat\n",
    "                event_mask = rms > 1.3*np.median(rms)\n",
    "                \n",
    "                silent = ~any(event_mask)\n",
    "                if silent:\n",
    "                    # event を検出できなかったらランダムにクロップ\n",
    "                    start = np.random.randint(len_y - effective_length)\n",
    "                    y = y[start:start + effective_length].astype(np.float32)\n",
    "                else:\n",
    "                    choice = random.choice(x_feat_sec[event_mask])\n",
    "                    ed_sec = x_feat_sec[-1]\n",
    "                    st_range_sec = 2.5001\n",
    "                    ed_range_sec = ed_sec - 2.5001\n",
    "                    range_in = (st_range_sec <= choice) & (choice <= ed_range_sec)\n",
    "                    if range_in:\n",
    "                        idxs = np.arange(len_y)\n",
    "                        x_sec = idxs/sr\n",
    "                        mask = (choice - 2.5) < x_sec\n",
    "                        start = idxs[mask][0]\n",
    "                        y = y[start:start + effective_length].astype(np.float32)\n",
    "                    else:\n",
    "                        # ランダムにクロップ\n",
    "                        start = np.random.randint(len_y - effective_length)\n",
    "                        y = y[start:start + effective_length].astype(np.float32)\n",
    "                    \n",
    "                # ----\n",
    "            else:\n",
    "                y = y.astype(np.float32)\n",
    "\n",
    "        melspec = librosa.feature.melspectrogram(y, sr=sr, **self.melspectrogram_parameters)\n",
    "        melspec = librosa.power_to_db(melspec).astype(np.float32)\n",
    "\n",
    "        if self.spectrogram_transforms:\n",
    "            melspec = self.spectrogram_transforms(melspec)\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "        image = mono_to_color(melspec)\n",
    "        height, width, _ = image.shape\n",
    "        image = cv2.resize(image, (int(width * self.img_size / height), self.img_size))\n",
    "        image = np.moveaxis(image, 2, 0)\n",
    "        image = (image / 255.0).astype(np.float32)\n",
    "\n",
    "#         labels = np.zeros(len(BIRD_CODE), dtype=\"i\")\n",
    "        labels = np.zeros(len(BIRD_CODE), dtype=\"f\")\n",
    "        labels[BIRD_CODE[ebird_code]] = 1\n",
    "\n",
    "        return image, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpectrogramEventRmsDatasetV3(data.Dataset):\n",
    "    def __init__(self, file_list, img_size=224, \n",
    "                 waveform_transforms=None, spectrogram_transforms=None, melspectrogram_parameters={}):\n",
    "        \n",
    "        self.file_list = file_list  # list of list: [file_path, ebird_code]\n",
    "        self.img_size = img_size\n",
    "        self.waveform_transforms = waveform_transforms\n",
    "        self.spectrogram_transforms = spectrogram_transforms\n",
    "        self.melspectrogram_parameters = melspectrogram_parameters\n",
    "#         self.df_rms = pd.read_csv(PATH_FEAT)\n",
    "        self.df_event = pd.read_csv(PATH_EVENT)\n",
    "        self.sr_feat = 4\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_list)\n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "        wav_path, ebird_code = self.file_list[idx]\n",
    "\n",
    "        y, sr = sf.read(wav_path)\n",
    "        \n",
    "        if self.waveform_transforms:\n",
    "            y = self.waveform_transforms(y)\n",
    "        else:\n",
    "            len_y = len(y)\n",
    "            effective_length = sr * PERIOD\n",
    "            if len_y < effective_length:\n",
    "                new_y = np.zeros(effective_length, dtype=y.dtype)\n",
    "                start = np.random.randint(effective_length - len_y)\n",
    "                new_y[start:start + len_y] = y\n",
    "                y = new_y.astype(np.float32)\n",
    "            elif len_y > effective_length:\n",
    "                basename = os.path.basename(wav_path)\n",
    "                event_sec_list = self.df_event.query('filename == @basename').event_sec_list.to_list()[0]\n",
    "                event_sec_list = self.string_to_list(event_sec_list)\n",
    "                \n",
    "                # on event\n",
    "                if len(event_sec_list) != 0:\n",
    "                    choice = random.choice(event_sec_list)\n",
    "                    # 前から2.5秒、後ろから2.5秒の範囲におさまってるか(境界問題)\n",
    "                    ed_sec = len_y / sr\n",
    "                    st_range_sec = PERIOD/2 + 0.0001\n",
    "                    ed_range_sec = ed_sec - st_range_sec\n",
    "                    range_in = (st_range_sec <= choice) & (choice <= ed_range_sec)\n",
    "                    if range_in:\n",
    "                        start = int((choice - PERIOD/2) * sr)\n",
    "                        y = y[start:start + effective_length].astype(np.float32)\n",
    "                    else:\n",
    "                        # ランダムにクロップ\n",
    "                        start = np.random.randint(len_y - effective_length)\n",
    "                        y = y[start:start + effective_length].astype(np.float32)\n",
    "                # off event\n",
    "                else:\n",
    "                    # event を検出できなかったらランダムにクロップ\n",
    "                    start = np.random.randint(len_y - effective_length)\n",
    "                    y = y[start:start + effective_length].astype(np.float32)\n",
    "                    \n",
    "                # ----\n",
    "            else:\n",
    "                y = y.astype(np.float32)\n",
    "\n",
    "\n",
    "        melspec = librosa.feature.melspectrogram(y, sr=sr, **self.melspectrogram_parameters)\n",
    "        melspec = librosa.power_to_db(melspec).astype(np.float32)\n",
    "\n",
    "        if self.spectrogram_transforms:\n",
    "            melspec = self.spectrogram_transforms(melspec)\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "        image = mono_to_color(melspec)\n",
    "        height, width, _ = image.shape\n",
    "        image = cv2.resize(image, (int(width * self.img_size / height), self.img_size))\n",
    "        image = np.moveaxis(image, 2, 0)\n",
    "        image = (image / 255.0).astype(np.float32)\n",
    "\n",
    "#         labels = np.zeros(len(BIRD_CODE), dtype=\"i\")\n",
    "        labels = np.zeros(len(BIRD_CODE), dtype=\"f\")\n",
    "        labels[BIRD_CODE[ebird_code]] = 1\n",
    "\n",
    "        return image, labels\n",
    "    \n",
    "    def string_to_list(self, list_str):\n",
    "        for str_replace in ['\\n', '[', ']']:\n",
    "            list_str = list_str.replace(str_replace, '')\n",
    "\n",
    "        split = list_str.split(' ')\n",
    "        events_num = []\n",
    "        for text in split:\n",
    "            try:\n",
    "                num = np.float32(text)\n",
    "                events_num.append(num)\n",
    "            except:\n",
    "                pass\n",
    "        return events_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loaders_for_training(dataset_class, args_dataset, args_loader, train_file_list, valid_file_list):\n",
    "    # # make dataset\n",
    "    train_dataset = dataset_class(train_file_list, **args_dataset)\n",
    "    val_dataset = dataset_class(valid_file_list, **args_dataset)\n",
    "    # # make dataloader\n",
    "    train_loader = data.DataLoader(train_dataset, **args_loader[\"train\"])\n",
    "    valid_loader = data.DataLoader(val_dataset, **args_loader[\"val\"])\n",
    "    \n",
    "    return train_loader, valid_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SplAtConv2d(Module):\n",
    "    \"\"\"Split-Attention Conv2d\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, channels, kernel_size, stride=(1, 1), padding=(0, 0),\n",
    "                 dilation=(1, 1), groups=1, bias=True,\n",
    "                 radix=2, reduction_factor=4,\n",
    "                 rectify=False, rectify_avg=False, norm_layer=None,\n",
    "                 dropblock_prob=0.0, **kwargs):\n",
    "        super(SplAtConv2d, self).__init__()\n",
    "        padding = _pair(padding)\n",
    "        self.rectify = rectify and (padding[0] > 0 or padding[1] > 0)\n",
    "        self.rectify_avg = rectify_avg\n",
    "        inter_channels = max(in_channels*radix//reduction_factor, 32)\n",
    "        self.radix = radix\n",
    "        self.cardinality = groups\n",
    "        self.channels = channels\n",
    "        self.dropblock_prob = dropblock_prob\n",
    "        if self.rectify:\n",
    "            from rfconv import RFConv2d\n",
    "            self.conv = RFConv2d(in_channels, channels*radix, kernel_size, stride, padding, dilation,\n",
    "                                 groups=groups*radix, bias=bias, average_mode=rectify_avg, **kwargs)\n",
    "        else:\n",
    "            self.conv = Conv2d(in_channels, channels*radix, kernel_size, stride, padding, dilation,\n",
    "                               groups=groups*radix, bias=bias, **kwargs)\n",
    "        self.use_bn = norm_layer is not None\n",
    "        if self.use_bn:\n",
    "            self.bn0 = norm_layer(channels*radix)\n",
    "        self.relu = ReLU(inplace=True)\n",
    "        self.fc1 = Conv2d(channels, inter_channels, 1, groups=self.cardinality)\n",
    "        if self.use_bn:\n",
    "            self.bn1 = norm_layer(inter_channels)\n",
    "        self.fc2 = Conv2d(inter_channels, channels*radix, 1, groups=self.cardinality)\n",
    "        if dropblock_prob > 0.0:\n",
    "            self.dropblock = DropBlock2D(dropblock_prob, 3)\n",
    "        self.rsoftmax = rSoftMax(radix, groups)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        if self.use_bn:\n",
    "            x = self.bn0(x)\n",
    "        if self.dropblock_prob > 0.0:\n",
    "            x = self.dropblock(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        batch, rchannel = x.shape[:2]\n",
    "        if self.radix > 1:\n",
    "            if torch.__version__ < '1.5':\n",
    "                splited = torch.split(x, int(rchannel//self.radix), dim=1)\n",
    "            else:\n",
    "                splited = torch.split(x, rchannel//self.radix, dim=1)\n",
    "            gap = sum(splited) \n",
    "        else:\n",
    "            gap = x\n",
    "        gap = F.adaptive_avg_pool2d(gap, 1)\n",
    "        gap = self.fc1(gap)\n",
    "\n",
    "        if self.use_bn:\n",
    "            gap = self.bn1(gap)\n",
    "        gap = self.relu(gap)\n",
    "\n",
    "        atten = self.fc2(gap)\n",
    "        atten = self.rsoftmax(atten).view(batch, -1, 1, 1)\n",
    "\n",
    "        if self.radix > 1:\n",
    "            if torch.__version__ < '1.5':\n",
    "                attens = torch.split(atten, int(rchannel//self.radix), dim=1)\n",
    "            else:\n",
    "                attens = torch.split(atten, rchannel//self.radix, dim=1)\n",
    "            out = sum([att*split for (att, split) in zip(attens, splited)])\n",
    "        else:\n",
    "            out = atten * x\n",
    "        return out.contiguous()\n",
    "\n",
    "class rSoftMax(nn.Module):\n",
    "    def __init__(self, radix, cardinality):\n",
    "        super().__init__()\n",
    "        self.radix = radix\n",
    "        self.cardinality = cardinality\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch = x.size(0)\n",
    "        if self.radix > 1:\n",
    "            x = x.view(batch, self.cardinality, self.radix, -1).transpose(1, 2)\n",
    "            x = F.softmax(x, dim=1)\n",
    "            x = x.reshape(batch, -1)\n",
    "        else:\n",
    "            x = torch.sigmoid(x)\n",
    "        return x\n",
    "class DropBlock2D(object):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        raise NotImplementedError\n",
    "\n",
    "class GlobalAvgPool2d(nn.Module):\n",
    "    def __init__(self):\n",
    "        \"\"\"Global average pooling over the input's spatial dimensions\"\"\"\n",
    "        super(GlobalAvgPool2d, self).__init__()\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        return nn.functional.adaptive_avg_pool2d(inputs, 1).view(inputs.size(0), -1)\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    \"\"\"ResNet Bottleneck\n",
    "    \"\"\"\n",
    "    # pylint: disable=unused-argument\n",
    "    expansion = 4\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None,\n",
    "                 radix=1, cardinality=1, bottleneck_width=64,\n",
    "                 avd=False, avd_first=False, dilation=1, is_first=False,\n",
    "                 rectified_conv=False, rectify_avg=False,\n",
    "                 norm_layer=None, dropblock_prob=0.0, last_gamma=False):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        group_width = int(planes * (bottleneck_width / 64.)) * cardinality\n",
    "        self.conv1 = nn.Conv2d(inplanes, group_width, kernel_size=1, bias=False)\n",
    "        self.bn1 = norm_layer(group_width)\n",
    "        self.dropblock_prob = dropblock_prob\n",
    "        self.radix = radix\n",
    "        self.avd = avd and (stride > 1 or is_first)\n",
    "        self.avd_first = avd_first\n",
    "\n",
    "        if self.avd:\n",
    "            self.avd_layer = nn.AvgPool2d(3, stride, padding=1)\n",
    "            stride = 1\n",
    "\n",
    "        if dropblock_prob > 0.0:\n",
    "            self.dropblock1 = DropBlock2D(dropblock_prob, 3)\n",
    "            if radix == 1:\n",
    "                self.dropblock2 = DropBlock2D(dropblock_prob, 3)\n",
    "            self.dropblock3 = DropBlock2D(dropblock_prob, 3)\n",
    "\n",
    "        if radix >= 1:\n",
    "            self.conv2 = SplAtConv2d(\n",
    "                group_width, group_width, kernel_size=3,\n",
    "                stride=stride, padding=dilation,\n",
    "                dilation=dilation, groups=cardinality, bias=False,\n",
    "                radix=radix, rectify=rectified_conv,\n",
    "                rectify_avg=rectify_avg,\n",
    "                norm_layer=norm_layer,\n",
    "                dropblock_prob=dropblock_prob)\n",
    "        elif rectified_conv:\n",
    "            from rfconv import RFConv2d\n",
    "            self.conv2 = RFConv2d(\n",
    "                group_width, group_width, kernel_size=3, stride=stride,\n",
    "                padding=dilation, dilation=dilation,\n",
    "                groups=cardinality, bias=False,\n",
    "                average_mode=rectify_avg)\n",
    "            self.bn2 = norm_layer(group_width)\n",
    "        else:\n",
    "            self.conv2 = nn.Conv2d(\n",
    "                group_width, group_width, kernel_size=3, stride=stride,\n",
    "                padding=dilation, dilation=dilation,\n",
    "                groups=cardinality, bias=False)\n",
    "            self.bn2 = norm_layer(group_width)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(\n",
    "            group_width, planes * 4, kernel_size=1, bias=False)\n",
    "        self.bn3 = norm_layer(planes*4)\n",
    "\n",
    "        if last_gamma:\n",
    "            from torch.nn.init import zeros_\n",
    "            zeros_(self.bn3.weight)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.downsample = downsample\n",
    "        self.dilation = dilation\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        if self.dropblock_prob > 0.0:\n",
    "            out = self.dropblock1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        if self.avd and self.avd_first:\n",
    "            out = self.avd_layer(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        if self.radix == 0:\n",
    "            out = self.bn2(out)\n",
    "            if self.dropblock_prob > 0.0:\n",
    "                out = self.dropblock2(out)\n",
    "            out = self.relu(out)\n",
    "\n",
    "        if self.avd and not self.avd_first:\n",
    "            out = self.avd_layer(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "        if self.dropblock_prob > 0.0:\n",
    "            out = self.dropblock3(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    \"\"\"ResNet Variants\n",
    "    Parameters\n",
    "    ----------\n",
    "    block : Block\n",
    "        Class for the residual block. Options are BasicBlockV1, BottleneckV1.\n",
    "    layers : list of int\n",
    "        Numbers of layers in each block\n",
    "    classes : int, default 1000\n",
    "        Number of classification classes.\n",
    "    dilated : bool, default False\n",
    "        Applying dilation strategy to pretrained ResNet yielding a stride-8 model,\n",
    "        typically used in Semantic Segmentation.\n",
    "    norm_layer : object\n",
    "        Normalization layer used in backbone network (default: :class:`mxnet.gluon.nn.BatchNorm`;\n",
    "        for Synchronized Cross-GPU BachNormalization).\n",
    "    Reference:\n",
    "        - He, Kaiming, et al. \"Deep residual learning for image recognition.\" Proceedings of the IEEE conference on computer vision and pattern recognition. 2016.\n",
    "        - Yu, Fisher, and Vladlen Koltun. \"Multi-scale context aggregation by dilated convolutions.\"\n",
    "    \"\"\"\n",
    "    # pylint: disable=unused-variable\n",
    "    def __init__(self, block, layers, radix=1, groups=1, bottleneck_width=64,\n",
    "                 num_classes=1000, dilated=False, dilation=1,\n",
    "                 deep_stem=False, stem_width=64, avg_down=False,\n",
    "                 rectified_conv=False, rectify_avg=False,\n",
    "                 avd=False, avd_first=False,\n",
    "                 final_drop=0.0, dropblock_prob=0,\n",
    "                 last_gamma=False, norm_layer=nn.BatchNorm2d):\n",
    "        self.cardinality = groups\n",
    "        self.bottleneck_width = bottleneck_width\n",
    "        # ResNet-D params\n",
    "        self.inplanes = stem_width*2 if deep_stem else 64\n",
    "        self.avg_down = avg_down\n",
    "        self.last_gamma = last_gamma\n",
    "        # ResNeSt params\n",
    "        self.radix = radix\n",
    "        self.avd = avd\n",
    "        self.avd_first = avd_first\n",
    "\n",
    "        super(ResNet, self).__init__()\n",
    "        self.rectified_conv = rectified_conv\n",
    "        self.rectify_avg = rectify_avg\n",
    "        if rectified_conv:\n",
    "            from rfconv import RFConv2d\n",
    "            conv_layer = RFConv2d\n",
    "        else:\n",
    "            conv_layer = nn.Conv2d\n",
    "        conv_kwargs = {'average_mode': rectify_avg} if rectified_conv else {}\n",
    "        if deep_stem:\n",
    "            self.conv1 = nn.Sequential(\n",
    "                conv_layer(3, stem_width, kernel_size=3, stride=2, padding=1, bias=False, **conv_kwargs),\n",
    "                norm_layer(stem_width),\n",
    "                nn.ReLU(inplace=True),\n",
    "                conv_layer(stem_width, stem_width, kernel_size=3, stride=1, padding=1, bias=False, **conv_kwargs),\n",
    "                norm_layer(stem_width),\n",
    "                nn.ReLU(inplace=True),\n",
    "                conv_layer(stem_width, stem_width*2, kernel_size=3, stride=1, padding=1, bias=False, **conv_kwargs),\n",
    "            )\n",
    "        else:\n",
    "            self.conv1 = conv_layer(3, 64, kernel_size=7, stride=2, padding=3,\n",
    "                                   bias=False, **conv_kwargs)\n",
    "        self.bn1 = norm_layer(self.inplanes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.layer1 = self._make_layer(block, 64, layers[0], norm_layer=norm_layer, is_first=False)\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2, norm_layer=norm_layer)\n",
    "        if dilated or dilation == 4:\n",
    "            self.layer3 = self._make_layer(block, 256, layers[2], stride=1,\n",
    "                                           dilation=2, norm_layer=norm_layer,\n",
    "                                           dropblock_prob=dropblock_prob)\n",
    "            self.layer4 = self._make_layer(block, 512, layers[3], stride=1,\n",
    "                                           dilation=4, norm_layer=norm_layer,\n",
    "                                           dropblock_prob=dropblock_prob)\n",
    "        elif dilation==2:\n",
    "            self.layer3 = self._make_layer(block, 256, layers[2], stride=2,\n",
    "                                           dilation=1, norm_layer=norm_layer,\n",
    "                                           dropblock_prob=dropblock_prob)\n",
    "            self.layer4 = self._make_layer(block, 512, layers[3], stride=1,\n",
    "                                           dilation=2, norm_layer=norm_layer,\n",
    "                                           dropblock_prob=dropblock_prob)\n",
    "        else:\n",
    "            self.layer3 = self._make_layer(block, 256, layers[2], stride=2,\n",
    "                                           norm_layer=norm_layer,\n",
    "                                           dropblock_prob=dropblock_prob)\n",
    "            self.layer4 = self._make_layer(block, 512, layers[3], stride=2,\n",
    "                                           norm_layer=norm_layer,\n",
    "                                           dropblock_prob=dropblock_prob)\n",
    "        self.avgpool = GlobalAvgPool2d()\n",
    "        self.drop = nn.Dropout(final_drop) if final_drop > 0.0 else None\n",
    "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "            elif isinstance(m, norm_layer):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1, dilation=1, norm_layer=None,\n",
    "                    dropblock_prob=0.0, is_first=True):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            down_layers = []\n",
    "            if self.avg_down:\n",
    "                if dilation == 1:\n",
    "                    down_layers.append(nn.AvgPool2d(kernel_size=stride, stride=stride,\n",
    "                                                    ceil_mode=True, count_include_pad=False))\n",
    "                else:\n",
    "                    down_layers.append(nn.AvgPool2d(kernel_size=1, stride=1,\n",
    "                                                    ceil_mode=True, count_include_pad=False))\n",
    "                down_layers.append(nn.Conv2d(self.inplanes, planes * block.expansion,\n",
    "                                             kernel_size=1, stride=1, bias=False))\n",
    "            else:\n",
    "                down_layers.append(nn.Conv2d(self.inplanes, planes * block.expansion,\n",
    "                                             kernel_size=1, stride=stride, bias=False))\n",
    "            down_layers.append(norm_layer(planes * block.expansion))\n",
    "            downsample = nn.Sequential(*down_layers)\n",
    "\n",
    "        layers = []\n",
    "        if dilation == 1 or dilation == 2:\n",
    "            layers.append(block(self.inplanes, planes, stride, downsample=downsample,\n",
    "                                radix=self.radix, cardinality=self.cardinality,\n",
    "                                bottleneck_width=self.bottleneck_width,\n",
    "                                avd=self.avd, avd_first=self.avd_first,\n",
    "                                dilation=1, is_first=is_first, rectified_conv=self.rectified_conv,\n",
    "                                rectify_avg=self.rectify_avg,\n",
    "                                norm_layer=norm_layer, dropblock_prob=dropblock_prob,\n",
    "                                last_gamma=self.last_gamma))\n",
    "        elif dilation == 4:\n",
    "            layers.append(block(self.inplanes, planes, stride, downsample=downsample,\n",
    "                                radix=self.radix, cardinality=self.cardinality,\n",
    "                                bottleneck_width=self.bottleneck_width,\n",
    "                                avd=self.avd, avd_first=self.avd_first,\n",
    "                                dilation=2, is_first=is_first, rectified_conv=self.rectified_conv,\n",
    "                                rectify_avg=self.rectify_avg,\n",
    "                                norm_layer=norm_layer, dropblock_prob=dropblock_prob,\n",
    "                                last_gamma=self.last_gamma))\n",
    "        else:\n",
    "            raise RuntimeError(\"=> unknown dilation size: {}\".format(dilation))\n",
    "\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes,\n",
    "                                radix=self.radix, cardinality=self.cardinality,\n",
    "                                bottleneck_width=self.bottleneck_width,\n",
    "                                avd=self.avd, avd_first=self.avd_first,\n",
    "                                dilation=dilation, rectified_conv=self.rectified_conv,\n",
    "                                rectify_avg=self.rectify_avg,\n",
    "                                norm_layer=norm_layer, dropblock_prob=dropblock_prob,\n",
    "                                last_gamma=self.last_gamma))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        #x = x.view(x.size(0), -1)\n",
    "        x = torch.flatten(x, 1)\n",
    "        if self.drop:\n",
    "            x = self.drop(x)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x\n",
    "    \n",
    "class DropBlock2D(object):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        raise NotImplementedError\n",
    "\n",
    "class GlobalAvgPool2d(nn.Module):\n",
    "    def __init__(self):\n",
    "        \"\"\"Global average pooling over the input's spatial dimensions\"\"\"\n",
    "        super(GlobalAvgPool2d, self).__init__()\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        return nn.functional.adaptive_avg_pool2d(inputs, 1).view(inputs.size(0), -1)\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    \"\"\"ResNet Bottleneck\n",
    "    \"\"\"\n",
    "    # pylint: disable=unused-argument\n",
    "    expansion = 4\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None,\n",
    "                 radix=1, cardinality=1, bottleneck_width=64,\n",
    "                 avd=False, avd_first=False, dilation=1, is_first=False,\n",
    "                 rectified_conv=False, rectify_avg=False,\n",
    "                 norm_layer=None, dropblock_prob=0.0, last_gamma=False):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        group_width = int(planes * (bottleneck_width / 64.)) * cardinality\n",
    "        self.conv1 = nn.Conv2d(inplanes, group_width, kernel_size=1, bias=False)\n",
    "        self.bn1 = norm_layer(group_width)\n",
    "        self.dropblock_prob = dropblock_prob\n",
    "        self.radix = radix\n",
    "        self.avd = avd and (stride > 1 or is_first)\n",
    "        self.avd_first = avd_first\n",
    "\n",
    "        if self.avd:\n",
    "            self.avd_layer = nn.AvgPool2d(3, stride, padding=1)\n",
    "            stride = 1\n",
    "\n",
    "        if dropblock_prob > 0.0:\n",
    "            self.dropblock1 = DropBlock2D(dropblock_prob, 3)\n",
    "            if radix == 1:\n",
    "                self.dropblock2 = DropBlock2D(dropblock_prob, 3)\n",
    "            self.dropblock3 = DropBlock2D(dropblock_prob, 3)\n",
    "\n",
    "        if radix >= 1:\n",
    "            self.conv2 = SplAtConv2d(\n",
    "                group_width, group_width, kernel_size=3,\n",
    "                stride=stride, padding=dilation,\n",
    "                dilation=dilation, groups=cardinality, bias=False,\n",
    "                radix=radix, rectify=rectified_conv,\n",
    "                rectify_avg=rectify_avg,\n",
    "                norm_layer=norm_layer,\n",
    "                dropblock_prob=dropblock_prob)\n",
    "        elif rectified_conv:\n",
    "            from rfconv import RFConv2d\n",
    "            self.conv2 = RFConv2d(\n",
    "                group_width, group_width, kernel_size=3, stride=stride,\n",
    "                padding=dilation, dilation=dilation,\n",
    "                groups=cardinality, bias=False,\n",
    "                average_mode=rectify_avg)\n",
    "            self.bn2 = norm_layer(group_width)\n",
    "        else:\n",
    "            self.conv2 = nn.Conv2d(\n",
    "                group_width, group_width, kernel_size=3, stride=stride,\n",
    "                padding=dilation, dilation=dilation,\n",
    "                groups=cardinality, bias=False)\n",
    "            self.bn2 = norm_layer(group_width)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(\n",
    "            group_width, planes * 4, kernel_size=1, bias=False)\n",
    "        self.bn3 = norm_layer(planes*4)\n",
    "\n",
    "        if last_gamma:\n",
    "            from torch.nn.init import zeros_\n",
    "            zeros_(self.bn3.weight)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.downsample = downsample\n",
    "        self.dilation = dilation\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        if self.dropblock_prob > 0.0:\n",
    "            out = self.dropblock1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        if self.avd and self.avd_first:\n",
    "            out = self.avd_layer(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        if self.radix == 0:\n",
    "            out = self.bn2(out)\n",
    "            if self.dropblock_prob > 0.0:\n",
    "                out = self.dropblock2(out)\n",
    "            out = self.relu(out)\n",
    "\n",
    "        if self.avd and not self.avd_first:\n",
    "            out = self.avd_layer(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "        if self.dropblock_prob > 0.0:\n",
    "            out = self.dropblock3(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    \"\"\"ResNet Variants\n",
    "    Parameters\n",
    "    ----------\n",
    "    block : Block\n",
    "        Class for the residual block. Options are BasicBlockV1, BottleneckV1.\n",
    "    layers : list of int\n",
    "        Numbers of layers in each block\n",
    "    classes : int, default 1000\n",
    "        Number of classification classes.\n",
    "    dilated : bool, default False\n",
    "        Applying dilation strategy to pretrained ResNet yielding a stride-8 model,\n",
    "        typically used in Semantic Segmentation.\n",
    "    norm_layer : object\n",
    "        Normalization layer used in backbone network (default: :class:`mxnet.gluon.nn.BatchNorm`;\n",
    "        for Synchronized Cross-GPU BachNormalization).\n",
    "    Reference:\n",
    "        - He, Kaiming, et al. \"Deep residual learning for image recognition.\" Proceedings of the IEEE conference on computer vision and pattern recognition. 2016.\n",
    "        - Yu, Fisher, and Vladlen Koltun. \"Multi-scale context aggregation by dilated convolutions.\"\n",
    "    \"\"\"\n",
    "    # pylint: disable=unused-variable\n",
    "    def __init__(self, block, layers, radix=1, groups=1, bottleneck_width=64,\n",
    "                 num_classes=1000, dilated=False, dilation=1,\n",
    "                 deep_stem=False, stem_width=64, avg_down=False,\n",
    "                 rectified_conv=False, rectify_avg=False,\n",
    "                 avd=False, avd_first=False,\n",
    "                 final_drop=0.0, dropblock_prob=0,\n",
    "                 last_gamma=False, norm_layer=nn.BatchNorm2d):\n",
    "        self.cardinality = groups\n",
    "        self.bottleneck_width = bottleneck_width\n",
    "        # ResNet-D params\n",
    "        self.inplanes = stem_width*2 if deep_stem else 64\n",
    "        self.avg_down = avg_down\n",
    "        self.last_gamma = last_gamma\n",
    "        # ResNeSt params\n",
    "        self.radix = radix\n",
    "        self.avd = avd\n",
    "        self.avd_first = avd_first\n",
    "\n",
    "        super(ResNet, self).__init__()\n",
    "        self.rectified_conv = rectified_conv\n",
    "        self.rectify_avg = rectify_avg\n",
    "        if rectified_conv:\n",
    "            from rfconv import RFConv2d\n",
    "            conv_layer = RFConv2d\n",
    "        else:\n",
    "            conv_layer = nn.Conv2d\n",
    "        conv_kwargs = {'average_mode': rectify_avg} if rectified_conv else {}\n",
    "        if deep_stem:\n",
    "            self.conv1 = nn.Sequential(\n",
    "                conv_layer(3, stem_width, kernel_size=3, stride=2, padding=1, bias=False, **conv_kwargs),\n",
    "                norm_layer(stem_width),\n",
    "                nn.ReLU(inplace=True),\n",
    "                conv_layer(stem_width, stem_width, kernel_size=3, stride=1, padding=1, bias=False, **conv_kwargs),\n",
    "                norm_layer(stem_width),\n",
    "                nn.ReLU(inplace=True),\n",
    "                conv_layer(stem_width, stem_width*2, kernel_size=3, stride=1, padding=1, bias=False, **conv_kwargs),\n",
    "            )\n",
    "        else:\n",
    "            self.conv1 = conv_layer(3, 64, kernel_size=7, stride=2, padding=3,\n",
    "                                   bias=False, **conv_kwargs)\n",
    "        self.bn1 = norm_layer(self.inplanes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.layer1 = self._make_layer(block, 64, layers[0], norm_layer=norm_layer, is_first=False)\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2, norm_layer=norm_layer)\n",
    "        if dilated or dilation == 4:\n",
    "            self.layer3 = self._make_layer(block, 256, layers[2], stride=1,\n",
    "                                           dilation=2, norm_layer=norm_layer,\n",
    "                                           dropblock_prob=dropblock_prob)\n",
    "            self.layer4 = self._make_layer(block, 512, layers[3], stride=1,\n",
    "                                           dilation=4, norm_layer=norm_layer,\n",
    "                                           dropblock_prob=dropblock_prob)\n",
    "        elif dilation==2:\n",
    "            self.layer3 = self._make_layer(block, 256, layers[2], stride=2,\n",
    "                                           dilation=1, norm_layer=norm_layer,\n",
    "                                           dropblock_prob=dropblock_prob)\n",
    "            self.layer4 = self._make_layer(block, 512, layers[3], stride=1,\n",
    "                                           dilation=2, norm_layer=norm_layer,\n",
    "                                           dropblock_prob=dropblock_prob)\n",
    "        else:\n",
    "            self.layer3 = self._make_layer(block, 256, layers[2], stride=2,\n",
    "                                           norm_layer=norm_layer,\n",
    "                                           dropblock_prob=dropblock_prob)\n",
    "            self.layer4 = self._make_layer(block, 512, layers[3], stride=2,\n",
    "                                           norm_layer=norm_layer,\n",
    "                                           dropblock_prob=dropblock_prob)\n",
    "        self.avgpool = GlobalAvgPool2d()\n",
    "        self.drop = nn.Dropout(final_drop) if final_drop > 0.0 else None\n",
    "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "            elif isinstance(m, norm_layer):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1, dilation=1, norm_layer=None,\n",
    "                    dropblock_prob=0.0, is_first=True):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            down_layers = []\n",
    "            if self.avg_down:\n",
    "                if dilation == 1:\n",
    "                    down_layers.append(nn.AvgPool2d(kernel_size=stride, stride=stride,\n",
    "                                                    ceil_mode=True, count_include_pad=False))\n",
    "                else:\n",
    "                    down_layers.append(nn.AvgPool2d(kernel_size=1, stride=1,\n",
    "                                                    ceil_mode=True, count_include_pad=False))\n",
    "                down_layers.append(nn.Conv2d(self.inplanes, planes * block.expansion,\n",
    "                                             kernel_size=1, stride=1, bias=False))\n",
    "            else:\n",
    "                down_layers.append(nn.Conv2d(self.inplanes, planes * block.expansion,\n",
    "                                             kernel_size=1, stride=stride, bias=False))\n",
    "            down_layers.append(norm_layer(planes * block.expansion))\n",
    "            downsample = nn.Sequential(*down_layers)\n",
    "\n",
    "        layers = []\n",
    "        if dilation == 1 or dilation == 2:\n",
    "            layers.append(block(self.inplanes, planes, stride, downsample=downsample,\n",
    "                                radix=self.radix, cardinality=self.cardinality,\n",
    "                                bottleneck_width=self.bottleneck_width,\n",
    "                                avd=self.avd, avd_first=self.avd_first,\n",
    "                                dilation=1, is_first=is_first, rectified_conv=self.rectified_conv,\n",
    "                                rectify_avg=self.rectify_avg,\n",
    "                                norm_layer=norm_layer, dropblock_prob=dropblock_prob,\n",
    "                                last_gamma=self.last_gamma))\n",
    "        elif dilation == 4:\n",
    "            layers.append(block(self.inplanes, planes, stride, downsample=downsample,\n",
    "                                radix=self.radix, cardinality=self.cardinality,\n",
    "                                bottleneck_width=self.bottleneck_width,\n",
    "                                avd=self.avd, avd_first=self.avd_first,\n",
    "                                dilation=2, is_first=is_first, rectified_conv=self.rectified_conv,\n",
    "                                rectify_avg=self.rectify_avg,\n",
    "                                norm_layer=norm_layer, dropblock_prob=dropblock_prob,\n",
    "                                last_gamma=self.last_gamma))\n",
    "        else:\n",
    "            raise RuntimeError(\"=> unknown dilation size: {}\".format(dilation))\n",
    "\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes,\n",
    "                                radix=self.radix, cardinality=self.cardinality,\n",
    "                                bottleneck_width=self.bottleneck_width,\n",
    "                                avd=self.avd, avd_first=self.avd_first,\n",
    "                                dilation=dilation, rectified_conv=self.rectified_conv,\n",
    "                                rectify_avg=self.rectify_avg,\n",
    "                                norm_layer=norm_layer, dropblock_prob=dropblock_prob,\n",
    "                                last_gamma=self.last_gamma))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        #x = x.view(x.size(0), -1)\n",
    "        x = torch.flatten(x, 1)\n",
    "        if self.drop:\n",
    "            x = self.drop(x)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(args: tp.Dict):\n",
    "    # # get resnest50_fast_1s1x64d\n",
    "    model = ResNet(\n",
    "        Bottleneck, [3, 4, 6, 3],\n",
    "        radix=1, groups=1, bottleneck_width=64,\n",
    "        deep_stem=True, stem_width=32, avg_down=True,\n",
    "        avd=True, avd_first=True)\n",
    "    \n",
    "    state_dict = torch.load(args[\"trained_weights\"])\n",
    "    model.load_state_dict(state_dict)\n",
    "    \n",
    "    del model.fc\n",
    "    # # use the same head as the baseline notebook.\n",
    "    model.fc = nn.Sequential(\n",
    "        nn.Linear(2048, 1024), nn.ReLU(), nn.Dropout(p=0.2),\n",
    "        nn.Linear(1024, 1024), nn.ReLU(), nn.Dropout(p=0.2),\n",
    "        nn.Linear(1024, args[\"num_classes\"]))\n",
    "    \n",
    "#     state_dict = torch.load(args[\"trained_weights\"])\n",
    "#     model.load_state_dict(state_dict)\n",
    "    device = torch.device(\"cuda\")\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    return model\n",
    "\n",
    "# def get_model(args: tp.Dict):\n",
    "#     model =getattr(resnest_torch, args[\"name\"])(pretrained=args[\"params\"][\"pretrained\"])\n",
    "#     del model.fc\n",
    "#     # # use the same head as the baseline notebook.\n",
    "#     model.fc = nn.Sequential(\n",
    "#         nn.Linear(2048, 1024), nn.ReLU(), nn.Dropout(p=0.2),\n",
    "#         nn.Linear(1024, 1024), nn.ReLU(), nn.Dropout(p=0.2),\n",
    "#         nn.Linear(1024, args[\"params\"][\"n_classes\"]))\n",
    "    \n",
    "#     return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[globals]\n",
      "{'seed': 1213, 'device': 'cuda', 'num_epochs': 45, 'output_dir': '/kaggle/training_output/', 'use_fold': 0, 'target_sr': 32000}\n",
      "[dataset]\n",
      "{'name': 'SpectrogramDataset', 'params': {'img_size': 224, 'melspectrogram_parameters': {'n_mels': 128, 'fmin': 20, 'fmax': 16000}}}\n",
      "[split]\n",
      "{'name': 'StratifiedKFold', 'params': {'n_splits': 5, 'random_state': 42, 'shuffle': True}}\n",
      "[loader]\n",
      "{'train': {'batch_size': 50, 'shuffle': True, 'num_workers': 10, 'pin_memory': True, 'drop_last': True}, 'val': {'batch_size': 50, 'shuffle': False, 'num_workers': 10, 'pin_memory': True, 'drop_last': False}}\n",
      "[model]\n",
      "{'name': 'resnest50_fast_1s1x64d', 'params': {'pretrained': True, 'n_classes': 264}}\n",
      "[loss]\n",
      "{'name': 'BCEWithLogitsLoss', 'params': {}}\n",
      "[optimizer]\n",
      "{'name': 'Adam', 'params': {'lr': 0.001}}\n",
      "[scheduler]\n",
      "{'name': 'CosineAnnealingLR', 'params': {'T_max': 10}}\n"
     ]
    }
   ],
   "source": [
    "settings = yaml.safe_load(settings_str)\n",
    "if DEBUG:\n",
    "    settings['split']['params']['n_splits'] = 2\n",
    "    settings['globals']['num_epochs'] = 3\n",
    "\n",
    "for k, v in settings.items():\n",
    "    print(\"[{}]\".format(k))\n",
    "    print(v)\n",
    "set_seed(settings[\"globals\"][\"seed\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "data path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = Path.cwd().parent\n",
    "input_ex_root = root / 'data_ignore/external_dataset' / DATASET\n",
    "train_resampled_audio_dirs = [input_ex_root / \"birdsong-resampled-train-audio-{:0>2}\"\n",
    "                              .format(i)  for i in range(5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('/home/user/Git/kaggle-Cornell-Birdcall-Identification/data_ignore/external_dataset/32khz/birdsong-resampled-train-audio-00'),\n",
       " PosixPath('/home/user/Git/kaggle-Cornell-Birdcall-Identification/data_ignore/external_dataset/32khz/birdsong-resampled-train-audio-01'),\n",
       " PosixPath('/home/user/Git/kaggle-Cornell-Birdcall-Identification/data_ignore/external_dataset/32khz/birdsong-resampled-train-audio-02'),\n",
       " PosixPath('/home/user/Git/kaggle-Cornell-Birdcall-Identification/data_ignore/external_dataset/32khz/birdsong-resampled-train-audio-03'),\n",
       " PosixPath('/home/user/Git/kaggle-Cornell-Birdcall-Identification/data_ignore/external_dataset/32khz/birdsong-resampled-train-audio-04')]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_resampled_audio_dirs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(train_resampled_audio_dirs[0] / \"train_mod.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Execution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "train_all を作成  \n",
    "train_all: リサンプル後のファイルパスなどを追加"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21375, 38)\n",
      "(21375, 3)\n",
      "(21375, 39)\n"
     ]
    }
   ],
   "source": [
    "tmp_list = []\n",
    "for audio_d in train_resampled_audio_dirs:\n",
    "    if not audio_d.exists():\n",
    "        continue\n",
    "    for ebird_d in audio_d.iterdir():\n",
    "        if ebird_d.is_file():\n",
    "            continue\n",
    "        for i, wav_f in enumerate(ebird_d.iterdir()):\n",
    "            bool_n_splits = i==settings['split']['params']['n_splits']\n",
    "            if bool_n_splits and DEBUG: break  # if DEBUG=True: 1bird/n_splits file\n",
    "            tmp_list.append([ebird_d.name, wav_f.name, wav_f.as_posix()])\n",
    "            \n",
    "train_wav_path_exist = pd.DataFrame(\n",
    "    tmp_list, columns=[\"ebird_code\", \"resampled_filename\", \"file_path\"])\n",
    "\n",
    "del tmp_list\n",
    "\n",
    "train_all = pd.merge(\n",
    "    train, train_wav_path_exist, on=[\"ebird_code\", \"resampled_filename\"], how=\"inner\")\n",
    "\n",
    "if DEBUG: print('----- debug mode -----')\n",
    "print(train.shape)\n",
    "print(train_wav_path_exist.shape)\n",
    "print(train_all.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(**settings[\"split\"][\"params\"])\n",
    "\n",
    "train_all[\"fold\"] = -1\n",
    "for fold_id, (train_index, val_index) in enumerate(skf.split(train_all, train_all[\"ebird_code\"])):\n",
    "    train_all.iloc[val_index, -1] = fold_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(264, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>fold</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ebird_code</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>aldfly</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ameavo</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>amebit</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>amecro</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>amegfi</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>amekes</th>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>amepip</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>amered</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>amerob</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>amewig</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>amewoo</th>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>amtspa</th>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>annhum</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>astfly</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>baisan</th>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>baleag</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>balori</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>banswa</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>barswa</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bawwar</th>\n",
       "      <td>15</td>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>belkin1</th>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>belspa2</th>\n",
       "      <td>16</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bewwre</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bkbcuc</th>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bkbmag1</th>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bkbwar</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bkcchi</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bkchum</th>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bkhgro</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bkpwar</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bktspa</th>\n",
       "      <td>19</td>\n",
       "      <td>18</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>blkpho</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>blugrb1</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>blujay</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bnhcow</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>boboli</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bongul</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brdowl</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brebla</th>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brespa</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brncre</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brnthr</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brthum</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brwhaw</th>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>btbwar</th>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>btnwar</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>btywar</th>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>20</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>buffle</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>buggna</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>buhvir</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bulori</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bushti</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>buwtea</th>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>buwwar</th>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cacwre</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>calgul</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>calqua</th>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>camwar</th>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cangoo</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>canwar</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>canwre</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>carwre</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>casfin</th>\n",
       "      <td>16</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>caster1</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>casvir</th>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cedwax</th>\n",
       "      <td>17</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chispa</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chiswi</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chswar</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chukar</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>clanut</th>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cliswa</th>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>comgol</th>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>comgra</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>comloo</th>\n",
       "      <td>14</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>commer</th>\n",
       "      <td>16</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>comnig</th>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>18</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>comrav</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>comred</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>comter</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>comyel</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>coohaw</th>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>coshum</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cowscj1</th>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>daejun</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>doccor</th>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dowwoo</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dusfly</th>\n",
       "      <td>19</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eargre</th>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>easblu</th>\n",
       "      <td>19</td>\n",
       "      <td>20</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>easkin</th>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>easmea</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>easpho</th>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eastow</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eawpew</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eucdov</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eursta</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>evegro</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fiespa</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fiscro</th>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>foxspa</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gadwal</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gcrfin</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gnttow</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gnwtea</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gockin</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gocspa</th>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>goleag</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>grbher3</th>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>grcfly</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>greegr</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>greroa</th>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>greyel</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>grhowl</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>grnher</th>\n",
       "      <td>14</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>grtgra</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>grycat</th>\n",
       "      <td>16</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gryfly</th>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>17</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>haiwoo</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hamfly</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hergul</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>herthr</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hoomer</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hoowar</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>horgre</th>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>horlar</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>houfin</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>houspa</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>houwre</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>indbun</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>juntit1</th>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>killde</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>labwoo</th>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>larspa</th>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lazbun</th>\n",
       "      <td>20</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>leabit</th>\n",
       "      <td>18</td>\n",
       "      <td>19</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>leafly</th>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>leasan</th>\n",
       "      <td>15</td>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lecthr</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lesgol</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lesnig</th>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lesyel</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lewwoo</th>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>linspa</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lobcur</th>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lobdow</th>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>logshr</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lotduc</th>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>louwat</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macwar</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>magwar</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mallar3</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>marwre</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>merlin</th>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>moublu</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mouchi</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>moudov</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>norcar</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>norfli</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>norhar2</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>normoc</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>norpar</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>norpin</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>norsho</th>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>norwat</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nrwswa</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nutwoo</th>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>olsfly</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>orcwar</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>osprey</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ovenbi1</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>palwar</th>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pasfly</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pecsan</th>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>perfal</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>phaino</th>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pibgre</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pilwoo</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pingro</th>\n",
       "      <td>19</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pinjay</th>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pinsis</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pinwar</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>plsvir</th>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prawar</th>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>purfin</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pygnut</th>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rebmer</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rebnut</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rebsap</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rebwoo</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>redcro</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>redhea</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reevir1</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>renpha</th>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reshaw</th>\n",
       "      <td>15</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rethaw</th>\n",
       "      <td>18</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rewbla</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ribgul</th>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rinduc</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>robgro</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rocpig</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rocwre</th>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rthhum</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ruckin</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rudduc</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rufgro</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rufhum</th>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rusbla</th>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sagspa1</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sagthr</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>savspa</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>saypho</th>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scatan</th>\n",
       "      <td>19</td>\n",
       "      <td>18</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scoori</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>semplo</th>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>semsan</th>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sheowl</th>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shshaw</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>snobun</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>snogoo</th>\n",
       "      <td>16</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>solsan</th>\n",
       "      <td>18</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sonspa</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sora</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sposan</th>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spotow</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stejay</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>swahaw</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>swaspa</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>swathr</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treswa</th>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>truswa</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tuftit</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tunswa</th>\n",
       "      <td>13</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>veery</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vesspa</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vigswa</th>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>warvir</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wesblu</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wesgre</th>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weskin</th>\n",
       "      <td>16</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wesmea</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wessan</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>westan</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wewpew</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>whbnut</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>whcspa</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>whfibi</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>whtspa</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>whtswi</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wilfly</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wilsni1</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wiltur</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>winwre3</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wlswar</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wooduc</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wooscj2</th>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>17</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>woothr</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>y00475</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yebfly</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yebsap</th>\n",
       "      <td>13</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yehbla</th>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yelwar</th>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>17</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yerwar</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yetvir</th>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "fold         0   1   2   3   4\n",
       "ebird_code                    \n",
       "aldfly      20  20  20  20  20\n",
       "ameavo       8   8   8   7   7\n",
       "amebit       9   9   8   9   9\n",
       "amecro      20  20  20  20  20\n",
       "amegfi      20  20  20  20  20\n",
       "amekes      15  15  15  15  15\n",
       "amepip      20  20  20  20  20\n",
       "amered      20  20  20  20  20\n",
       "amerob      20  20  20  20  20\n",
       "amewig       6   6   7   7   7\n",
       "amewoo      17  17  17  16  16\n",
       "amtspa      15  15  14  15  15\n",
       "annhum      20  20  20  20  20\n",
       "astfly      20  20  20  20  20\n",
       "baisan      11  11  11  11  11\n",
       "baleag       7   7   7   7   7\n",
       "balori      20  20  20  20  20\n",
       "banswa      20  20  20  20  20\n",
       "barswa      20  20  20  20  20\n",
       "bawwar      15  14  15  15  15\n",
       "belkin1     13  14  14  14  14\n",
       "belspa2     16  15  15  15  15\n",
       "bewwre      20  20  20  20  20\n",
       "bkbcuc       9  10  10  10   9\n",
       "bkbmag1     12  12  12  12  12\n",
       "bkbwar      20  20  20  20  20\n",
       "bkcchi      20  20  20  20  20\n",
       "bkchum      14  14  13  13  14\n",
       "bkhgro      20  20  20  20  20\n",
       "bkpwar      20  20  20  20  20\n",
       "bktspa      19  18  19  19  19\n",
       "blkpho      20  20  20  20  20\n",
       "blugrb1     20  20  20  20  20\n",
       "blujay      20  20  20  20  20\n",
       "bnhcow      20  20  20  20  20\n",
       "boboli      20  20  20  20  20\n",
       "bongul       8   8   8   8   8\n",
       "brdowl      20  20  20  20  20\n",
       "brebla       9  10  10  10  10\n",
       "brespa      20  20  20  20  20\n",
       "brncre      20  20  20  20  20\n",
       "brnthr      20  20  20  20  20\n",
       "brthum      20  20  20  20  19\n",
       "brwhaw      15  15  15  14  15\n",
       "btbwar      15  15  15  15  15\n",
       "btnwar      20  20  20  20  20\n",
       "btywar      19  19  19  20  19\n",
       "buffle       3   3   3   3   3\n",
       "buggna      20  20  20  20  20\n",
       "buhvir      20  20  20  20  20\n",
       "bulori      20  20  20  20  20\n",
       "bushti      20  20  20  20  20\n",
       "buwtea      11  11  10  10  11\n",
       "buwwar      19  19  20  20  19\n",
       "cacwre      20  20  20  20  20\n",
       "calgul       8   8   8   8   8\n",
       "calqua      18  18  18  18  18\n",
       "camwar      15  15  15  15  16\n",
       "cangoo      20  20  20  20  20\n",
       "canwar      20  20  20  20  20\n",
       "canwre      20  20  20  20  20\n",
       "carwre      20  20  20  20  20\n",
       "casfin      16  15  15  15  15\n",
       "caster1     20  20  20  20  20\n",
       "casvir      18  18  18  18  18\n",
       "cedwax      17  18  18  18  18\n",
       "chispa      20  20  20  20  20\n",
       "chiswi       6   6   6   6   5\n",
       "chswar      20  20  20  20  20\n",
       "chukar       6   6   6   6   6\n",
       "clanut      16  16  16  15  16\n",
       "cliswa      13  13  13  13  13\n",
       "comgol      17  17  17  18  18\n",
       "comgra      20  20  20  20  20\n",
       "comloo      14  13  13  13  13\n",
       "commer      16  17  17  16  16\n",
       "comnig      17  17  17  18  17\n",
       "comrav      20  20  20  20  20\n",
       "comred      20  20  20  20  20\n",
       "comter      20  20  20  20  20\n",
       "comyel      20  20  20  20  20\n",
       "coohaw      18  18  18  18  18\n",
       "coshum       4   4   4   3   4\n",
       "cowscj1     14  14  13  14  14\n",
       "daejun      20  20  20  20  20\n",
       "doccor       7   6   7   7   7\n",
       "dowwoo      20  20  20  20  20\n",
       "dusfly      19  20  20  20  19\n",
       "eargre       8   7   7   7   8\n",
       "easblu      19  20  19  19  19\n",
       "easkin      16  16  17  17  16\n",
       "easmea      20  20  20  20  20\n",
       "easpho      18  18  18  18  19\n",
       "eastow      20  20  20  20  20\n",
       "eawpew      20  20  20  20  20\n",
       "eucdov      20  20  20  20  20\n",
       "eursta       8   8   8   8   8\n",
       "evegro      20  20  20  20  20\n",
       "fiespa      20  20  20  20  20\n",
       "fiscro      18  18  17  17  17\n",
       "foxspa      20  20  20  20  20\n",
       "gadwal      20  20  20  20  20\n",
       "gcrfin       6   6   7   6   6\n",
       "gnttow      20  20  20  20  20\n",
       "gnwtea      20  20  20  20  20\n",
       "gockin      20  20  20  20  20\n",
       "gocspa      14  14  14  14  14\n",
       "goleag      10  10  10  10  10\n",
       "grbher3     14  14  14  15  15\n",
       "grcfly      20  20  20  20  20\n",
       "greegr      20  20  20  20  20\n",
       "greroa      18  18  18  18  18\n",
       "greyel      20  20  20  20  20\n",
       "grhowl      20  20  20  20  20\n",
       "grnher      14  13  13  13  13\n",
       "grtgra      20  20  20  20  20\n",
       "grycat      16  17  17  16  16\n",
       "gryfly      16  16  16  17  16\n",
       "haiwoo      20  20  20  20  20\n",
       "hamfly      20  20  20  20  20\n",
       "hergul      20  20  20  20  20\n",
       "herthr      20  20  20  20  20\n",
       "hoomer       4   4   4   3   4\n",
       "hoowar      20  20  20  20  20\n",
       "horgre      13  13  13  14  14\n",
       "horlar      20  20  20  20  20\n",
       "houfin      20  20  20  20  20\n",
       "houspa      20  20  20  20  20\n",
       "houwre      20  20  20  20  20\n",
       "indbun      20  20  20  20  20\n",
       "juntit1     14  14  14  14  13\n",
       "killde      20  20  20  20  20\n",
       "labwoo      17  17  17  17  17\n",
       "larspa      19  19  19  19  19\n",
       "lazbun      20  19  19  19  20\n",
       "leabit      18  19  18  18  18\n",
       "leafly      19  19  19  19  19\n",
       "leasan      15  14  15  15  15\n",
       "lecthr       4   4   4   4   4\n",
       "lesgol      20  20  20  20  20\n",
       "lesnig       8   9   9   8   8\n",
       "lesyel      20  20  20  20  20\n",
       "lewwoo       6   5   5   6   6\n",
       "linspa      20  20  20  20  20\n",
       "lobcur      13  14  13  13  13\n",
       "lobdow      15  15  15  15  15\n",
       "logshr      20  20  20  20  20\n",
       "lotduc      12  12  12  12  12\n",
       "louwat      20  20  20  20  20\n",
       "macwar      20  20  20  20  20\n",
       "magwar      20  20  20  20  20\n",
       "mallar3     20  20  20  20  20\n",
       "marwre      20  20  20  20  20\n",
       "merlin      11  11  12  12  11\n",
       "moublu       6   6   6   6   6\n",
       "mouchi      20  20  20  20  20\n",
       "moudov      20  20  20  20  20\n",
       "norcar      20  20  20  20  20\n",
       "norfli      20  20  20  20  20\n",
       "norhar2      6   6   6   5   6\n",
       "normoc      20  20  20  20  20\n",
       "norpar      20  20  20  20  20\n",
       "norpin       8   8   7   8   8\n",
       "norsho      13  13  13  13  13\n",
       "norwat      20  20  20  20  20\n",
       "nrwswa       6   6   6   6   6\n",
       "nutwoo       9   8   9   9   9\n",
       "olsfly      20  20  20  20  20\n",
       "orcwar      20  20  20  20  20\n",
       "osprey      20  20  20  20  20\n",
       "ovenbi1     20  20  20  20  20\n",
       "palwar       9  10   9   9   9\n",
       "pasfly      20  20  20  20  20\n",
       "pecsan      13  13  14  13  13\n",
       "perfal      20  20  20  20  20\n",
       "phaino      12  12  12  12  12\n",
       "pibgre      20  20  20  20  20\n",
       "pilwoo      20  20  20  20  20\n",
       "pingro      19  18  18  19  19\n",
       "pinjay      10  11  10  10  10\n",
       "pinsis      20  20  20  20  20\n",
       "pinwar      20  20  20  20  20\n",
       "plsvir      18  18  19  19  18\n",
       "prawar      14  14  14  14  14\n",
       "purfin      20  20  20  20  20\n",
       "pygnut      12  12  12  12  12\n",
       "rebmer       6   6   6   5   6\n",
       "rebnut      20  20  20  20  20\n",
       "rebsap       6   6   6   7   7\n",
       "rebwoo      20  20  20  20  20\n",
       "redcro      20  20  20  20  20\n",
       "redhea       2   2   2   2   1\n",
       "reevir1     20  20  20  20  20\n",
       "renpha      15  15  15  14  15\n",
       "reshaw      15  14  14  15  15\n",
       "rethaw      18  19  19  19  18\n",
       "rewbla      20  20  20  20  20\n",
       "ribgul      13  13  13  13  14\n",
       "rinduc       5   5   5   5   5\n",
       "robgro      20  20  20  20  20\n",
       "rocpig      20  20  20  20  20\n",
       "rocwre      16  16  16  15  15\n",
       "rthhum       6   6   6   7   6\n",
       "ruckin      20  20  20  20  20\n",
       "rudduc       5   5   4   4   5\n",
       "rufgro       5   4   5   5   5\n",
       "rufhum      11  12  12  12  12\n",
       "rusbla      12  12  11  11  11\n",
       "sagspa1      6   6   6   6   6\n",
       "sagthr       7   7   7   7   7\n",
       "savspa      20  20  20  20  20\n",
       "saypho      11  11  11  11  11\n",
       "scatan      19  18  19  19  19\n",
       "scoori      20  20  20  20  20\n",
       "semplo      12  13  13  13  13\n",
       "semsan      14  14  14  14  14\n",
       "sheowl      12  12  11  11  11\n",
       "shshaw       4   4   5   5   4\n",
       "snobun      20  20  20  20  20\n",
       "snogoo      16  15  15  15  16\n",
       "solsan      18  19  19  19  19\n",
       "sonspa      20  20  20  20  20\n",
       "sora        20  20  20  20  20\n",
       "sposan      19  19  19  18  18\n",
       "spotow      20  20  20  20  20\n",
       "stejay      20  20  20  20  20\n",
       "swahaw       5   5   5   6   5\n",
       "swaspa      20  20  20  20  20\n",
       "swathr      20  20  20  20  20\n",
       "treswa      17  17  17  17  17\n",
       "truswa       8   8   7   7   8\n",
       "tuftit      20  20  20  20  20\n",
       "tunswa      13  12  13  13  13\n",
       "veery       20  20  20  20  20\n",
       "vesspa      20  20  20  20  20\n",
       "vigswa      10  11  11  10  10\n",
       "warvir      20  20  20  20  20\n",
       "wesblu       7   7   7   7   7\n",
       "wesgre       8   7   7   8   8\n",
       "weskin      16  17  17  17  16\n",
       "wesmea      20  20  20  20  20\n",
       "wessan       6   6   6   6   6\n",
       "westan      20  20  20  20  20\n",
       "wewpew      20  20  20  20  20\n",
       "whbnut      20  20  20  20  20\n",
       "whcspa      20  20  20  20  20\n",
       "whfibi       7   7   6   6   7\n",
       "whtspa      20  20  20  20  20\n",
       "whtswi       7   7   8   7   7\n",
       "wilfly      20  20  20  20  20\n",
       "wilsni1     20  20  20  20  20\n",
       "wiltur       9   9   9  10   9\n",
       "winwre3     20  20  20  20  20\n",
       "wlswar      20  20  20  20  20\n",
       "wooduc       8   8   8   8   8\n",
       "wooscj2     18  18  18  17  18\n",
       "woothr      20  20  20  20  20\n",
       "y00475      20  20  20  20  20\n",
       "yebfly      20  20  20  20  20\n",
       "yebsap      13  12  12  13  13\n",
       "yehbla      11  12  12  11  11\n",
       "yelwar      18  18  17  18  18\n",
       "yerwar      20  20  20  20  20\n",
       "yetvir      19  19  20  20  20"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fold_proportion = pd.pivot_table(train_all, index=\"ebird_code\", columns=\"fold\", values=\"xc_id\", aggfunc=len)\n",
    "print(fold_proportion.shape)\n",
    "fold_proportion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[fold 0] train: 17100, val: 4275\n"
     ]
    }
   ],
   "source": [
    "use_fold = settings[\"globals\"][\"use_fold\"]\n",
    "idx_train = train_all['fold']!=use_fold\n",
    "idx_valid = train_all['fold']==use_fold\n",
    "train_file_list = train_all[idx_train][['file_path', 'ebird_code']].values.tolist()\n",
    "valid_file_list = train_all[idx_valid][['file_path', 'ebird_code']].values.tolist()\n",
    "\n",
    "print(\"[fold {}] train: {}, val: {}\".format(use_fold, len(train_file_list), len(valid_file_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21375"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_file_list)+len(valid_file_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(settings['globals']['device'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "**<font color='orange'> -------------------- settings ------------------ </font>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # get loader\n",
    "train_loader, valid_loader = get_loaders_for_training(\n",
    "    SpectrogramDataset,\n",
    "    settings[\"dataset\"][\"params\"], settings[\"loader\"], train_file_list, valid_file_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model name: ResNet\n"
     ]
    }
   ],
   "source": [
    "# resnet18\n",
    "# model = models.resnet18(pretrained=True)\n",
    "# model.fc = nn.Linear(in_features=512, out_features=len(BIRD_CODE))\n",
    "\n",
    "# resnet34\n",
    "# model = models.resnet34(pretrained=True)\n",
    "# model.fc = nn.Linear(in_features=512, out_features=len(BIRD_CODE))\n",
    "\n",
    "# resnet50 のファインチューニング\n",
    "# model = models.resnet50(pretrained=True)\n",
    "# model.fc = nn.Linear(in_features=2048, out_features=len(BIRD_CODE))\n",
    "\n",
    "# resnest\n",
    "# model = getattr(resnest_torch, settings['model'][\"name\"])(pretrained=settings['model'][\"params\"][\"pretrained\"])\n",
    "# del model.fc\n",
    "# model.fc = nn.Sequential(\n",
    "#     nn.Linear(2048, 1024), nn.ReLU(), nn.Dropout(p=0.2),\n",
    "#     nn.Linear(1024, 1024), nn.ReLU(), nn.Dropout(p=0.2),\n",
    "#     nn.Linear(1024, settings['model'][\"params\"][\"n_classes\"]))\n",
    "# resnest\n",
    "model_config = {\n",
    "    \"base_model_name\": \"resnest50_fast_1s1x64d\",\n",
    "    \"pretrained\": False,\n",
    "    \"num_classes\": 264,\n",
    "    \"trained_weights\": PATH_MODEL,\n",
    "}\n",
    "model = get_model(model_config)\n",
    "\n",
    "\n",
    "model = model.to(device)\n",
    "print(f'model name: {model.__class__.__name__}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<font color='orange'> ------------------------------------------------ </font>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # get optimizer\n",
    "optimizer = getattr(\n",
    "        torch.optim, settings[\"optimizer\"][\"name\"]\n",
    "        )(model.parameters(), **settings[\"optimizer\"][\"params\"])\n",
    "\n",
    "# # # get scheduler\n",
    "scheduler = getattr(\n",
    "    torch.optim.lr_scheduler, settings[\"scheduler\"][\"name\"]\n",
    "    )(optimizer, **settings[\"scheduler\"][\"params\"])\n",
    "\n",
    "# # # get loss\n",
    "loss_func = getattr(nn, settings[\"loss\"][\"name\"])(**settings[\"loss\"][\"params\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, device, train_loader, optimizer, scheduler, loss_func):\n",
    "    model.train()\n",
    "    epoch_train_loss = 0\n",
    "    for batch_idx, (data, target) in enumerate(progress_bar(train_loader)):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = loss_func(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_train_loss += loss.item()*data.size(0)\n",
    "    scheduler.step()\n",
    "    loss = epoch_train_loss / len(train_loader.dataset)\n",
    "    del data\n",
    "    return loss\n",
    "\n",
    "class EarlyStopping:\n",
    "    \"\"\"\n",
    "    Early stops the training if validation loss doesn't improve after a given patience.\n",
    "    https://github.com/Bjarten/early-stopping-pytorch/blob/master/pytorchtools.py\n",
    "    \"\"\"\n",
    "    def __init__(self, patience=7, verbose=False, delta=0, path='checkpoint.pt', trace_func=print):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            patience (int): How long to wait after last time validation loss improved.\n",
    "                            Default: 7\n",
    "            verbose (bool): If True, prints a message for each validation loss improvement. \n",
    "                            Default: False\n",
    "            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n",
    "                            Default: 0\n",
    "            path (str): Path for the checkpoint to be saved to.\n",
    "                            Default: 'checkpoint.pt'\n",
    "            trace_func (function): trace print function.\n",
    "                            Default: print            \n",
    "        \"\"\"\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = np.Inf\n",
    "        self.delta = delta\n",
    "        self.path = path\n",
    "        self.trace_func = trace_func\n",
    "#         self.best_state_dict = {}\n",
    "    def __call__(self, val_loss, model):\n",
    "\n",
    "        score = -val_loss\n",
    "\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            self.trace_func(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, val_loss, model):\n",
    "        '''Saves model when validation loss decrease.'''\n",
    "        if self.verbose:\n",
    "            self.trace_func(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
    "        torch.save(model.state_dict(), self.path)\n",
    "#         self.best_state_dict = model.state_dict()\n",
    "        self.val_loss_min = val_loss\n",
    "        \n",
    "def get_epoch_loss_score(model, device, valid_loder, loss_func):\n",
    "    model.eval()\n",
    "    epoch_valid_loss = 0\n",
    "    y_pred_list = []\n",
    "    y_true_list = []\n",
    "    for batch_idx, (data, target) in enumerate(progress_bar(valid_loader)):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        output = model(data)\n",
    "        loss = loss_func(output, target)\n",
    "        epoch_valid_loss += loss.item()*data.size(0)\n",
    "        \n",
    "#         out_numpy = output.detach().cpu().numpy()\n",
    "        _y_pred = output.detach().cpu().numpy().argmax(axis=1)\n",
    "        y_pred_list.append(_y_pred)\n",
    "        _y_true = target.detach().cpu().numpy().argmax(axis=1)\n",
    "        y_true_list.append(_y_true)\n",
    "    \n",
    "    loss = epoch_valid_loss / len(valid_loader.dataset)\n",
    "    y_pred = np.concatenate(y_pred_list, axis=0)\n",
    "    y_true = np.concatenate(y_true_list, axis=0)\n",
    "    f_score = f1_score(y_true, y_pred, average='macro')\n",
    "    del data\n",
    "    return loss, f_score\n",
    "\n",
    "def evaluate(model, device, valid_loder, loss_func):\n",
    "    model.eval()\n",
    "    epoch_valid_loss = 0\n",
    "    for batch_idx, (data, target) in enumerate(progress_bar(valid_loader)):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        output = model(data)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        loss = loss_func(output, target)\n",
    "        epoch_valid_loss += loss.item()*data.size(0)\n",
    "    \n",
    "    loss = epoch_valid_loss / len(valid_loader.dataset)\n",
    "    del data\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = f'{DIR_MODEL}/nb{NB}_{model.__class__.__name__}/'\n",
    "file_dir = os.path.dirname(save_dir)\n",
    "if not os.path.exists(file_dir):\n",
    "    os.makedirs(file_dir)\n",
    "save_path = f'{save_dir}model_{model.__class__.__name__}.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='45', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/45 00:00<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " epoch: 1 Wed Aug 26 22:14:42 2020\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='342' class='' max='342', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [342/342 07:40<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='86', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/86 00:00<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "losses_train = []\n",
    "losses_valid = []\n",
    "epochs = []\n",
    "\n",
    "early_stopping = EarlyStopping(patience=7, verbose=True, path=save_path)\n",
    "n_epoch = settings['globals']['num_epochs']\n",
    "# n_epoch = 50\n",
    "for epoch in progress_bar(range(1, n_epoch+1)):\n",
    "    print(f'\\n epoch: {epoch} {time.ctime()}')\n",
    "    loss_train = train(model, device, train_loader, optimizer, scheduler, loss_func)\n",
    "    loss_valid, f_score_valid = get_epoch_loss_score(model, device, valid_loader, loss_func)\n",
    "    print(f'loss_train: {loss_train:.6f}, loss_valid: {loss_valid:.6f}, f1(macro): {f_score_valid:.6f}')\n",
    "    \n",
    "    epochs.append(epoch)\n",
    "    losses_train.append(loss_train)\n",
    "    losses_valid.append(loss_valid)\n",
    "    \n",
    "    early_stopping(loss_valid, model)\n",
    "\n",
    "    if early_stopping.early_stop:\n",
    "        print(\"Early stopping\")\n",
    "        break\n",
    "# model.load_state_dict(early_stopping.best_state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(epochs, losses_train, '-x', label='train')\n",
    "plt.plot(epochs, losses_valid, '-x', label='valid')\n",
    "plt.xlabel('epoch')\n",
    "plt.grid()\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del train_loader\n",
    "# del valid_loader\n",
    "# del model\n",
    "del optimizer\n",
    "del scheduler\n",
    "# del loss_func\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# save model"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "save_dir = f'{DIR_MODEL}/nb{NB}_{model.__class__.__name__}/'\n",
    "file_dir = os.path.dirname(save_dir)\n",
    "if not os.path.exists(file_dir):\n",
    "    os.makedirs(file_dir)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "save_path = f'{save_dir}model_{model.__class__.__name__}.pth'\n",
    "save_path"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "if DEBUG:\n",
    "    pass\n",
    "else:\n",
    "    torch.save(model.state_dict(), save_path)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# check model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predection check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DEBUG:\n",
    "    pass\n",
    "else:\n",
    "    load_weights = torch.load(save_path)\n",
    "    model.load_state_dict(load_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_valid, f_score_valid = get_epoch_loss_score(model, device, valid_loader, loss_func)\n",
    "loss_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestDataset(data.Dataset):\n",
    "    def __init__(self, df: pd.DataFrame, clip: np.ndarray,\n",
    "                 img_size=224, melspectrogram_parameters={}):\n",
    "        self.df = df\n",
    "        self.clip = clip\n",
    "        self.img_size = img_size\n",
    "        self.melspectrogram_parameters = melspectrogram_parameters\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx: int):\n",
    "        SR = 32000\n",
    "        sample = self.df.loc[idx, :]\n",
    "        site = sample.site\n",
    "        row_id = sample.row_id\n",
    "        \n",
    "        if site == \"site_3\":\n",
    "            y = self.clip.astype(np.float32)\n",
    "            len_y = len(y)\n",
    "            start = 0\n",
    "            end = SR * 5\n",
    "            images = []\n",
    "            while len_y > start:\n",
    "                y_batch = y[start:end].astype(np.float32)\n",
    "                if len(y_batch) != (SR * 5):\n",
    "                    break\n",
    "                start = end\n",
    "                end = end + SR * 5\n",
    "                \n",
    "                melspec = librosa.feature.melspectrogram(y_batch,\n",
    "                                                         sr=SR,\n",
    "                                                         **self.melspectrogram_parameters)\n",
    "                melspec = librosa.power_to_db(melspec).astype(np.float32)\n",
    "                image = mono_to_color(melspec)\n",
    "                height, width, _ = image.shape\n",
    "                image = cv2.resize(image, (int(width * self.img_size / height), self.img_size))\n",
    "                image = np.moveaxis(image, 2, 0)\n",
    "                image = (image / 255.0).astype(np.float32)\n",
    "                images.append(image)\n",
    "            images = np.asarray(images)\n",
    "            return images, row_id, site\n",
    "        else:\n",
    "            end_seconds = int(sample.seconds)\n",
    "            start_seconds = int(end_seconds - 5)\n",
    "            \n",
    "            start_index = SR * start_seconds\n",
    "            end_index = SR * end_seconds\n",
    "            \n",
    "            y = self.clip[start_index:end_index].astype(np.float32)\n",
    "\n",
    "            melspec = librosa.feature.melspectrogram(y, sr=SR, **self.melspectrogram_parameters)\n",
    "            melspec = librosa.power_to_db(melspec).astype(np.float32)\n",
    "\n",
    "            image = mono_to_color(melspec)\n",
    "            height, width, _ = image.shape\n",
    "            image = cv2.resize(image, (int(width * self.img_size / height), self.img_size))\n",
    "            image = np.moveaxis(image, 2, 0)\n",
    "            image = (image / 255.0).astype(np.float32)\n",
    "\n",
    "            return image, row_id, site\n",
    "        \n",
    "def prediction_for_clip(test_df: pd.DataFrame, \n",
    "                        clip: np.ndarray, \n",
    "                        model, \n",
    "                        mel_params: dict, \n",
    "                        threshold=0.5):\n",
    "\n",
    "    dataset = TestDataset(df=test_df, \n",
    "                          clip=clip,\n",
    "                          img_size=224,\n",
    "                          melspectrogram_parameters=mel_params)\n",
    "    loader = data.DataLoader(dataset, batch_size=1, shuffle=False)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    model.eval()\n",
    "    prediction_dict = {}\n",
    "    for image, row_id, site in progress_bar(loader):\n",
    "        site = site[0]\n",
    "        row_id = row_id[0]\n",
    "        if site in {\"site_1\", \"site_2\"}:\n",
    "            image = image.to(device)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                prediction = model(image)\n",
    "                proba = F.sigmoid(prediction).detach().cpu().numpy().reshape(-1)\n",
    "\n",
    "            events = proba >= threshold\n",
    "            labels = np.argwhere(events).reshape(-1).tolist()\n",
    "            \n",
    "\n",
    "        else:\n",
    "            # to avoid prediction on large batch\n",
    "            image = image.squeeze(0)\n",
    "            batch_size = 16\n",
    "            whole_size = image.size(0)\n",
    "            if whole_size % batch_size == 0:\n",
    "                n_iter = whole_size // batch_size\n",
    "            else:\n",
    "                n_iter = whole_size // batch_size + 1\n",
    "                \n",
    "            all_events = set()\n",
    "            for batch_i in range(n_iter):\n",
    "                batch = image[batch_i * batch_size:(batch_i + 1) * batch_size]\n",
    "#                 if batch.ndim == 3:\n",
    "#                     batch = batch.unsqueeze(0)\n",
    "\n",
    "                batch = batch.to(device)\n",
    "                with torch.no_grad():\n",
    "                    prediction = model(batch)\n",
    "                    proba = F.sigmoid(prediction).detach().cpu().numpy()              \n",
    "                events = proba >= threshold\n",
    "                for i in range(len(events)):\n",
    "                    event = events[i, :]\n",
    "                    labels = np.argwhere(event).reshape(-1).tolist()\n",
    "                    for label in labels:\n",
    "                        all_events.add(label)\n",
    "                        \n",
    "            labels = list(all_events)\n",
    "        if len(labels) == 0:\n",
    "            prediction_dict[row_id] = \"nocall\"\n",
    "        else:\n",
    "            labels_str_list = list(map(lambda x: INV_BIRD_CODE[x], labels))\n",
    "            label_string = \" \".join(labels_str_list)\n",
    "            prediction_dict[row_id] = label_string\n",
    "    return prediction_dict\n",
    "\n",
    "def prediction(test_df: pd.DataFrame,\n",
    "               test_audio: Path,\n",
    "               mel_params: dict,\n",
    "               model,\n",
    "               threshold=0.5):\n",
    "    \n",
    "    unique_audio_id = test_df.audio_id.unique()\n",
    "\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    prediction_dfs = []\n",
    "    for audio_id in unique_audio_id:\n",
    "        with timer(f\"Loading {audio_id}\", logger):\n",
    "            clip, _ = librosa.load(f'{test_audio}/{audio_id}.mp3',\n",
    "                                   sr=TARGET_SR,\n",
    "                                   mono=True,\n",
    "                                   res_type=\"kaiser_fast\")\n",
    "        \n",
    "        test_df_for_audio_id = test_df.query(\n",
    "            f\"audio_id == '{audio_id}'\").reset_index(drop=True)\n",
    "        with timer(f\"Prediction on {audio_id}\", logger):\n",
    "            prediction_dict = prediction_for_clip(test_df_for_audio_id,\n",
    "                                                  clip=clip,\n",
    "                                                  model=model,\n",
    "                                                  mel_params=mel_params,\n",
    "                                                  threshold=threshold)\n",
    "        row_id = list(prediction_dict.keys())\n",
    "        birds = list(prediction_dict.values())\n",
    "        prediction_df = pd.DataFrame({\n",
    "            \"row_id\": row_id,\n",
    "            \"birds\": birds\n",
    "        })\n",
    "        prediction_dfs.append(prediction_df)\n",
    "    \n",
    "    prediction_df = pd.concat(prediction_dfs, axis=0, sort=False).reset_index(drop=True)\n",
    "    return prediction_df\n",
    "\n",
    "@contextmanager\n",
    "def timer(name: str, logger):\n",
    "    t0 = time.time()\n",
    "    msg = f\"[{name}] start\"\n",
    "    if logger is None:\n",
    "        print(msg)\n",
    "    else:\n",
    "        logger.info(msg)\n",
    "    yield\n",
    "\n",
    "    msg = f\"[{name}] done in {time.time() - t0:.2f} s\"\n",
    "    if logger is None:\n",
    "        print(msg)\n",
    "    else:\n",
    "        logger.info(msg)\n",
    "        \n",
    "def get_logger(out_file=None):\n",
    "    logger = logging.getLogger()\n",
    "    formatter = logging.Formatter(\"%(asctime)s - %(levelname)s - %(message)s\")\n",
    "    logger.handlers = []\n",
    "    logger.setLevel(logging.INFO)\n",
    "\n",
    "    handler = logging.StreamHandler()\n",
    "    handler.setFormatter(formatter)\n",
    "    handler.setLevel(logging.INFO)\n",
    "    logger.addHandler(handler)\n",
    "\n",
    "    if out_file is not None:\n",
    "        fh = logging.FileHandler(out_file)\n",
    "        fh.setFormatter(formatter)\n",
    "        fh.setLevel(logging.INFO)\n",
    "        logger.addHandler(fh)\n",
    "    logger.info(\"logger set up\")\n",
    "    return logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = get_logger(\"main.log\")\n",
    "set_seed(1213)\n",
    "\n",
    "dir_test_audio = '../data/external_dataset/birdcall-check/test_audio/'\n",
    "test = pd.read_csv('./../data/external_dataset/birdcall-check/test.csv')\n",
    "sub = pd.read_csv('./../data_ignore/official/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "melspectrogram_parameters = {\n",
    "    \"n_mels\": 128,\n",
    "    \"fmin\": 20,\n",
    "    \"fmax\": 16000\n",
    "}\n",
    "\n",
    "THRESHOLD = 0.6\n",
    "TARGET_SR = 32000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = prediction(test_df=test,\n",
    "                        test_audio=dir_test_audio,\n",
    "                        model=model,\n",
    "                        mel_params=melspectrogram_parameters,\n",
    "                        threshold=THRESHOLD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_rows = 500\n",
    "submission.head(80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
