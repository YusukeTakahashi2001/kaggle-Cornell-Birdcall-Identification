{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overvew\n",
    "\n",
    "- nb033ベース\n",
    "- site3の推論部分をチェックしてみる"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CONST"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "NB = '040'\n",
    "DEBUG = False\n",
    "PERIOD = 5\n",
    "# PATH_EVENT = './../data_ignore/event/nb017_event_rms/nb017_event_rms.csv'\n",
    "DATASET = '32khz'\n",
    "DIR_MODEL = './../data_ignore/model'\n",
    "PATH_MODEL = './../data_ignore/model/resnest50/resnest50_fast_1s1x64d-d8fbf808.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "settings_str = \"\"\"\n",
    "globals:\n",
    "  seed: 1213\n",
    "  device: cuda\n",
    "  num_epochs: 45\n",
    "  output_dir: /kaggle/training_output/\n",
    "  use_fold: 0\n",
    "  target_sr: 32000\n",
    "\n",
    "dataset:\n",
    "  name: SpectrogramDataset\n",
    "  params:\n",
    "    img_size: 224\n",
    "    melspectrogram_parameters:\n",
    "      n_mels: 128\n",
    "      fmin: 20\n",
    "      fmax: 16000\n",
    "    \n",
    "split:\n",
    "  name: StratifiedKFold\n",
    "  params:\n",
    "    n_splits: 5\n",
    "    random_state: 42\n",
    "    shuffle: True\n",
    "\n",
    "loader:\n",
    "  train:\n",
    "    batch_size: 50\n",
    "    shuffle: True\n",
    "    num_workers: 10\n",
    "    pin_memory: True\n",
    "    drop_last: True\n",
    "  val:\n",
    "    batch_size: 50\n",
    "    shuffle: False\n",
    "    num_workers: 10\n",
    "    pin_memory: True\n",
    "    drop_last: False\n",
    "\n",
    "model:\n",
    "  name: resnest50_fast_1s1x64d\n",
    "  params:\n",
    "    pretrained: True\n",
    "    n_classes: 264\n",
    "\n",
    "loss:\n",
    "  name: BCEWithLogitsLoss\n",
    "  params: {}\n",
    "\n",
    "optimizer:\n",
    "  name: Adam\n",
    "  params:\n",
    "    lr: 0.001\n",
    "\n",
    "scheduler:\n",
    "  name: CosineAnnealingLR\n",
    "  params:\n",
    "    T_max: 10\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import everything I need :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/librosa/util/decorators.py:9: NumbaDeprecationWarning: An import was requested from a module that has moved location.\n",
      "Import of 'jit' requested from: 'numba.decorators', please update to use 'numba.core.decorators' or pin to Numba version 0.48.0. This alias will not be present in Numba version 0.50.0.\n",
      "  from numba.decorators import jit as optional_jit\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gc\n",
    "import typing as tp\n",
    "import logging\n",
    "import cv2 \n",
    "import warnings\n",
    "import math\n",
    "import time\n",
    "import yaml\n",
    "import random\n",
    "import librosa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import soundfile as sf\n",
    "from pathlib import Path\n",
    "from scipy.io import wavfile\n",
    "import matplotlib.pyplot as plt\n",
    "from fastprogress import progress_bar\n",
    "from contextlib import contextmanager\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "# from torchvision import models\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data\n",
    "import resnest.torch as resnest_torch\n",
    "from torch.nn import Conv2d, Module, Linear, BatchNorm2d, ReLU\n",
    "from torch.nn.modules.utils import _pair\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, './../src/util/')\n",
    "from const import BIRD_CODE, INV_BIRD_CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# My function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed: int = 42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)  # type: ignore\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mono_to_color(X, mean=None, std=None, norm_max=None, norm_min=None, eps=1e-6):\n",
    "    # Stack X as [X,X,X]\n",
    "    X = np.stack([X, X, X], axis=-1)\n",
    "\n",
    "    # Standardize\n",
    "    mean = mean or X.mean()\n",
    "    X = X - mean\n",
    "    std = std or X.std()\n",
    "    Xstd = X / (std + eps)\n",
    "    _min, _max = Xstd.min(), Xstd.max()\n",
    "    norm_max = norm_max or _max\n",
    "    norm_min = norm_min or _min\n",
    "    if (_max - _min) > eps:\n",
    "        # Normalize to [0, 255]\n",
    "        V = Xstd\n",
    "        V[V < norm_min] = norm_min\n",
    "        V[V > norm_max] = norm_max\n",
    "        V = 255 * (V - norm_min) / (norm_max - norm_min)\n",
    "        V = V.astype(np.uint8)\n",
    "    else:\n",
    "        # Just zero\n",
    "        V = np.zeros_like(Xstd, dtype=np.uint8)\n",
    "    return V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpectrogramDataset(data.Dataset):\n",
    "    def __init__(self, file_list, img_size=224, \n",
    "                 waveform_transforms=None, spectrogram_transforms=None, melspectrogram_parameters={}):\n",
    "        \n",
    "        self.file_list = file_list  # list of list: [file_path, ebird_code]\n",
    "        self.img_size = img_size\n",
    "        self.waveform_transforms = waveform_transforms\n",
    "        self.spectrogram_transforms = spectrogram_transforms\n",
    "        self.melspectrogram_parameters = melspectrogram_parameters\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_list)\n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "        wav_path, ebird_code = self.file_list[idx]\n",
    "\n",
    "        y, sr = sf.read(wav_path)\n",
    "#         sr, y = wavfile.read(wav_path)\n",
    "\n",
    "        if self.waveform_transforms:\n",
    "            y = self.waveform_transforms(y)\n",
    "        else:\n",
    "            len_y = len(y)\n",
    "            effective_length = sr * PERIOD\n",
    "            if len_y < effective_length:\n",
    "                new_y = np.zeros(effective_length, dtype=y.dtype)\n",
    "                start = np.random.randint(effective_length - len_y)\n",
    "                new_y[start:start + len_y] = y\n",
    "                y = new_y.astype(np.float32)\n",
    "            elif len_y > effective_length:\n",
    "                start = np.random.randint(len_y - effective_length)\n",
    "                y = y[start:start + effective_length].astype(np.float32)\n",
    "            else:\n",
    "                y = y.astype(np.float32)\n",
    "\n",
    "        melspec = librosa.feature.melspectrogram(y, sr=sr, **self.melspectrogram_parameters)\n",
    "        melspec = librosa.power_to_db(melspec).astype(np.float32)\n",
    "\n",
    "        if self.spectrogram_transforms:\n",
    "            melspec = self.spectrogram_transforms(melspec)\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "        image = mono_to_color(melspec)\n",
    "        height, width, _ = image.shape\n",
    "        image = cv2.resize(image, (int(width * self.img_size / height), self.img_size))\n",
    "        image = np.moveaxis(image, 2, 0)\n",
    "        image = (image / 255.0).astype(np.float32)\n",
    "\n",
    "#         labels = np.zeros(len(BIRD_CODE), dtype=\"i\")\n",
    "        labels = np.zeros(len(BIRD_CODE), dtype=\"f\")\n",
    "        labels[BIRD_CODE[ebird_code]] = 1\n",
    "\n",
    "        return image, labels\n",
    "\n",
    "class SpectrogramEventRmsDataset(data.Dataset):\n",
    "    def __init__(self, file_list, img_size=224, \n",
    "                 waveform_transforms=None, spectrogram_transforms=None, melspectrogram_parameters={}):\n",
    "        \n",
    "        self.file_list = file_list  # list of list: [file_path, ebird_code]\n",
    "        self.img_size = img_size\n",
    "        self.waveform_transforms = waveform_transforms\n",
    "        self.spectrogram_transforms = spectrogram_transforms\n",
    "        self.melspectrogram_parameters = melspectrogram_parameters\n",
    "        self.df_rms = pd.read_csv(PATH_FEAT)\n",
    "        self.sr_feat = 4\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_list)\n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "        wav_path, ebird_code = self.file_list[idx]\n",
    "\n",
    "        y, sr = sf.read(wav_path)\n",
    "        \n",
    "        if self.waveform_transforms:\n",
    "            y = self.waveform_transforms(y)\n",
    "        else:\n",
    "            len_y = len(y)\n",
    "            effective_length = sr * PERIOD\n",
    "            if len_y < effective_length:\n",
    "                new_y = np.zeros(effective_length, dtype=y.dtype)\n",
    "                start = np.random.randint(effective_length - len_y)\n",
    "                new_y[start:start + len_y] = y\n",
    "                y = new_y.astype(np.float32)\n",
    "            elif len_y > effective_length:\n",
    "                basename = os.path.basename(wav_path)\n",
    "                rms = self.df_rms.query('filename == @basename').librosa_rms.values\n",
    "                x_feat_sec = np.arange(0, len(rms))/self.sr_feat + 1/self.sr_feat\n",
    "                event_mask = rms > 1.3*np.median(rms)\n",
    "                \n",
    "                silent = ~any(event_mask)\n",
    "                if silent:\n",
    "                    # event を検出できなかったらランダムにクロップ\n",
    "                    start = np.random.randint(len_y - effective_length)\n",
    "                    y = y[start:start + effective_length].astype(np.float32)\n",
    "                else:\n",
    "                    choice = random.choice(x_feat_sec[event_mask])\n",
    "                    ed_sec = x_feat_sec[-1]\n",
    "                    st_range_sec = 2.5001\n",
    "                    ed_range_sec = ed_sec - 2.5001\n",
    "                    range_in = (st_range_sec <= choice) & (choice <= ed_range_sec)\n",
    "                    if range_in:\n",
    "                        idxs = np.arange(len_y)\n",
    "                        x_sec = idxs/sr\n",
    "                        mask = (choice - 2.5) < x_sec\n",
    "                        start = idxs[mask][0]\n",
    "                        y = y[start:start + effective_length].astype(np.float32)\n",
    "                    else:\n",
    "                        # ランダムにクロップ\n",
    "                        start = np.random.randint(len_y - effective_length)\n",
    "                        y = y[start:start + effective_length].astype(np.float32)\n",
    "                    \n",
    "                # ----\n",
    "            else:\n",
    "                y = y.astype(np.float32)\n",
    "\n",
    "        melspec = librosa.feature.melspectrogram(y, sr=sr, **self.melspectrogram_parameters)\n",
    "        melspec = librosa.power_to_db(melspec).astype(np.float32)\n",
    "\n",
    "        if self.spectrogram_transforms:\n",
    "            melspec = self.spectrogram_transforms(melspec)\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "        image = mono_to_color(melspec)\n",
    "        height, width, _ = image.shape\n",
    "        image = cv2.resize(image, (int(width * self.img_size / height), self.img_size))\n",
    "        image = np.moveaxis(image, 2, 0)\n",
    "        image = (image / 255.0).astype(np.float32)\n",
    "\n",
    "#         labels = np.zeros(len(BIRD_CODE), dtype=\"i\")\n",
    "        labels = np.zeros(len(BIRD_CODE), dtype=\"f\")\n",
    "        labels[BIRD_CODE[ebird_code]] = 1\n",
    "\n",
    "        return image, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpectrogramEventRmsDatasetV3(data.Dataset):\n",
    "    def __init__(self, file_list, img_size=224, \n",
    "                 waveform_transforms=None, spectrogram_transforms=None, melspectrogram_parameters={}):\n",
    "        \n",
    "        self.file_list = file_list  # list of list: [file_path, ebird_code]\n",
    "        self.img_size = img_size\n",
    "        self.waveform_transforms = waveform_transforms\n",
    "        self.spectrogram_transforms = spectrogram_transforms\n",
    "        self.melspectrogram_parameters = melspectrogram_parameters\n",
    "#         self.df_rms = pd.read_csv(PATH_FEAT)\n",
    "        self.df_event = pd.read_csv(PATH_EVENT)\n",
    "        self.sr_feat = 4\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_list)\n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "        wav_path, ebird_code = self.file_list[idx]\n",
    "\n",
    "        y, sr = sf.read(wav_path)\n",
    "        \n",
    "        if self.waveform_transforms:\n",
    "            y = self.waveform_transforms(y)\n",
    "        else:\n",
    "            len_y = len(y)\n",
    "            effective_length = sr * PERIOD\n",
    "            if len_y < effective_length:\n",
    "                new_y = np.zeros(effective_length, dtype=y.dtype)\n",
    "                start = np.random.randint(effective_length - len_y)\n",
    "                new_y[start:start + len_y] = y\n",
    "                y = new_y.astype(np.float32)\n",
    "            elif len_y > effective_length:\n",
    "                basename = os.path.basename(wav_path)\n",
    "                event_sec_list = self.df_event.query('filename == @basename').event_sec_list.to_list()[0]\n",
    "                event_sec_list = self.string_to_list(event_sec_list)\n",
    "                \n",
    "                # on event\n",
    "                if len(event_sec_list) != 0:\n",
    "                    choice = random.choice(event_sec_list)\n",
    "                    # 前から2.5秒、後ろから2.5秒の範囲におさまってるか(境界問題)\n",
    "                    ed_sec = len_y / sr\n",
    "                    st_range_sec = PERIOD/2 + 0.0001\n",
    "                    ed_range_sec = ed_sec - st_range_sec\n",
    "                    range_in = (st_range_sec <= choice) & (choice <= ed_range_sec)\n",
    "                    if range_in:\n",
    "                        start = int((choice - PERIOD/2) * sr)\n",
    "                        y = y[start:start + effective_length].astype(np.float32)\n",
    "                    else:\n",
    "                        # ランダムにクロップ\n",
    "                        start = np.random.randint(len_y - effective_length)\n",
    "                        y = y[start:start + effective_length].astype(np.float32)\n",
    "                # off event\n",
    "                else:\n",
    "                    # event を検出できなかったらランダムにクロップ\n",
    "                    start = np.random.randint(len_y - effective_length)\n",
    "                    y = y[start:start + effective_length].astype(np.float32)\n",
    "                    \n",
    "                # ----\n",
    "            else:\n",
    "                y = y.astype(np.float32)\n",
    "\n",
    "\n",
    "        melspec = librosa.feature.melspectrogram(y, sr=sr, **self.melspectrogram_parameters)\n",
    "        melspec = librosa.power_to_db(melspec).astype(np.float32)\n",
    "\n",
    "        if self.spectrogram_transforms:\n",
    "            melspec = self.spectrogram_transforms(melspec)\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "        image = mono_to_color(melspec)\n",
    "        height, width, _ = image.shape\n",
    "        image = cv2.resize(image, (int(width * self.img_size / height), self.img_size))\n",
    "        image = np.moveaxis(image, 2, 0)\n",
    "        image = (image / 255.0).astype(np.float32)\n",
    "\n",
    "#         labels = np.zeros(len(BIRD_CODE), dtype=\"i\")\n",
    "        labels = np.zeros(len(BIRD_CODE), dtype=\"f\")\n",
    "        labels[BIRD_CODE[ebird_code]] = 1\n",
    "\n",
    "        return image, labels\n",
    "    \n",
    "    def string_to_list(self, list_str):\n",
    "        for str_replace in ['\\n', '[', ']']:\n",
    "            list_str = list_str.replace(str_replace, '')\n",
    "\n",
    "        split = list_str.split(' ')\n",
    "        events_num = []\n",
    "        for text in split:\n",
    "            try:\n",
    "                num = np.float32(text)\n",
    "                events_num.append(num)\n",
    "            except:\n",
    "                pass\n",
    "        return events_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loaders_for_training(dataset_class, args_dataset, args_loader, train_file_list, valid_file_list):\n",
    "    # # make dataset\n",
    "    train_dataset = dataset_class(train_file_list, **args_dataset)\n",
    "    val_dataset = dataset_class(valid_file_list, **args_dataset)\n",
    "    # # make dataloader\n",
    "    train_loader = data.DataLoader(train_dataset, **args_loader[\"train\"])\n",
    "    valid_loader = data.DataLoader(val_dataset, **args_loader[\"val\"])\n",
    "    \n",
    "    return train_loader, valid_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SplAtConv2d(Module):\n",
    "    \"\"\"Split-Attention Conv2d\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, channels, kernel_size, stride=(1, 1), padding=(0, 0),\n",
    "                 dilation=(1, 1), groups=1, bias=True,\n",
    "                 radix=2, reduction_factor=4,\n",
    "                 rectify=False, rectify_avg=False, norm_layer=None,\n",
    "                 dropblock_prob=0.0, **kwargs):\n",
    "        super(SplAtConv2d, self).__init__()\n",
    "        padding = _pair(padding)\n",
    "        self.rectify = rectify and (padding[0] > 0 or padding[1] > 0)\n",
    "        self.rectify_avg = rectify_avg\n",
    "        inter_channels = max(in_channels*radix//reduction_factor, 32)\n",
    "        self.radix = radix\n",
    "        self.cardinality = groups\n",
    "        self.channels = channels\n",
    "        self.dropblock_prob = dropblock_prob\n",
    "        if self.rectify:\n",
    "            from rfconv import RFConv2d\n",
    "            self.conv = RFConv2d(in_channels, channels*radix, kernel_size, stride, padding, dilation,\n",
    "                                 groups=groups*radix, bias=bias, average_mode=rectify_avg, **kwargs)\n",
    "        else:\n",
    "            self.conv = Conv2d(in_channels, channels*radix, kernel_size, stride, padding, dilation,\n",
    "                               groups=groups*radix, bias=bias, **kwargs)\n",
    "        self.use_bn = norm_layer is not None\n",
    "        if self.use_bn:\n",
    "            self.bn0 = norm_layer(channels*radix)\n",
    "        self.relu = ReLU(inplace=True)\n",
    "        self.fc1 = Conv2d(channels, inter_channels, 1, groups=self.cardinality)\n",
    "        if self.use_bn:\n",
    "            self.bn1 = norm_layer(inter_channels)\n",
    "        self.fc2 = Conv2d(inter_channels, channels*radix, 1, groups=self.cardinality)\n",
    "        if dropblock_prob > 0.0:\n",
    "            self.dropblock = DropBlock2D(dropblock_prob, 3)\n",
    "        self.rsoftmax = rSoftMax(radix, groups)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        if self.use_bn:\n",
    "            x = self.bn0(x)\n",
    "        if self.dropblock_prob > 0.0:\n",
    "            x = self.dropblock(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        batch, rchannel = x.shape[:2]\n",
    "        if self.radix > 1:\n",
    "            if torch.__version__ < '1.5':\n",
    "                splited = torch.split(x, int(rchannel//self.radix), dim=1)\n",
    "            else:\n",
    "                splited = torch.split(x, rchannel//self.radix, dim=1)\n",
    "            gap = sum(splited) \n",
    "        else:\n",
    "            gap = x\n",
    "        gap = F.adaptive_avg_pool2d(gap, 1)\n",
    "        gap = self.fc1(gap)\n",
    "\n",
    "        if self.use_bn:\n",
    "            gap = self.bn1(gap)\n",
    "        gap = self.relu(gap)\n",
    "\n",
    "        atten = self.fc2(gap)\n",
    "        atten = self.rsoftmax(atten).view(batch, -1, 1, 1)\n",
    "\n",
    "        if self.radix > 1:\n",
    "            if torch.__version__ < '1.5':\n",
    "                attens = torch.split(atten, int(rchannel//self.radix), dim=1)\n",
    "            else:\n",
    "                attens = torch.split(atten, rchannel//self.radix, dim=1)\n",
    "            out = sum([att*split for (att, split) in zip(attens, splited)])\n",
    "        else:\n",
    "            out = atten * x\n",
    "        return out.contiguous()\n",
    "\n",
    "class rSoftMax(nn.Module):\n",
    "    def __init__(self, radix, cardinality):\n",
    "        super().__init__()\n",
    "        self.radix = radix\n",
    "        self.cardinality = cardinality\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch = x.size(0)\n",
    "        if self.radix > 1:\n",
    "            x = x.view(batch, self.cardinality, self.radix, -1).transpose(1, 2)\n",
    "            x = F.softmax(x, dim=1)\n",
    "            x = x.reshape(batch, -1)\n",
    "        else:\n",
    "            x = torch.sigmoid(x)\n",
    "        return x\n",
    "class DropBlock2D(object):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        raise NotImplementedError\n",
    "\n",
    "class GlobalAvgPool2d(nn.Module):\n",
    "    def __init__(self):\n",
    "        \"\"\"Global average pooling over the input's spatial dimensions\"\"\"\n",
    "        super(GlobalAvgPool2d, self).__init__()\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        return nn.functional.adaptive_avg_pool2d(inputs, 1).view(inputs.size(0), -1)\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    \"\"\"ResNet Bottleneck\n",
    "    \"\"\"\n",
    "    # pylint: disable=unused-argument\n",
    "    expansion = 4\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None,\n",
    "                 radix=1, cardinality=1, bottleneck_width=64,\n",
    "                 avd=False, avd_first=False, dilation=1, is_first=False,\n",
    "                 rectified_conv=False, rectify_avg=False,\n",
    "                 norm_layer=None, dropblock_prob=0.0, last_gamma=False):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        group_width = int(planes * (bottleneck_width / 64.)) * cardinality\n",
    "        self.conv1 = nn.Conv2d(inplanes, group_width, kernel_size=1, bias=False)\n",
    "        self.bn1 = norm_layer(group_width)\n",
    "        self.dropblock_prob = dropblock_prob\n",
    "        self.radix = radix\n",
    "        self.avd = avd and (stride > 1 or is_first)\n",
    "        self.avd_first = avd_first\n",
    "\n",
    "        if self.avd:\n",
    "            self.avd_layer = nn.AvgPool2d(3, stride, padding=1)\n",
    "            stride = 1\n",
    "\n",
    "        if dropblock_prob > 0.0:\n",
    "            self.dropblock1 = DropBlock2D(dropblock_prob, 3)\n",
    "            if radix == 1:\n",
    "                self.dropblock2 = DropBlock2D(dropblock_prob, 3)\n",
    "            self.dropblock3 = DropBlock2D(dropblock_prob, 3)\n",
    "\n",
    "        if radix >= 1:\n",
    "            self.conv2 = SplAtConv2d(\n",
    "                group_width, group_width, kernel_size=3,\n",
    "                stride=stride, padding=dilation,\n",
    "                dilation=dilation, groups=cardinality, bias=False,\n",
    "                radix=radix, rectify=rectified_conv,\n",
    "                rectify_avg=rectify_avg,\n",
    "                norm_layer=norm_layer,\n",
    "                dropblock_prob=dropblock_prob)\n",
    "        elif rectified_conv:\n",
    "            from rfconv import RFConv2d\n",
    "            self.conv2 = RFConv2d(\n",
    "                group_width, group_width, kernel_size=3, stride=stride,\n",
    "                padding=dilation, dilation=dilation,\n",
    "                groups=cardinality, bias=False,\n",
    "                average_mode=rectify_avg)\n",
    "            self.bn2 = norm_layer(group_width)\n",
    "        else:\n",
    "            self.conv2 = nn.Conv2d(\n",
    "                group_width, group_width, kernel_size=3, stride=stride,\n",
    "                padding=dilation, dilation=dilation,\n",
    "                groups=cardinality, bias=False)\n",
    "            self.bn2 = norm_layer(group_width)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(\n",
    "            group_width, planes * 4, kernel_size=1, bias=False)\n",
    "        self.bn3 = norm_layer(planes*4)\n",
    "\n",
    "        if last_gamma:\n",
    "            from torch.nn.init import zeros_\n",
    "            zeros_(self.bn3.weight)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.downsample = downsample\n",
    "        self.dilation = dilation\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        if self.dropblock_prob > 0.0:\n",
    "            out = self.dropblock1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        if self.avd and self.avd_first:\n",
    "            out = self.avd_layer(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        if self.radix == 0:\n",
    "            out = self.bn2(out)\n",
    "            if self.dropblock_prob > 0.0:\n",
    "                out = self.dropblock2(out)\n",
    "            out = self.relu(out)\n",
    "\n",
    "        if self.avd and not self.avd_first:\n",
    "            out = self.avd_layer(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "        if self.dropblock_prob > 0.0:\n",
    "            out = self.dropblock3(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    \"\"\"ResNet Variants\n",
    "    Parameters\n",
    "    ----------\n",
    "    block : Block\n",
    "        Class for the residual block. Options are BasicBlockV1, BottleneckV1.\n",
    "    layers : list of int\n",
    "        Numbers of layers in each block\n",
    "    classes : int, default 1000\n",
    "        Number of classification classes.\n",
    "    dilated : bool, default False\n",
    "        Applying dilation strategy to pretrained ResNet yielding a stride-8 model,\n",
    "        typically used in Semantic Segmentation.\n",
    "    norm_layer : object\n",
    "        Normalization layer used in backbone network (default: :class:`mxnet.gluon.nn.BatchNorm`;\n",
    "        for Synchronized Cross-GPU BachNormalization).\n",
    "    Reference:\n",
    "        - He, Kaiming, et al. \"Deep residual learning for image recognition.\" Proceedings of the IEEE conference on computer vision and pattern recognition. 2016.\n",
    "        - Yu, Fisher, and Vladlen Koltun. \"Multi-scale context aggregation by dilated convolutions.\"\n",
    "    \"\"\"\n",
    "    # pylint: disable=unused-variable\n",
    "    def __init__(self, block, layers, radix=1, groups=1, bottleneck_width=64,\n",
    "                 num_classes=1000, dilated=False, dilation=1,\n",
    "                 deep_stem=False, stem_width=64, avg_down=False,\n",
    "                 rectified_conv=False, rectify_avg=False,\n",
    "                 avd=False, avd_first=False,\n",
    "                 final_drop=0.0, dropblock_prob=0,\n",
    "                 last_gamma=False, norm_layer=nn.BatchNorm2d):\n",
    "        self.cardinality = groups\n",
    "        self.bottleneck_width = bottleneck_width\n",
    "        # ResNet-D params\n",
    "        self.inplanes = stem_width*2 if deep_stem else 64\n",
    "        self.avg_down = avg_down\n",
    "        self.last_gamma = last_gamma\n",
    "        # ResNeSt params\n",
    "        self.radix = radix\n",
    "        self.avd = avd\n",
    "        self.avd_first = avd_first\n",
    "\n",
    "        super(ResNet, self).__init__()\n",
    "        self.rectified_conv = rectified_conv\n",
    "        self.rectify_avg = rectify_avg\n",
    "        if rectified_conv:\n",
    "            from rfconv import RFConv2d\n",
    "            conv_layer = RFConv2d\n",
    "        else:\n",
    "            conv_layer = nn.Conv2d\n",
    "        conv_kwargs = {'average_mode': rectify_avg} if rectified_conv else {}\n",
    "        if deep_stem:\n",
    "            self.conv1 = nn.Sequential(\n",
    "                conv_layer(3, stem_width, kernel_size=3, stride=2, padding=1, bias=False, **conv_kwargs),\n",
    "                norm_layer(stem_width),\n",
    "                nn.ReLU(inplace=True),\n",
    "                conv_layer(stem_width, stem_width, kernel_size=3, stride=1, padding=1, bias=False, **conv_kwargs),\n",
    "                norm_layer(stem_width),\n",
    "                nn.ReLU(inplace=True),\n",
    "                conv_layer(stem_width, stem_width*2, kernel_size=3, stride=1, padding=1, bias=False, **conv_kwargs),\n",
    "            )\n",
    "        else:\n",
    "            self.conv1 = conv_layer(3, 64, kernel_size=7, stride=2, padding=3,\n",
    "                                   bias=False, **conv_kwargs)\n",
    "        self.bn1 = norm_layer(self.inplanes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.layer1 = self._make_layer(block, 64, layers[0], norm_layer=norm_layer, is_first=False)\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2, norm_layer=norm_layer)\n",
    "        if dilated or dilation == 4:\n",
    "            self.layer3 = self._make_layer(block, 256, layers[2], stride=1,\n",
    "                                           dilation=2, norm_layer=norm_layer,\n",
    "                                           dropblock_prob=dropblock_prob)\n",
    "            self.layer4 = self._make_layer(block, 512, layers[3], stride=1,\n",
    "                                           dilation=4, norm_layer=norm_layer,\n",
    "                                           dropblock_prob=dropblock_prob)\n",
    "        elif dilation==2:\n",
    "            self.layer3 = self._make_layer(block, 256, layers[2], stride=2,\n",
    "                                           dilation=1, norm_layer=norm_layer,\n",
    "                                           dropblock_prob=dropblock_prob)\n",
    "            self.layer4 = self._make_layer(block, 512, layers[3], stride=1,\n",
    "                                           dilation=2, norm_layer=norm_layer,\n",
    "                                           dropblock_prob=dropblock_prob)\n",
    "        else:\n",
    "            self.layer3 = self._make_layer(block, 256, layers[2], stride=2,\n",
    "                                           norm_layer=norm_layer,\n",
    "                                           dropblock_prob=dropblock_prob)\n",
    "            self.layer4 = self._make_layer(block, 512, layers[3], stride=2,\n",
    "                                           norm_layer=norm_layer,\n",
    "                                           dropblock_prob=dropblock_prob)\n",
    "        self.avgpool = GlobalAvgPool2d()\n",
    "        self.drop = nn.Dropout(final_drop) if final_drop > 0.0 else None\n",
    "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "            elif isinstance(m, norm_layer):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1, dilation=1, norm_layer=None,\n",
    "                    dropblock_prob=0.0, is_first=True):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            down_layers = []\n",
    "            if self.avg_down:\n",
    "                if dilation == 1:\n",
    "                    down_layers.append(nn.AvgPool2d(kernel_size=stride, stride=stride,\n",
    "                                                    ceil_mode=True, count_include_pad=False))\n",
    "                else:\n",
    "                    down_layers.append(nn.AvgPool2d(kernel_size=1, stride=1,\n",
    "                                                    ceil_mode=True, count_include_pad=False))\n",
    "                down_layers.append(nn.Conv2d(self.inplanes, planes * block.expansion,\n",
    "                                             kernel_size=1, stride=1, bias=False))\n",
    "            else:\n",
    "                down_layers.append(nn.Conv2d(self.inplanes, planes * block.expansion,\n",
    "                                             kernel_size=1, stride=stride, bias=False))\n",
    "            down_layers.append(norm_layer(planes * block.expansion))\n",
    "            downsample = nn.Sequential(*down_layers)\n",
    "\n",
    "        layers = []\n",
    "        if dilation == 1 or dilation == 2:\n",
    "            layers.append(block(self.inplanes, planes, stride, downsample=downsample,\n",
    "                                radix=self.radix, cardinality=self.cardinality,\n",
    "                                bottleneck_width=self.bottleneck_width,\n",
    "                                avd=self.avd, avd_first=self.avd_first,\n",
    "                                dilation=1, is_first=is_first, rectified_conv=self.rectified_conv,\n",
    "                                rectify_avg=self.rectify_avg,\n",
    "                                norm_layer=norm_layer, dropblock_prob=dropblock_prob,\n",
    "                                last_gamma=self.last_gamma))\n",
    "        elif dilation == 4:\n",
    "            layers.append(block(self.inplanes, planes, stride, downsample=downsample,\n",
    "                                radix=self.radix, cardinality=self.cardinality,\n",
    "                                bottleneck_width=self.bottleneck_width,\n",
    "                                avd=self.avd, avd_first=self.avd_first,\n",
    "                                dilation=2, is_first=is_first, rectified_conv=self.rectified_conv,\n",
    "                                rectify_avg=self.rectify_avg,\n",
    "                                norm_layer=norm_layer, dropblock_prob=dropblock_prob,\n",
    "                                last_gamma=self.last_gamma))\n",
    "        else:\n",
    "            raise RuntimeError(\"=> unknown dilation size: {}\".format(dilation))\n",
    "\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes,\n",
    "                                radix=self.radix, cardinality=self.cardinality,\n",
    "                                bottleneck_width=self.bottleneck_width,\n",
    "                                avd=self.avd, avd_first=self.avd_first,\n",
    "                                dilation=dilation, rectified_conv=self.rectified_conv,\n",
    "                                rectify_avg=self.rectify_avg,\n",
    "                                norm_layer=norm_layer, dropblock_prob=dropblock_prob,\n",
    "                                last_gamma=self.last_gamma))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        #x = x.view(x.size(0), -1)\n",
    "        x = torch.flatten(x, 1)\n",
    "        if self.drop:\n",
    "            x = self.drop(x)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x\n",
    "    \n",
    "class DropBlock2D(object):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        raise NotImplementedError\n",
    "\n",
    "class GlobalAvgPool2d(nn.Module):\n",
    "    def __init__(self):\n",
    "        \"\"\"Global average pooling over the input's spatial dimensions\"\"\"\n",
    "        super(GlobalAvgPool2d, self).__init__()\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        return nn.functional.adaptive_avg_pool2d(inputs, 1).view(inputs.size(0), -1)\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    \"\"\"ResNet Bottleneck\n",
    "    \"\"\"\n",
    "    # pylint: disable=unused-argument\n",
    "    expansion = 4\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None,\n",
    "                 radix=1, cardinality=1, bottleneck_width=64,\n",
    "                 avd=False, avd_first=False, dilation=1, is_first=False,\n",
    "                 rectified_conv=False, rectify_avg=False,\n",
    "                 norm_layer=None, dropblock_prob=0.0, last_gamma=False):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        group_width = int(planes * (bottleneck_width / 64.)) * cardinality\n",
    "        self.conv1 = nn.Conv2d(inplanes, group_width, kernel_size=1, bias=False)\n",
    "        self.bn1 = norm_layer(group_width)\n",
    "        self.dropblock_prob = dropblock_prob\n",
    "        self.radix = radix\n",
    "        self.avd = avd and (stride > 1 or is_first)\n",
    "        self.avd_first = avd_first\n",
    "\n",
    "        if self.avd:\n",
    "            self.avd_layer = nn.AvgPool2d(3, stride, padding=1)\n",
    "            stride = 1\n",
    "\n",
    "        if dropblock_prob > 0.0:\n",
    "            self.dropblock1 = DropBlock2D(dropblock_prob, 3)\n",
    "            if radix == 1:\n",
    "                self.dropblock2 = DropBlock2D(dropblock_prob, 3)\n",
    "            self.dropblock3 = DropBlock2D(dropblock_prob, 3)\n",
    "\n",
    "        if radix >= 1:\n",
    "            self.conv2 = SplAtConv2d(\n",
    "                group_width, group_width, kernel_size=3,\n",
    "                stride=stride, padding=dilation,\n",
    "                dilation=dilation, groups=cardinality, bias=False,\n",
    "                radix=radix, rectify=rectified_conv,\n",
    "                rectify_avg=rectify_avg,\n",
    "                norm_layer=norm_layer,\n",
    "                dropblock_prob=dropblock_prob)\n",
    "        elif rectified_conv:\n",
    "            from rfconv import RFConv2d\n",
    "            self.conv2 = RFConv2d(\n",
    "                group_width, group_width, kernel_size=3, stride=stride,\n",
    "                padding=dilation, dilation=dilation,\n",
    "                groups=cardinality, bias=False,\n",
    "                average_mode=rectify_avg)\n",
    "            self.bn2 = norm_layer(group_width)\n",
    "        else:\n",
    "            self.conv2 = nn.Conv2d(\n",
    "                group_width, group_width, kernel_size=3, stride=stride,\n",
    "                padding=dilation, dilation=dilation,\n",
    "                groups=cardinality, bias=False)\n",
    "            self.bn2 = norm_layer(group_width)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(\n",
    "            group_width, planes * 4, kernel_size=1, bias=False)\n",
    "        self.bn3 = norm_layer(planes*4)\n",
    "\n",
    "        if last_gamma:\n",
    "            from torch.nn.init import zeros_\n",
    "            zeros_(self.bn3.weight)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.downsample = downsample\n",
    "        self.dilation = dilation\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        if self.dropblock_prob > 0.0:\n",
    "            out = self.dropblock1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        if self.avd and self.avd_first:\n",
    "            out = self.avd_layer(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        if self.radix == 0:\n",
    "            out = self.bn2(out)\n",
    "            if self.dropblock_prob > 0.0:\n",
    "                out = self.dropblock2(out)\n",
    "            out = self.relu(out)\n",
    "\n",
    "        if self.avd and not self.avd_first:\n",
    "            out = self.avd_layer(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "        if self.dropblock_prob > 0.0:\n",
    "            out = self.dropblock3(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    \"\"\"ResNet Variants\n",
    "    Parameters\n",
    "    ----------\n",
    "    block : Block\n",
    "        Class for the residual block. Options are BasicBlockV1, BottleneckV1.\n",
    "    layers : list of int\n",
    "        Numbers of layers in each block\n",
    "    classes : int, default 1000\n",
    "        Number of classification classes.\n",
    "    dilated : bool, default False\n",
    "        Applying dilation strategy to pretrained ResNet yielding a stride-8 model,\n",
    "        typically used in Semantic Segmentation.\n",
    "    norm_layer : object\n",
    "        Normalization layer used in backbone network (default: :class:`mxnet.gluon.nn.BatchNorm`;\n",
    "        for Synchronized Cross-GPU BachNormalization).\n",
    "    Reference:\n",
    "        - He, Kaiming, et al. \"Deep residual learning for image recognition.\" Proceedings of the IEEE conference on computer vision and pattern recognition. 2016.\n",
    "        - Yu, Fisher, and Vladlen Koltun. \"Multi-scale context aggregation by dilated convolutions.\"\n",
    "    \"\"\"\n",
    "    # pylint: disable=unused-variable\n",
    "    def __init__(self, block, layers, radix=1, groups=1, bottleneck_width=64,\n",
    "                 num_classes=1000, dilated=False, dilation=1,\n",
    "                 deep_stem=False, stem_width=64, avg_down=False,\n",
    "                 rectified_conv=False, rectify_avg=False,\n",
    "                 avd=False, avd_first=False,\n",
    "                 final_drop=0.0, dropblock_prob=0,\n",
    "                 last_gamma=False, norm_layer=nn.BatchNorm2d):\n",
    "        self.cardinality = groups\n",
    "        self.bottleneck_width = bottleneck_width\n",
    "        # ResNet-D params\n",
    "        self.inplanes = stem_width*2 if deep_stem else 64\n",
    "        self.avg_down = avg_down\n",
    "        self.last_gamma = last_gamma\n",
    "        # ResNeSt params\n",
    "        self.radix = radix\n",
    "        self.avd = avd\n",
    "        self.avd_first = avd_first\n",
    "\n",
    "        super(ResNet, self).__init__()\n",
    "        self.rectified_conv = rectified_conv\n",
    "        self.rectify_avg = rectify_avg\n",
    "        if rectified_conv:\n",
    "            from rfconv import RFConv2d\n",
    "            conv_layer = RFConv2d\n",
    "        else:\n",
    "            conv_layer = nn.Conv2d\n",
    "        conv_kwargs = {'average_mode': rectify_avg} if rectified_conv else {}\n",
    "        if deep_stem:\n",
    "            self.conv1 = nn.Sequential(\n",
    "                conv_layer(3, stem_width, kernel_size=3, stride=2, padding=1, bias=False, **conv_kwargs),\n",
    "                norm_layer(stem_width),\n",
    "                nn.ReLU(inplace=True),\n",
    "                conv_layer(stem_width, stem_width, kernel_size=3, stride=1, padding=1, bias=False, **conv_kwargs),\n",
    "                norm_layer(stem_width),\n",
    "                nn.ReLU(inplace=True),\n",
    "                conv_layer(stem_width, stem_width*2, kernel_size=3, stride=1, padding=1, bias=False, **conv_kwargs),\n",
    "            )\n",
    "        else:\n",
    "            self.conv1 = conv_layer(3, 64, kernel_size=7, stride=2, padding=3,\n",
    "                                   bias=False, **conv_kwargs)\n",
    "        self.bn1 = norm_layer(self.inplanes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.layer1 = self._make_layer(block, 64, layers[0], norm_layer=norm_layer, is_first=False)\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2, norm_layer=norm_layer)\n",
    "        if dilated or dilation == 4:\n",
    "            self.layer3 = self._make_layer(block, 256, layers[2], stride=1,\n",
    "                                           dilation=2, norm_layer=norm_layer,\n",
    "                                           dropblock_prob=dropblock_prob)\n",
    "            self.layer4 = self._make_layer(block, 512, layers[3], stride=1,\n",
    "                                           dilation=4, norm_layer=norm_layer,\n",
    "                                           dropblock_prob=dropblock_prob)\n",
    "        elif dilation==2:\n",
    "            self.layer3 = self._make_layer(block, 256, layers[2], stride=2,\n",
    "                                           dilation=1, norm_layer=norm_layer,\n",
    "                                           dropblock_prob=dropblock_prob)\n",
    "            self.layer4 = self._make_layer(block, 512, layers[3], stride=1,\n",
    "                                           dilation=2, norm_layer=norm_layer,\n",
    "                                           dropblock_prob=dropblock_prob)\n",
    "        else:\n",
    "            self.layer3 = self._make_layer(block, 256, layers[2], stride=2,\n",
    "                                           norm_layer=norm_layer,\n",
    "                                           dropblock_prob=dropblock_prob)\n",
    "            self.layer4 = self._make_layer(block, 512, layers[3], stride=2,\n",
    "                                           norm_layer=norm_layer,\n",
    "                                           dropblock_prob=dropblock_prob)\n",
    "        self.avgpool = GlobalAvgPool2d()\n",
    "        self.drop = nn.Dropout(final_drop) if final_drop > 0.0 else None\n",
    "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "            elif isinstance(m, norm_layer):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1, dilation=1, norm_layer=None,\n",
    "                    dropblock_prob=0.0, is_first=True):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            down_layers = []\n",
    "            if self.avg_down:\n",
    "                if dilation == 1:\n",
    "                    down_layers.append(nn.AvgPool2d(kernel_size=stride, stride=stride,\n",
    "                                                    ceil_mode=True, count_include_pad=False))\n",
    "                else:\n",
    "                    down_layers.append(nn.AvgPool2d(kernel_size=1, stride=1,\n",
    "                                                    ceil_mode=True, count_include_pad=False))\n",
    "                down_layers.append(nn.Conv2d(self.inplanes, planes * block.expansion,\n",
    "                                             kernel_size=1, stride=1, bias=False))\n",
    "            else:\n",
    "                down_layers.append(nn.Conv2d(self.inplanes, planes * block.expansion,\n",
    "                                             kernel_size=1, stride=stride, bias=False))\n",
    "            down_layers.append(norm_layer(planes * block.expansion))\n",
    "            downsample = nn.Sequential(*down_layers)\n",
    "\n",
    "        layers = []\n",
    "        if dilation == 1 or dilation == 2:\n",
    "            layers.append(block(self.inplanes, planes, stride, downsample=downsample,\n",
    "                                radix=self.radix, cardinality=self.cardinality,\n",
    "                                bottleneck_width=self.bottleneck_width,\n",
    "                                avd=self.avd, avd_first=self.avd_first,\n",
    "                                dilation=1, is_first=is_first, rectified_conv=self.rectified_conv,\n",
    "                                rectify_avg=self.rectify_avg,\n",
    "                                norm_layer=norm_layer, dropblock_prob=dropblock_prob,\n",
    "                                last_gamma=self.last_gamma))\n",
    "        elif dilation == 4:\n",
    "            layers.append(block(self.inplanes, planes, stride, downsample=downsample,\n",
    "                                radix=self.radix, cardinality=self.cardinality,\n",
    "                                bottleneck_width=self.bottleneck_width,\n",
    "                                avd=self.avd, avd_first=self.avd_first,\n",
    "                                dilation=2, is_first=is_first, rectified_conv=self.rectified_conv,\n",
    "                                rectify_avg=self.rectify_avg,\n",
    "                                norm_layer=norm_layer, dropblock_prob=dropblock_prob,\n",
    "                                last_gamma=self.last_gamma))\n",
    "        else:\n",
    "            raise RuntimeError(\"=> unknown dilation size: {}\".format(dilation))\n",
    "\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes,\n",
    "                                radix=self.radix, cardinality=self.cardinality,\n",
    "                                bottleneck_width=self.bottleneck_width,\n",
    "                                avd=self.avd, avd_first=self.avd_first,\n",
    "                                dilation=dilation, rectified_conv=self.rectified_conv,\n",
    "                                rectify_avg=self.rectify_avg,\n",
    "                                norm_layer=norm_layer, dropblock_prob=dropblock_prob,\n",
    "                                last_gamma=self.last_gamma))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        #x = x.view(x.size(0), -1)\n",
    "        x = torch.flatten(x, 1)\n",
    "        if self.drop:\n",
    "            x = self.drop(x)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(args: tp.Dict):\n",
    "    # # get resnest50_fast_1s1x64d\n",
    "    model = ResNet(\n",
    "        Bottleneck, [3, 4, 6, 3],\n",
    "        radix=1, groups=1, bottleneck_width=64,\n",
    "        deep_stem=True, stem_width=32, avg_down=True,\n",
    "        avd=True, avd_first=True)\n",
    "    \n",
    "    state_dict = torch.load(args[\"trained_weights\"])\n",
    "    model.load_state_dict(state_dict)\n",
    "    \n",
    "    del model.fc\n",
    "    # # use the same head as the baseline notebook.\n",
    "    model.fc = nn.Sequential(\n",
    "        nn.Linear(2048, 1024), nn.ReLU(), nn.Dropout(p=0.2),\n",
    "        nn.Linear(1024, 1024), nn.ReLU(), nn.Dropout(p=0.2),\n",
    "        nn.Linear(1024, args[\"num_classes\"]))\n",
    "    \n",
    "#     state_dict = torch.load(args[\"trained_weights\"])\n",
    "#     model.load_state_dict(state_dict)\n",
    "    device = torch.device(\"cuda\")\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    return model\n",
    "\n",
    "# def get_model(args: tp.Dict):\n",
    "#     model =getattr(resnest_torch, args[\"name\"])(pretrained=args[\"params\"][\"pretrained\"])\n",
    "#     del model.fc\n",
    "#     # # use the same head as the baseline notebook.\n",
    "#     model.fc = nn.Sequential(\n",
    "#         nn.Linear(2048, 1024), nn.ReLU(), nn.Dropout(p=0.2),\n",
    "#         nn.Linear(1024, 1024), nn.ReLU(), nn.Dropout(p=0.2),\n",
    "#         nn.Linear(1024, args[\"params\"][\"n_classes\"]))\n",
    "    \n",
    "#     return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[globals]\n",
      "{'seed': 1213, 'device': 'cuda', 'num_epochs': 45, 'output_dir': '/kaggle/training_output/', 'use_fold': 0, 'target_sr': 32000}\n",
      "[dataset]\n",
      "{'name': 'SpectrogramDataset', 'params': {'img_size': 224, 'melspectrogram_parameters': {'n_mels': 128, 'fmin': 20, 'fmax': 16000}}}\n",
      "[split]\n",
      "{'name': 'StratifiedKFold', 'params': {'n_splits': 5, 'random_state': 42, 'shuffle': True}}\n",
      "[loader]\n",
      "{'train': {'batch_size': 50, 'shuffle': True, 'num_workers': 10, 'pin_memory': True, 'drop_last': True}, 'val': {'batch_size': 50, 'shuffle': False, 'num_workers': 10, 'pin_memory': True, 'drop_last': False}}\n",
      "[model]\n",
      "{'name': 'resnest50_fast_1s1x64d', 'params': {'pretrained': True, 'n_classes': 264}}\n",
      "[loss]\n",
      "{'name': 'BCEWithLogitsLoss', 'params': {}}\n",
      "[optimizer]\n",
      "{'name': 'Adam', 'params': {'lr': 0.001}}\n",
      "[scheduler]\n",
      "{'name': 'CosineAnnealingLR', 'params': {'T_max': 10}}\n"
     ]
    }
   ],
   "source": [
    "settings = yaml.safe_load(settings_str)\n",
    "if DEBUG:\n",
    "    settings['split']['params']['n_splits'] = 2\n",
    "    settings['globals']['num_epochs'] = 3\n",
    "\n",
    "for k, v in settings.items():\n",
    "    print(\"[{}]\".format(k))\n",
    "    print(v)\n",
    "set_seed(settings[\"globals\"][\"seed\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "data path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = Path.cwd().parent\n",
    "input_ex_root = root / 'data_ignore/external_dataset' / DATASET\n",
    "train_resampled_audio_dirs = [input_ex_root / \"birdsong-resampled-train-audio-{:0>2}\"\n",
    "                              .format(i)  for i in range(5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('/home/user/Git/kaggle-Cornell-Birdcall-Identification/data_ignore/external_dataset/32khz/birdsong-resampled-train-audio-00'),\n",
       " PosixPath('/home/user/Git/kaggle-Cornell-Birdcall-Identification/data_ignore/external_dataset/32khz/birdsong-resampled-train-audio-01'),\n",
       " PosixPath('/home/user/Git/kaggle-Cornell-Birdcall-Identification/data_ignore/external_dataset/32khz/birdsong-resampled-train-audio-02'),\n",
       " PosixPath('/home/user/Git/kaggle-Cornell-Birdcall-Identification/data_ignore/external_dataset/32khz/birdsong-resampled-train-audio-03'),\n",
       " PosixPath('/home/user/Git/kaggle-Cornell-Birdcall-Identification/data_ignore/external_dataset/32khz/birdsong-resampled-train-audio-04')]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_resampled_audio_dirs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(train_resampled_audio_dirs[0] / \"train_mod.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Execution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "train_all を作成  \n",
    "train_all: リサンプル後のファイルパスなどを追加"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21375, 38)\n",
      "(21375, 3)\n",
      "(21375, 39)\n"
     ]
    }
   ],
   "source": [
    "tmp_list = []\n",
    "for audio_d in train_resampled_audio_dirs:\n",
    "    if not audio_d.exists():\n",
    "        continue\n",
    "    for ebird_d in audio_d.iterdir():\n",
    "        if ebird_d.is_file():\n",
    "            continue\n",
    "        for i, wav_f in enumerate(ebird_d.iterdir()):\n",
    "            bool_n_splits = i==settings['split']['params']['n_splits']\n",
    "            if bool_n_splits and DEBUG: break  # if DEBUG=True: 1bird/n_splits file\n",
    "            tmp_list.append([ebird_d.name, wav_f.name, wav_f.as_posix()])\n",
    "            \n",
    "train_wav_path_exist = pd.DataFrame(\n",
    "    tmp_list, columns=[\"ebird_code\", \"resampled_filename\", \"file_path\"])\n",
    "\n",
    "del tmp_list\n",
    "\n",
    "train_all = pd.merge(\n",
    "    train, train_wav_path_exist, on=[\"ebird_code\", \"resampled_filename\"], how=\"inner\")\n",
    "\n",
    "if DEBUG: print('----- debug mode -----')\n",
    "print(train.shape)\n",
    "print(train_wav_path_exist.shape)\n",
    "print(train_all.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(**settings[\"split\"][\"params\"])\n",
    "\n",
    "train_all[\"fold\"] = -1\n",
    "for fold_id, (train_index, val_index) in enumerate(skf.split(train_all, train_all[\"ebird_code\"])):\n",
    "    train_all.iloc[val_index, -1] = fold_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(264, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>fold</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ebird_code</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>aldfly</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ameavo</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>amebit</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>amecro</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>amegfi</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yebsap</th>\n",
       "      <td>13</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yehbla</th>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yelwar</th>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>17</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yerwar</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yetvir</th>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>264 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "fold         0   1   2   3   4\n",
       "ebird_code                    \n",
       "aldfly      20  20  20  20  20\n",
       "ameavo       8   8   8   7   7\n",
       "amebit       9   9   8   9   9\n",
       "amecro      20  20  20  20  20\n",
       "amegfi      20  20  20  20  20\n",
       "...         ..  ..  ..  ..  ..\n",
       "yebsap      13  12  12  13  13\n",
       "yehbla      11  12  12  11  11\n",
       "yelwar      18  18  17  18  18\n",
       "yerwar      20  20  20  20  20\n",
       "yetvir      19  19  20  20  20\n",
       "\n",
       "[264 rows x 5 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fold_proportion = pd.pivot_table(train_all, index=\"ebird_code\", columns=\"fold\", values=\"xc_id\", aggfunc=len)\n",
    "print(fold_proportion.shape)\n",
    "fold_proportion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[fold 0] train: 17100, val: 4275\n"
     ]
    }
   ],
   "source": [
    "use_fold = settings[\"globals\"][\"use_fold\"]\n",
    "idx_train = train_all['fold']!=use_fold\n",
    "idx_valid = train_all['fold']==use_fold\n",
    "train_file_list = train_all[idx_train][['file_path', 'ebird_code']].values.tolist()\n",
    "valid_file_list = train_all[idx_valid][['file_path', 'ebird_code']].values.tolist()\n",
    "\n",
    "print(\"[fold {}] train: {}, val: {}\".format(use_fold, len(train_file_list), len(valid_file_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21375"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_file_list)+len(valid_file_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(settings['globals']['device'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "**<font color='orange'> -------------------- settings ------------------ </font>**"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# # # get loader\n",
    "train_loader, valid_loader = get_loaders_for_training(\n",
    "    SpectrogramDataset,\n",
    "    settings[\"dataset\"][\"params\"], settings[\"loader\"], train_file_list, valid_file_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model name: ResNet\n"
     ]
    }
   ],
   "source": [
    "# resnet18\n",
    "# model = models.resnet18(pretrained=True)\n",
    "# model.fc = nn.Linear(in_features=512, out_features=len(BIRD_CODE))\n",
    "\n",
    "# resnet34\n",
    "# model = models.resnet34(pretrained=True)\n",
    "# model.fc = nn.Linear(in_features=512, out_features=len(BIRD_CODE))\n",
    "\n",
    "# resnet50 のファインチューニング\n",
    "# model = models.resnet50(pretrained=True)\n",
    "# model.fc = nn.Linear(in_features=2048, out_features=len(BIRD_CODE))\n",
    "\n",
    "# resnest\n",
    "# model = getattr(resnest_torch, settings['model'][\"name\"])(pretrained=settings['model'][\"params\"][\"pretrained\"])\n",
    "# del model.fc\n",
    "# model.fc = nn.Sequential(\n",
    "#     nn.Linear(2048, 1024), nn.ReLU(), nn.Dropout(p=0.2),\n",
    "#     nn.Linear(1024, 1024), nn.ReLU(), nn.Dropout(p=0.2),\n",
    "#     nn.Linear(1024, settings['model'][\"params\"][\"n_classes\"]))\n",
    "# resnest\n",
    "model_config = {\n",
    "    \"base_model_name\": \"resnest50_fast_1s1x64d\",\n",
    "    \"pretrained\": False,\n",
    "    \"num_classes\": 264,\n",
    "    \"trained_weights\": PATH_MODEL,\n",
    "}\n",
    "model = get_model(model_config)\n",
    "\n",
    "\n",
    "model = model.to(device)\n",
    "print(f'model name: {model.__class__.__name__}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<font color='orange'> ------------------------------------------------ </font>**"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "save_path = f'{save_dir}model_{model.__class__.__name__}.pth'\n",
    "save_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predection check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestDataset(data.Dataset):\n",
    "    def __init__(self, df: pd.DataFrame, clip: np.ndarray,\n",
    "                 img_size=224, melspectrogram_parameters={}):\n",
    "        self.df = df\n",
    "        self.clip = clip\n",
    "        self.img_size = img_size\n",
    "        self.melspectrogram_parameters = melspectrogram_parameters\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx: int):\n",
    "        SR = 32000\n",
    "        sample = self.df.loc[idx, :]\n",
    "        site = sample.site\n",
    "        row_id = sample.row_id\n",
    "        \n",
    "        if site == \"site_3\":\n",
    "            y = self.clip.astype(np.float32)\n",
    "            len_y = len(y)\n",
    "            start = 0\n",
    "            end = SR * 5\n",
    "            images = []\n",
    "            while len_y > start:\n",
    "                y_batch = y[start:end].astype(np.float32)\n",
    "                if len(y_batch) != (SR * 5):\n",
    "                    break\n",
    "                start = end\n",
    "                end = end + SR * 5\n",
    "                \n",
    "                melspec = librosa.feature.melspectrogram(y_batch,\n",
    "                                                         sr=SR,\n",
    "                                                         **self.melspectrogram_parameters)\n",
    "                melspec = librosa.power_to_db(melspec).astype(np.float32)\n",
    "                image = mono_to_color(melspec)\n",
    "                height, width, _ = image.shape\n",
    "                image = cv2.resize(image, (int(width * self.img_size / height), self.img_size))\n",
    "                image = np.moveaxis(image, 2, 0)\n",
    "                image = (image / 255.0).astype(np.float32)\n",
    "                images.append(image)\n",
    "            images = np.asarray(images)\n",
    "            return images, row_id, site\n",
    "        else:\n",
    "            end_seconds = int(sample.seconds)\n",
    "            start_seconds = int(end_seconds - 5)\n",
    "            \n",
    "            start_index = SR * start_seconds\n",
    "            end_index = SR * end_seconds\n",
    "            \n",
    "            y = self.clip[start_index:end_index].astype(np.float32)\n",
    "\n",
    "            melspec = librosa.feature.melspectrogram(y, sr=SR, **self.melspectrogram_parameters)\n",
    "            melspec = librosa.power_to_db(melspec).astype(np.float32)\n",
    "\n",
    "            image = mono_to_color(melspec)\n",
    "            height, width, _ = image.shape\n",
    "            image = cv2.resize(image, (int(width * self.img_size / height), self.img_size))\n",
    "            image = np.moveaxis(image, 2, 0)\n",
    "            image = (image / 255.0).astype(np.float32)\n",
    "\n",
    "            return image, row_id, site\n",
    "        \n",
    "class TestDataset_mod(data.Dataset):\n",
    "    def __init__(self,\n",
    "                 clip,\n",
    "                 img_size=224,\n",
    "                 melspectrogram_parameters={}):\n",
    "        self.clip = clip\n",
    "        self.img_size = img_size\n",
    "        self.melspectrogram_parameters = melspectrogram_parameters\n",
    "        \n",
    "    def __len__(self):\n",
    "        return 1\n",
    "    \n",
    "    def __getitem__(self, idx: int):\n",
    "        SR = 32000\n",
    "        \n",
    "        y = self.clip.astype(np.float32)\n",
    "        len_y = len(y)\n",
    "        start = 0\n",
    "        end = SR * 5\n",
    "        images = []\n",
    "        while len_y > start:\n",
    "            y_batch = y[start:end].astype(np.float32)\n",
    "            if len(y_batch) != (SR * 5):\n",
    "                break\n",
    "            start = end\n",
    "            end = end + SR * 5\n",
    "\n",
    "            melspec = librosa.feature.melspectrogram(y_batch,\n",
    "                                                     sr=SR,\n",
    "                                                     **self.melspectrogram_parameters)\n",
    "            melspec = librosa.power_to_db(melspec).astype(np.float32)\n",
    "            image = mono_to_color(melspec)\n",
    "            height, width, _ = image.shape\n",
    "            image = cv2.resize(image, (int(width * self.img_size / height), self.img_size))\n",
    "            image = np.moveaxis(image, 2, 0)\n",
    "            image = (image / 255.0).astype(np.float32)\n",
    "            images.append(image)\n",
    "        images = np.asarray(images)\n",
    "        return images\n",
    "        \n",
    "def prediction_for_clip(test_df: pd.DataFrame, \n",
    "                        clip: np.ndarray, \n",
    "                        model, \n",
    "                        mel_params: dict, \n",
    "                        threshold=0.5):\n",
    "\n",
    "    dataset = TestDataset(df=test_df, \n",
    "                          clip=clip,\n",
    "                          img_size=224,\n",
    "                          melspectrogram_parameters=mel_params)\n",
    "    loader = data.DataLoader(dataset, batch_size=1, shuffle=False)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    model.eval()\n",
    "    prediction_dict = {}\n",
    "    for image, row_id, site in progress_bar(loader):\n",
    "        site = site[0]\n",
    "        row_id = row_id[0]\n",
    "        if site in {\"site_1\", \"site_2\"}:\n",
    "            image = image.to(device)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                prediction = model(image)\n",
    "                proba = F.sigmoid(prediction).detach().cpu().numpy().reshape(-1)\n",
    "\n",
    "            events = proba >= threshold\n",
    "            labels = np.argwhere(events).reshape(-1).tolist()\n",
    "            \n",
    "\n",
    "        else:\n",
    "            # to avoid prediction on large batch\n",
    "            image = image.squeeze(0)\n",
    "            batch_size = 16\n",
    "            whole_size = image.size(0)\n",
    "            if whole_size % batch_size == 0:\n",
    "                n_iter = whole_size // batch_size\n",
    "            else:\n",
    "                n_iter = whole_size // batch_size + 1\n",
    "                \n",
    "            all_events = set()\n",
    "            for batch_i in range(n_iter):\n",
    "                batch = image[batch_i * batch_size:(batch_i + 1) * batch_size]\n",
    "#                 if batch.ndim == 3:\n",
    "#                     batch = batch.unsqueeze(0)\n",
    "\n",
    "                batch = batch.to(device)\n",
    "                with torch.no_grad():\n",
    "                    prediction = model(batch)\n",
    "                    proba = F.sigmoid(prediction).detach().cpu().numpy()              \n",
    "                events = proba >= threshold\n",
    "                for i in range(len(events)):\n",
    "                    event = events[i, :]\n",
    "                    labels = np.argwhere(event).reshape(-1).tolist()\n",
    "                    for label in labels:\n",
    "                        all_events.add(label)\n",
    "                        \n",
    "            labels = list(all_events)\n",
    "        if len(labels) == 0:\n",
    "            prediction_dict[row_id] = \"nocall\"\n",
    "        else:\n",
    "            labels_str_list = list(map(lambda x: INV_BIRD_CODE[x], labels))\n",
    "            label_string = \" \".join(labels_str_list)\n",
    "            prediction_dict[row_id] = label_string\n",
    "    return prediction_dict\n",
    "\n",
    "def prediction_for_clip_mod(clip: np.ndarray, \n",
    "                            model,\n",
    "                            mel_params: dict,\n",
    "                            threshold=0.5):\n",
    "\n",
    "    dataset = TestDataset_mod(clip=clip,\n",
    "                          img_size=224,\n",
    "                          melspectrogram_parameters=mel_params)\n",
    "    loader = data.DataLoader(dataset, batch_size=1, shuffle=False)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    model.eval()\n",
    "#     prediction_dict = {}\n",
    "    prediction_list = []\n",
    "    for image in loader:\n",
    "        # to avoid prediction on large batch\n",
    "        image = image.squeeze(0)\n",
    "        batch_size = 16\n",
    "        whole_size = image.size(0)\n",
    "        if whole_size % batch_size == 0:\n",
    "            n_iter = whole_size // batch_size\n",
    "        else:\n",
    "            n_iter = whole_size // batch_size + 1\n",
    "\n",
    "        all_events = set()\n",
    "        for batch_i in range(n_iter):\n",
    "            batch = image[batch_i * batch_size:(batch_i + 1) * batch_size]\n",
    "#                 if batch.ndim == 3:\n",
    "#                     batch = batch.unsqueeze(0)\n",
    "\n",
    "            batch = batch.to(device)\n",
    "            with torch.no_grad():\n",
    "                prediction = model(batch)\n",
    "                proba = F.sigmoid(prediction).detach().cpu().numpy()              \n",
    "            events = proba >= threshold\n",
    "            for i in range(len(events)):\n",
    "                event = events[i, :]\n",
    "                labels = np.argwhere(event).reshape(-1).tolist()\n",
    "                for label in labels:\n",
    "                    all_events.add(label)\n",
    "\n",
    "        labels = list(all_events)\n",
    "        \n",
    "        if len(labels) == 0:\n",
    "            prediction_list.append(\"nocall\")\n",
    "        else:\n",
    "            labels_str_list = list(map(lambda x: INV_BIRD_CODE[x], labels))\n",
    "            label_string = \" \".join(labels_str_list)\n",
    "#             prediction_dict[row_id] = label_string\n",
    "            prediction_list.append(label_string)\n",
    "    return prediction_list\n",
    "\n",
    "def prediction_for_clip_mod2(clip: np.ndarray, \n",
    "                            model,\n",
    "                            mel_params: dict,\n",
    "                            threshold=0.5):\n",
    "\n",
    "    dataset = TestDataset_mod(clip=clip,\n",
    "                          img_size=224,\n",
    "                          melspectrogram_parameters=mel_params)\n",
    "    loader = data.DataLoader(dataset, batch_size=1, shuffle=False)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    model.eval()\n",
    "#     prediction_dict = {}\n",
    "    prediction_list = []\n",
    "    for image in loader:\n",
    "        # to avoid prediction on large batch\n",
    "        image = image.squeeze(0)\n",
    "        batch_size = 16\n",
    "        whole_size = image.size(0)\n",
    "        if whole_size % batch_size == 0:\n",
    "            n_iter = whole_size // batch_size\n",
    "        else:\n",
    "            n_iter = whole_size // batch_size + 1\n",
    "\n",
    "        all_events = set()\n",
    "        max_proba = 0\n",
    "        max_label = 0\n",
    "        for batch_i in range(n_iter):\n",
    "            batch = image[batch_i * batch_size:(batch_i + 1) * batch_size]\n",
    "#                 if batch.ndim == 3:\n",
    "#                     batch = batch.unsqueeze(0)\n",
    "\n",
    "            batch = batch.to(device)\n",
    "            with torch.no_grad():\n",
    "                prediction = model(batch)\n",
    "                proba = F.sigmoid(prediction).detach().cpu().numpy()              \n",
    "            for proba_ in proba:\n",
    "                proba_val = np.max(proba_)\n",
    "                if proba_val > max_proba:\n",
    "                    max_proba = proba_val\n",
    "                    max_label = np.argmax(proba_)\n",
    "\n",
    "        labels = [max_label]\n",
    "        \n",
    "        if len(labels) == 0:\n",
    "            prediction_list.append(\"nocall\")\n",
    "        else:\n",
    "            labels_str_list = list(map(lambda x: INV_BIRD_CODE[x], labels))\n",
    "            label_string = \" \".join(labels_str_list)\n",
    "#             prediction_dict[row_id] = label_string\n",
    "            prediction_list.append(label_string)\n",
    "    return prediction_list\n",
    "\n",
    "\n",
    "def prediction_for_clip_site3_mod(test_df: pd.DataFrame, \n",
    "                        clip: np.ndarray, \n",
    "                        model, \n",
    "                        mel_params: dict, \n",
    "                        threshold=0.5):\n",
    "\n",
    "    dataset = TestDataset(df=test_df, \n",
    "                          clip=clip,\n",
    "                          img_size=224,\n",
    "                          melspectrogram_parameters=mel_params)\n",
    "    loader = data.DataLoader(dataset, batch_size=1, shuffle=False)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    model.eval()\n",
    "    prediction_dict = {}\n",
    "    for image, row_id, site in progress_bar(loader):\n",
    "        site = site[0]\n",
    "        row_id = row_id[0]\n",
    "        if site in {\"site_1\", \"site_2\"}:\n",
    "            image = image.to(device)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                prediction = model(image)\n",
    "                proba = F.sigmoid(prediction).detach().cpu().numpy().reshape(-1)\n",
    "\n",
    "            events = proba >= threshold\n",
    "            labels = np.argwhere(events).reshape(-1).tolist()\n",
    "            \n",
    "\n",
    "        else:\n",
    "            # to avoid prediction on large batch\n",
    "            image = image.squeeze(0)\n",
    "            batch_size = 16\n",
    "            whole_size = image.size(0)\n",
    "            if whole_size % batch_size == 0:\n",
    "                n_iter = whole_size // batch_size\n",
    "            else:\n",
    "                n_iter = whole_size // batch_size + 1\n",
    "                \n",
    "            all_events = set()\n",
    "            max_proba = 0\n",
    "            for batch_i in range(n_iter):\n",
    "                batch = image[batch_i * batch_size:(batch_i + 1) * batch_size]\n",
    "#                 if batch.ndim == 3:\n",
    "#                     batch = batch.unsqueeze(0)\n",
    "\n",
    "                batch = batch.to(device)\n",
    "                with torch.no_grad():\n",
    "                    prediction = model(batch)\n",
    "                    proba = F.sigmoid(prediction).detach().cpu().numpy()              \n",
    "                for proba_ in proba:\n",
    "                    proba_val = np.max(proba_)\n",
    "                    if proba_val > max_proba:\n",
    "                        max_proba = proba_val\n",
    "                        max_label = np.argmax(proba_)\n",
    "                        \n",
    "            labels = [max_label]\n",
    "                        \n",
    "        if len(labels) == 0:\n",
    "            prediction_dict[row_id] = \"nocall\"\n",
    "        else:\n",
    "            labels_str_list = list(map(lambda x: INV_BIRD_CODE[x], labels))\n",
    "            label_string = \" \".join(labels_str_list)\n",
    "            prediction_dict[row_id] = label_string\n",
    "    return prediction_dict\n",
    "\n",
    "\n",
    "\n",
    "def prediction(test_df: pd.DataFrame,\n",
    "               test_audio: Path,\n",
    "               mel_params: dict,\n",
    "               model,\n",
    "               threshold=0.5):\n",
    "    \n",
    "    unique_audio_id = test_df.audio_id.unique()\n",
    "\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    prediction_dfs = []\n",
    "    for audio_id in unique_audio_id:\n",
    "        with timer(f\"Loading {audio_id}\", logger):\n",
    "            clip, _ = librosa.load(f'{test_audio}/{audio_id}.mp3',\n",
    "                                   sr=TARGET_SR,\n",
    "                                   mono=True,\n",
    "                                   res_type=\"kaiser_fast\")\n",
    "        \n",
    "        test_df_for_audio_id = test_df.query(\n",
    "            f\"audio_id == '{audio_id}'\").reset_index(drop=True)\n",
    "        with timer(f\"Prediction on {audio_id}\", logger):\n",
    "            prediction_dict = prediction_for_clip(test_df_for_audio_id,\n",
    "                                                  clip=clip,\n",
    "                                                  model=model,\n",
    "                                                  mel_params=mel_params,\n",
    "                                                  threshold=threshold)\n",
    "        row_id = list(prediction_dict.keys())\n",
    "        birds = list(prediction_dict.values())\n",
    "        prediction_df = pd.DataFrame({\n",
    "            \"row_id\": row_id,\n",
    "            \"birds\": birds\n",
    "        })\n",
    "        prediction_dfs.append(prediction_df)\n",
    "    \n",
    "    prediction_df = pd.concat(prediction_dfs, axis=0, sort=False).reset_index(drop=True)\n",
    "    return prediction_df\n",
    "\n",
    "def prediction_mod(\n",
    "               test_audio_path_list,\n",
    "               mel_params: dict,\n",
    "               model,\n",
    "               threshold=0.5):\n",
    "    \n",
    "#     unique_audio_id = test_df.audio_id.unique()\n",
    "\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    prediction_dfs = []\n",
    "#     for audio_id in unique_audio_id:\n",
    "    for path in progress_bar(test_audio_path_list):\n",
    "        clip, _ = librosa.load(path,\n",
    "                               sr=TARGET_SR,\n",
    "                               mono=True,\n",
    "                               res_type=\"kaiser_fast\")\n",
    "        \n",
    "        prediction_list = prediction_for_clip_mod(clip=clip,\n",
    "                                                  model=model,\n",
    "                                                  mel_params=mel_params,\n",
    "                                                  threshold=threshold)\n",
    "        birds = prediction_list\n",
    "        prediction_df = pd.DataFrame({\n",
    "            \"birds\": birds\n",
    "        })\n",
    "        prediction_dfs.append(prediction_df)\n",
    "    \n",
    "    prediction_df = pd.concat(prediction_dfs, axis=0, sort=False).reset_index(drop=True)\n",
    "    return prediction_df\n",
    "\n",
    "def prediction_site3_mod(test_df: pd.DataFrame,\n",
    "               test_audio: Path,\n",
    "               mel_params: dict,\n",
    "               model,\n",
    "               threshold=0.5):\n",
    "    \n",
    "    unique_audio_id = test_df.audio_id.unique()\n",
    "\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    prediction_dfs = []\n",
    "    for audio_id in unique_audio_id:\n",
    "        with timer(f\"Loading {audio_id}\", logger):\n",
    "            clip, _ = librosa.load(f'{test_audio}/{audio_id}.mp3',\n",
    "                                   sr=TARGET_SR,\n",
    "                                   mono=True,\n",
    "                                   res_type=\"kaiser_fast\")\n",
    "        \n",
    "        test_df_for_audio_id = test_df.query(\n",
    "            f\"audio_id == '{audio_id}'\").reset_index(drop=True)\n",
    "        with timer(f\"Prediction on {audio_id}\", logger):\n",
    "            prediction_dict = prediction_for_clip_site3_mod(test_df_for_audio_id,\n",
    "                                                  clip=clip,\n",
    "                                                  model=model,\n",
    "                                                  mel_params=mel_params,\n",
    "                                                  threshold=threshold)\n",
    "        row_id = list(prediction_dict.keys())\n",
    "        birds = list(prediction_dict.values())\n",
    "        prediction_df = pd.DataFrame({\n",
    "            \"row_id\": row_id,\n",
    "            \"birds\": birds\n",
    "        })\n",
    "        prediction_dfs.append(prediction_df)\n",
    "    \n",
    "    prediction_df = pd.concat(prediction_dfs, axis=0, sort=False).reset_index(drop=True)\n",
    "    return prediction_df\n",
    "\n",
    "def prediction_mod2(\n",
    "               test_audio_path_list,\n",
    "               mel_params: dict,\n",
    "               model,\n",
    "               threshold=0.5):\n",
    "    \n",
    "#     unique_audio_id = test_df.audio_id.unique()\n",
    "\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    prediction_dfs = []\n",
    "#     for audio_id in unique_audio_id:\n",
    "    for path in progress_bar(test_audio_path_list):\n",
    "        clip, _ = librosa.load(path,\n",
    "                               sr=TARGET_SR,\n",
    "                               mono=True,\n",
    "                               res_type=\"kaiser_fast\")\n",
    "        \n",
    "        prediction_list = prediction_for_clip_mod2(clip=clip,\n",
    "                                                  model=model,\n",
    "                                                  mel_params=mel_params,\n",
    "                                                  threshold=threshold)\n",
    "        birds = prediction_list\n",
    "        prediction_df = pd.DataFrame({\n",
    "            \"birds\": birds\n",
    "        })\n",
    "        prediction_dfs.append(prediction_df)\n",
    "    \n",
    "    prediction_df = pd.concat(prediction_dfs, axis=0, sort=False).reset_index(drop=True)\n",
    "    return prediction_df\n",
    "\n",
    "@contextmanager\n",
    "def timer(name: str, logger):\n",
    "    t0 = time.time()\n",
    "    msg = f\"[{name}] start\"\n",
    "    if logger is None:\n",
    "        print(msg)\n",
    "    else:\n",
    "        logger.info(msg)\n",
    "    yield\n",
    "\n",
    "    msg = f\"[{name}] done in {time.time() - t0:.2f} s\"\n",
    "    if logger is None:\n",
    "        print(msg)\n",
    "    else:\n",
    "        logger.info(msg)\n",
    "        \n",
    "def get_logger(out_file=None):\n",
    "    logger = logging.getLogger()\n",
    "    formatter = logging.Formatter(\"%(asctime)s - %(levelname)s - %(message)s\")\n",
    "    logger.handlers = []\n",
    "    logger.setLevel(logging.INFO)\n",
    "\n",
    "    handler = logging.StreamHandler()\n",
    "    handler.setFormatter(formatter)\n",
    "    handler.setLevel(logging.INFO)\n",
    "    logger.addHandler(handler)\n",
    "\n",
    "    if out_file is not None:\n",
    "        fh = logging.FileHandler(out_file)\n",
    "        fh.setFormatter(formatter)\n",
    "        fh.setLevel(logging.INFO)\n",
    "        logger.addHandler(fh)\n",
    "    logger.info(\"logger set up\")\n",
    "    return logger\n",
    "\n",
    "@contextmanager\n",
    "def timer(name: str, logger):\n",
    "    t0 = time.time()\n",
    "    msg = f\"[{name}] start\"\n",
    "    if logger is None:\n",
    "        print(msg)\n",
    "    else:\n",
    "        logger.info(msg)\n",
    "    yield\n",
    "\n",
    "    msg = f\"[{name}] done in {time.time() - t0:.2f} s\"\n",
    "    if logger is None:\n",
    "        print(msg)\n",
    "    else:\n",
    "        logger.info(msg)\n",
    "        \n",
    "def get_logger(out_file=None):\n",
    "    logger = logging.getLogger()\n",
    "    formatter = logging.Formatter(\"%(asctime)s - %(levelname)s - %(message)s\")\n",
    "    logger.handlers = []\n",
    "    logger.setLevel(logging.INFO)\n",
    "\n",
    "    handler = logging.StreamHandler()\n",
    "    handler.setFormatter(formatter)\n",
    "    handler.setLevel(logging.INFO)\n",
    "    logger.addHandler(handler)\n",
    "\n",
    "    if out_file is not None:\n",
    "        fh = logging.FileHandler(out_file)\n",
    "        fh.setFormatter(formatter)\n",
    "        fh.setLevel(logging.INFO)\n",
    "        logger.addHandler(fh)\n",
    "    logger.info(\"logger set up\")\n",
    "    return logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-08-30 18:12:41,618 - INFO - logger set up\n"
     ]
    }
   ],
   "source": [
    "logger = get_logger()\n",
    "set_seed(1213)\n",
    "\n",
    "dir_test_audio = '../data/external_dataset/birdcall-check/test_audio/'\n",
    "test = pd.read_csv('./../data/external_dataset/birdcall-check/test.csv')\n",
    "sub = pd.read_csv('./../data_ignore/official/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "melspectrogram_parameters = {\n",
    "    \"n_mels\": 128,\n",
    "    \"fmin\": 20,\n",
    "    \"fmax\": 16000\n",
    "}\n",
    "\n",
    "THRESHOLD = 0.6\n",
    "TARGET_SR = 32000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_path_list = np.array(valid_file_list)[:, 0].tolist()\n",
    "valid_target_list = np.array(valid_file_list)[:, 1].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model nb033\n",
    "- scoreLB: 0.562\n",
    "\n",
    "**prediction_mod**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = './../data_ignore/model/nb033_ResNet/model_ResNet.pth'\n",
    "load_weights = torch.load(model_path)\n",
    "model.load_state_dict(load_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='86' class='' max='86' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [86/86 00:38<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "res = 50\n",
    "df_pred = prediction_mod(test_audio_path_list=valid_path_list[::res],\n",
    "                            model=model,\n",
    "                            mel_params=melspectrogram_parameters,\n",
    "                            threshold=THRESHOLD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ratio of nocall: 0.128\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>birds</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aldfly</td>\n",
       "      <td>aldfly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>canwar magwar</td>\n",
       "      <td>canwar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>hamfly</td>\n",
       "      <td>hamfly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>pinsis</td>\n",
       "      <td>pinsis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>gocspa whtspa</td>\n",
       "      <td>whtspa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            birds  target\n",
       "0          aldfly  aldfly\n",
       "20  canwar magwar  canwar\n",
       "40         hamfly  hamfly\n",
       "60         pinsis  pinsis\n",
       "80  gocspa whtspa  whtspa"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.options.display.max_rows = 500\n",
    "df_pred['target'] = valid_target_list[::res]\n",
    "print(f'ratio of nocall: {df_pred[\"birds\"].isin([\"nocall\"]).sum()/len(df_pred):.3f}')\n",
    "df_pred[::20].head(200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<br>\n",
    "\n",
    "**prediction_mod2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='86' class='' max='86' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [86/86 00:38<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "res = 50\n",
    "df_pred = prediction_mod2(test_audio_path_list=valid_path_list[::res],\n",
    "                            model=model,\n",
    "                            mel_params=melspectrogram_parameters,\n",
    "                            threshold=THRESHOLD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ratio of nocall: 0.000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>birds</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aldfly</td>\n",
       "      <td>aldfly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>amecro</td>\n",
       "      <td>amecro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>amepip</td>\n",
       "      <td>amepip</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>amerob</td>\n",
       "      <td>amerob</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>annhum</td>\n",
       "      <td>annhum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>warvir</td>\n",
       "      <td>balori</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>barswa</td>\n",
       "      <td>barswa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>belspa2</td>\n",
       "      <td>belspa2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>bkbwar</td>\n",
       "      <td>bkbwar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>bkhgro</td>\n",
       "      <td>bkhgro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>bktspa</td>\n",
       "      <td>bktspa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>reshaw</td>\n",
       "      <td>blujay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>boboli</td>\n",
       "      <td>boboli</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>brespa</td>\n",
       "      <td>brespa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>brnthr</td>\n",
       "      <td>brnthr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>btbwar</td>\n",
       "      <td>btbwar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>buggna</td>\n",
       "      <td>buggna</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>bulori</td>\n",
       "      <td>bulori</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>aldfly</td>\n",
       "      <td>buwwar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>calqua</td>\n",
       "      <td>calqua</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>canwar</td>\n",
       "      <td>canwar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>casfin</td>\n",
       "      <td>casfin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>cedwax</td>\n",
       "      <td>cedwax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>chswar</td>\n",
       "      <td>chswar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>comgol</td>\n",
       "      <td>comgol</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>commer</td>\n",
       "      <td>commer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>comrav</td>\n",
       "      <td>comrav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>comyel</td>\n",
       "      <td>comyel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>daejun</td>\n",
       "      <td>daejun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>gryfly</td>\n",
       "      <td>dusfly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>easkin</td>\n",
       "      <td>easkin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>spotow</td>\n",
       "      <td>eastow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>eucdov</td>\n",
       "      <td>eucdov</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>fiespa</td>\n",
       "      <td>fiespa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>gadwal</td>\n",
       "      <td>gadwal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>gnwtea</td>\n",
       "      <td>gnwtea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>goleag</td>\n",
       "      <td>goleag</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>greegr</td>\n",
       "      <td>greegr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>grhowl</td>\n",
       "      <td>grhowl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>grycat</td>\n",
       "      <td>grycat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>hamfly</td>\n",
       "      <td>hamfly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>herthr</td>\n",
       "      <td>herthr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>horlar</td>\n",
       "      <td>horlar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>houspa</td>\n",
       "      <td>houspa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>aldfly</td>\n",
       "      <td>juntit1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>aldfly</td>\n",
       "      <td>larspa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>leabit</td>\n",
       "      <td>leabit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>lesgol</td>\n",
       "      <td>lesgol</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>linspa</td>\n",
       "      <td>linspa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>logshr</td>\n",
       "      <td>logshr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>macwar</td>\n",
       "      <td>macwar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>mallar3</td>\n",
       "      <td>mallar3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>bkcchi</td>\n",
       "      <td>mouchi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>norcar</td>\n",
       "      <td>norcar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>amered</td>\n",
       "      <td>norpar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>norwat</td>\n",
       "      <td>norwat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>orcwar</td>\n",
       "      <td>orcwar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>ovenbi1</td>\n",
       "      <td>ovenbi1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>perfal</td>\n",
       "      <td>perfal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>pilwoo</td>\n",
       "      <td>pilwoo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>pinsis</td>\n",
       "      <td>pinsis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>plsvir</td>\n",
       "      <td>plsvir</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>pygnut</td>\n",
       "      <td>pygnut</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>rebwoo</td>\n",
       "      <td>rebwoo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>aldfly</td>\n",
       "      <td>renpha</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>normoc</td>\n",
       "      <td>rewbla</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>reevir1</td>\n",
       "      <td>robgro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>ruckin</td>\n",
       "      <td>ruckin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>sagspa1</td>\n",
       "      <td>sagspa1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>scatan</td>\n",
       "      <td>scatan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>semsan</td>\n",
       "      <td>semsan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>snogoo</td>\n",
       "      <td>snogoo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>aldfly</td>\n",
       "      <td>sora</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>spotow</td>\n",
       "      <td>spotow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>swathr</td>\n",
       "      <td>swathr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>carwre</td>\n",
       "      <td>tuftit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>vesspa</td>\n",
       "      <td>vesspa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>wesblu</td>\n",
       "      <td>wesblu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>wessan</td>\n",
       "      <td>wessan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>whbnut</td>\n",
       "      <td>whbnut</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>whtspa</td>\n",
       "      <td>whtspa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>wilsni1</td>\n",
       "      <td>wilsni1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>pasfly</td>\n",
       "      <td>wlswar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>woothr</td>\n",
       "      <td>woothr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>amerob</td>\n",
       "      <td>yebsap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>yerwar</td>\n",
       "      <td>yerwar</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      birds   target\n",
       "0    aldfly   aldfly\n",
       "1    amecro   amecro\n",
       "2    amepip   amepip\n",
       "3    amerob   amerob\n",
       "4    annhum   annhum\n",
       "5    warvir   balori\n",
       "6    barswa   barswa\n",
       "7   belspa2  belspa2\n",
       "8    bkbwar   bkbwar\n",
       "9    bkhgro   bkhgro\n",
       "10   bktspa   bktspa\n",
       "11   reshaw   blujay\n",
       "12   boboli   boboli\n",
       "13   brespa   brespa\n",
       "14   brnthr   brnthr\n",
       "15   btbwar   btbwar\n",
       "16   buggna   buggna\n",
       "17   bulori   bulori\n",
       "18   aldfly   buwwar\n",
       "19   calqua   calqua\n",
       "20   canwar   canwar\n",
       "21   casfin   casfin\n",
       "22   cedwax   cedwax\n",
       "23   chswar   chswar\n",
       "24   comgol   comgol\n",
       "25   commer   commer\n",
       "26   comrav   comrav\n",
       "27   comyel   comyel\n",
       "28   daejun   daejun\n",
       "29   gryfly   dusfly\n",
       "30   easkin   easkin\n",
       "31   spotow   eastow\n",
       "32   eucdov   eucdov\n",
       "33   fiespa   fiespa\n",
       "34   gadwal   gadwal\n",
       "35   gnwtea   gnwtea\n",
       "36   goleag   goleag\n",
       "37   greegr   greegr\n",
       "38   grhowl   grhowl\n",
       "39   grycat   grycat\n",
       "40   hamfly   hamfly\n",
       "41   herthr   herthr\n",
       "42   horlar   horlar\n",
       "43   houspa   houspa\n",
       "44   aldfly  juntit1\n",
       "45   aldfly   larspa\n",
       "46   leabit   leabit\n",
       "47   lesgol   lesgol\n",
       "48   linspa   linspa\n",
       "49   logshr   logshr\n",
       "50   macwar   macwar\n",
       "51  mallar3  mallar3\n",
       "52   bkcchi   mouchi\n",
       "53   norcar   norcar\n",
       "54   amered   norpar\n",
       "55   norwat   norwat\n",
       "56   orcwar   orcwar\n",
       "57  ovenbi1  ovenbi1\n",
       "58   perfal   perfal\n",
       "59   pilwoo   pilwoo\n",
       "60   pinsis   pinsis\n",
       "61   plsvir   plsvir\n",
       "62   pygnut   pygnut\n",
       "63   rebwoo   rebwoo\n",
       "64   aldfly   renpha\n",
       "65   normoc   rewbla\n",
       "66  reevir1   robgro\n",
       "67   ruckin   ruckin\n",
       "68  sagspa1  sagspa1\n",
       "69   scatan   scatan\n",
       "70   semsan   semsan\n",
       "71   snogoo   snogoo\n",
       "72   aldfly     sora\n",
       "73   spotow   spotow\n",
       "74   swathr   swathr\n",
       "75   carwre   tuftit\n",
       "76   vesspa   vesspa\n",
       "77   wesblu   wesblu\n",
       "78   wessan   wessan\n",
       "79   whbnut   whbnut\n",
       "80   whtspa   whtspa\n",
       "81  wilsni1  wilsni1\n",
       "82   pasfly   wlswar\n",
       "83   woothr   woothr\n",
       "84   amerob   yebsap\n",
       "85   yerwar   yerwar"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.options.display.max_rows = 500\n",
    "df_pred['target'] = valid_target_list[::res]\n",
    "print(f'ratio of nocall: {df_pred[\"birds\"].isin([\"nocall\"]).sum()/len(df_pred):.3f}')\n",
    "df_pred.head(200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# site3 Inference でnocallが出ないようにする"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-08-30 22:37:22,237 - INFO - [Loading 899616723a32409c996f6f3441646c2a] start\n",
      "2020-08-30 22:37:22,866 - INFO - [Loading 899616723a32409c996f6f3441646c2a] done in 0.63 s\n",
      "2020-08-30 22:37:22,870 - INFO - [Prediction on 899616723a32409c996f6f3441646c2a] start\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='1' class='' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [1/1 00:00<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-08-30 22:37:22,927 - INFO - [Prediction on 899616723a32409c996f6f3441646c2a] done in 0.06 s\n",
      "2020-08-30 22:37:22,929 - INFO - [Loading 9cc5d9646f344f1bbb52640a988fe902] start\n",
      "2020-08-30 22:37:25,132 - INFO - [Loading 9cc5d9646f344f1bbb52640a988fe902] done in 2.20 s\n",
      "2020-08-30 22:37:25,135 - INFO - [Prediction on 9cc5d9646f344f1bbb52640a988fe902] start\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='1' class='' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [1/1 00:02<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-08-30 22:37:27,503 - INFO - [Prediction on 9cc5d9646f344f1bbb52640a988fe902] done in 2.37 s\n",
      "2020-08-30 22:37:27,505 - INFO - [Loading a56e20a518684688a9952add8a9d5213] start\n",
      "2020-08-30 22:37:27,986 - INFO - [Loading a56e20a518684688a9952add8a9d5213] done in 0.48 s\n",
      "2020-08-30 22:37:27,989 - INFO - [Prediction on a56e20a518684688a9952add8a9d5213] start\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='1' class='' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [1/1 00:00<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-08-30 22:37:28,198 - INFO - [Prediction on a56e20a518684688a9952add8a9d5213] done in 0.21 s\n",
      "2020-08-30 22:37:28,200 - INFO - [Loading 96779836288745728306903d54e264dd] start\n",
      "2020-08-30 22:37:28,584 - INFO - [Loading 96779836288745728306903d54e264dd] done in 0.38 s\n",
      "2020-08-30 22:37:28,587 - INFO - [Prediction on 96779836288745728306903d54e264dd] start\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='1' class='' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [1/1 00:00<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-08-30 22:37:28,717 - INFO - [Prediction on 96779836288745728306903d54e264dd] done in 0.13 s\n",
      "2020-08-30 22:37:28,719 - INFO - [Loading f77783ba4c6641bc918b034a18c23e53] start\n",
      "2020-08-30 22:37:29,026 - INFO - [Loading f77783ba4c6641bc918b034a18c23e53] done in 0.31 s\n",
      "2020-08-30 22:37:29,029 - INFO - [Prediction on f77783ba4c6641bc918b034a18c23e53] start\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='1' class='' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [1/1 00:00<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-08-30 22:37:29,083 - INFO - [Prediction on f77783ba4c6641bc918b034a18c23e53] done in 0.05 s\n",
      "2020-08-30 22:37:29,086 - INFO - [Loading 856b194b097441958697c2bcd1f63982] start\n",
      "2020-08-30 22:37:29,543 - INFO - [Loading 856b194b097441958697c2bcd1f63982] done in 0.46 s\n",
      "2020-08-30 22:37:29,547 - INFO - [Prediction on 856b194b097441958697c2bcd1f63982] start\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='1' class='' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [1/1 00:00<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-08-30 22:37:29,775 - INFO - [Prediction on 856b194b097441958697c2bcd1f63982] done in 0.23 s\n"
     ]
    }
   ],
   "source": [
    "submission = prediction_site3_mod(test_df=test[70:],\n",
    "                        test_audio=dir_test_audio,\n",
    "                        model=model,\n",
    "                        mel_params=melspectrogram_parameters,\n",
    "                        threshold=THRESHOLD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>birds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>site_2_899616723a32409c996f6f3441646c2a_50</td>\n",
       "      <td>nocall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>site_3_9cc5d9646f344f1bbb52640a988fe902</td>\n",
       "      <td>aldfly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>site_3_a56e20a518684688a9952add8a9d5213</td>\n",
       "      <td>aldfly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>site_3_96779836288745728306903d54e264dd</td>\n",
       "      <td>aldfly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>site_3_f77783ba4c6641bc918b034a18c23e53</td>\n",
       "      <td>aldfly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>site_3_856b194b097441958697c2bcd1f63982</td>\n",
       "      <td>aldfly</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       row_id   birds\n",
       "0  site_2_899616723a32409c996f6f3441646c2a_50  nocall\n",
       "1     site_3_9cc5d9646f344f1bbb52640a988fe902  aldfly\n",
       "2     site_3_a56e20a518684688a9952add8a9d5213  aldfly\n",
       "3     site_3_96779836288745728306903d54e264dd  aldfly\n",
       "4     site_3_f77783ba4c6641bc918b034a18c23e53  aldfly\n",
       "5     site_3_856b194b097441958697c2bcd1f63982  aldfly"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
